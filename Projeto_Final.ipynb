{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTNXidF3Qq2K"
   },
   "source": [
    "# **Ci√™ncia de Dados e Machine Learning**\n",
    "\n",
    "## **Projeto Final do Curso**\n",
    "\n",
    "---\n",
    "\n",
    "### **Alunos:**\n",
    "\n",
    "> Charles Bezerra - 52400351\n",
    "\n",
    "> Jheferson Warley - 52400071\n",
    "\n",
    "> Paulo Machado - 52400245\n",
    "\n",
    "---\n",
    "\n",
    "### Tema: **Despesas pela Cota para Exerc√≠cio da Atividade Parlamentar**\n",
    "\n",
    "### Base de Dados: https://dadosabertos.camara.leg.br/swagger/api.html?tab=staticfile\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RfgYroaQq2N"
   },
   "source": [
    "Este projeto final do curso de **Ci√™ncia de Dados e Machine** Learning do UniCEUB se baseia na metodologia *Cross-Industry Standard Process for Data Mining - CRISP-DM* (https://www.sv-europe.com/crisp-dm-methodology/), oferecendo uma abordagem estruturada para planejar um projeto de minera√ß√£o de dados de uma forma robusta.\n",
    "\n",
    "Este modelo representa uma sequ√™ncia idealizada de eventos. Na pr√°tica, muitas das tarefas podem ser realizadas em uma ordem diferente, e frequentemente ser√° necess√°rio voltar a tarefas anteriores e repetir certas a√ß√µes.\n",
    "\n",
    "<div>\n",
    "<img src=\"FasesCRISP-DM.png\" width=\"50%\">\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjrc0DUFQq2O"
   },
   "source": [
    "## **Etapas do Processo CRISP-DM**\n",
    "\n",
    "### 1. [Entendimento do Neg√≥cio](#business-understanding)\n",
    "Compreens√£o dos objetivos de neg√≥cio, contexto organizacional e defini√ß√£o das metas anal√≠ticas.\n",
    "\n",
    "- [1.1 Avalia√ß√£o da Situa√ß√£o Atual](#avaliacao-da-situacao)\n",
    "- [1.2 Resultados Esperados](#resultados-esperados)\n",
    "- [1.3 Quest√µes de Pesquisa](#questoes-de-pesquisa)\n",
    "<!-- - [1.4 Plano de Projeto](#plano-do-projeto) -->\n",
    "\n",
    "---\n",
    "\n",
    "### 2. [Entendimento dos Dados](#entendimento-dados)\n",
    "Explora√ß√£o inicial dos dados, coleta e verifica√ß√£o da qualidade.\n",
    "\n",
    "- [2.1 Relatorio Inicial](#relatorio-inicial)\n",
    "- [2.2 Descri√ß√£o dos Dados](#descricao-dados)\n",
    "- [2.3 Explora√ß√£o dos Dados](#exploracao-dados)\n",
    "- [2.4 Verifica√ß√£o da Qualidade dos Dados](#qualidade-dos-dados)\n",
    "\n",
    "---\n",
    "\n",
    "### 3. [Prepara√ß√£o dos Dados](#preparacao-dados)\n",
    "Constru√ß√£o do dataset final que ser√° utilizado para modelagem.\n",
    "\n",
    "- [3.1 Sele√ß√£o dos Dados](#selecao-dados)\n",
    "- [3.2 Limpeza dos Dados](#limpeza-dados)\n",
    "- [3.3 Constru√ß√£o de Dados Derivados](#dados-derivados)\n",
    "- [3.4 Integra√ß√£o de Dados](#integracao-dados)\n",
    "- [3.5 An√°lise Explorat√≥ria de Dados](#analise-dados)\n",
    "\n",
    "---\n",
    "\n",
    "### 4. [Modelagem](#modelagem)\n",
    "Aplica√ß√£o de t√©cnicas de modelagem estat√≠stica ou de machine learning.\n",
    "\n",
    "- [5.1 T√©cnicas de Modelagem](#tecnicas-modelagem)\n",
    "- [5.2 Teste de Modelos](#teste-modelos)\n",
    "- [5.3 Constru√ß√£o dos Modelos](#construcao-modelo)\n",
    "- [5.4 Avalia√ß√£o de Performance](#avaliacao-modelo)\n",
    "\n",
    "---\n",
    "\n",
    "### 5. [Avalia√ß√£o](#avaliacao-modelo)\n",
    "Verifica√ß√£o se o modelo atende os objetivos de neg√≥cio definidos.\n",
    "\n",
    "- [6.1 Regress√£o Log√≠stica](#regressao-logistica)\n",
    "- [6.2 Revis√£o do Processo](#revisao-processo)\n",
    "- [6.3 Determina√ß√£o dos Pr√≥ximos Passos](#proximos-passos)\n",
    "\n",
    "---\n",
    "\n",
    "### 6. [Implementa√ß√£o (Deployment)](#implementacao)\n",
    "Entrega pr√°tica do modelo, seja em relat√≥rio, dashboard, sistema ou API.\n",
    "\n",
    "- [6.1 Planejamento da Implementa√ß√£o](#planejamento-implementacao)\n",
    "- [6.2 Monitoramento e Manuten√ß√£o](#monitoramento)\n",
    "- [6.3 Documenta√ß√£o Final](#documentacao-final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pdYJHP76Qq2O"
   },
   "source": [
    "## 1. Entendimento do Neg√≥cio  <a class=\"anchor\" id=\"business-understanding\"></a>\n",
    "\n",
    "Atualmente, o cen√°rio pol√≠tico brasileiro se mostra em foco, principalmente quando se trata de despesas relacionadas √† sustenta√ß√£o do governo como todo. Neste contexto, as despesas parlamentares, limitadas por uma cota, s√£o frequentemente noticiadas devido a seu alto custo. As cotas parlamentares variam conforme o estado do deputado e √© destinado ao custeio de despesas relacionadas ao exerc√≠cio do mandato. As despesas incluem passagens a√©reas, locomo√ß√£o, hospedagens, servi√ßos de seguran√ßa, divulga√ß√£o de atividades parlamentares e contrata√ß√£o de pessoal.\n",
    "\n",
    "\n",
    "A C√¢mara dos Deputados divulga atrav√©s da plataforma de dados abertos do governo (https://dadosabertos.camara.leg.br/swagger/api.html?tab=staticfile) as despesas refentes ao consumo de cotas separadas por ano, Deputado, UF, tipo de despesas, entre outras classifica√ß√µes. Os arquivos podem ser baixador por ano, dispon√≠veis desde o ano 2018, nos formatos XML, JSON, CSV, XLSX e ODS.\n",
    "\n",
    "\n",
    "Para este projeto, selecionamos os dados relativos ao ano de 2024 (ano completo mais recente) com arquivos no formato CSV para melhor tratamento dos dados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2SqAlWIyQq2P"
   },
   "source": [
    "## 1.1 Avalia√ß√£o da Situa√ß√£o Atual<a class=\"anchor\" id=\"avaliacao-da-situacao\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFsmtXzxQq2P"
   },
   "source": [
    "A transpar√™ncia nos gastos p√∫blicos tem ganhado relev√¢ncia nos debates sociais e institucionais, principalmente no contexto pol√≠tico brasileiro. A C√¢mara dos Deputados disponibiliza, por meio do portal de Dados Abertos, informa√ß√µes detalhadas sobre a utiliza√ß√£o da Cota para o Exerc√≠cio da Atividade Parlamentar (CEAP), que contempla diversos tipos de despesas efetuadas pelos parlamentares no desempenho de suas fun√ß√µes.\n",
    "\n",
    "Apesar da disponibilidade dos dados, observa-se uma subutiliza√ß√£o dessas informa√ß√µes por parte da sociedade civil e dos √≥rg√£os fiscalizadores. O volume e a complexidade dos dados dificultam an√°lises diretas e conclusivas, exigindo ferramentas adequadas de tratamento, an√°lise e visualiza√ß√£o. Diante disso, este projeto visa utilizar t√©cnicas de an√°lise de dados e aprendizado de m√°quina para transformar os dados brutos em insights relevantes e acess√≠veis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWxWA-87Qq2P"
   },
   "source": [
    "## 1.2 Resultados Esperados<a class=\"anchor\" id=\"resultaods-esperados\"></a>\n",
    "\n",
    "Este projeto tem como objetivo geral analisar os gastos parlamentares por meio da base de dados da CEAP, abrangendo os anos de 2023, 2024 e 2025. Os resultados esperados incluem:\n",
    "\n",
    "- Desenvolvimento de relat√≥rios e dashboards anal√≠ticos para visualiza√ß√£o dos dados por deputado, partido pol√≠tico, unidade federativa (UF), tipo de despesa, fornecedor e per√≠odo (m√™s e ano).\n",
    "- An√°lises estat√≠sticas descritivas e comparativas, a fim de identificar padr√µes de gastos e varia√ß√µes relevantes entre diferentes grupos.\n",
    "- Detec√ß√£o de anomalias e poss√≠veis irregularidades nos registros de despesas.\n",
    "- Aplica√ß√£o de t√©cnicas de aprendizado de m√°quina (Machine Learning) com o objetivo de construir modelos preditivos capazes de estimar os gastos parlamentares futuros por partido ou UF, com base nos dados hist√≥ricos.\n",
    "\n",
    "O projeto segue a metodologia CRISP-DM, com foco na reprodutibilidade dos resultados e na cria√ß√£o de documenta√ß√£o clara e acess√≠vel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Quest√µes de Pesquisa<a class=\"anchor\" id=\"questoes-de-pesquisa\"></a>\n",
    "\n",
    "O projeto √© orientado por um conjunto de quest√µes explorat√≥rias e preditivas, que servir√£o como guia para as etapas anal√≠ticas e de modelagem.\n",
    "\n",
    "### Quest√µes Explorat√≥rias\n",
    "\n",
    "- Quais partidos pol√≠ticos apresentaram os maiores volumes de gasto no per√≠odo analisado?\n",
    "- Quais unidades federativas concentram os maiores gastos?\n",
    "- Quais s√£o os tipos de despesa mais recorrentes e qual seu impacto nos valores totais?\n",
    "- Como os gastos variam ao longo do tempo? Existe sazonalidade ou tend√™ncia?\n",
    "- H√° fornecedores recorrentes nos maiores gastos? Qual seu perfil?\n",
    "\n",
    "### Quest√µes Preditivas\n",
    "\n",
    "- √â poss√≠vel prever os gastos parlamentares futuros com base no hist√≥rico de dados?\n",
    "- Quais vari√°veis mais influenciam no volume de gastos (ex.: partido, UF, tipo de despesa, m√™s)?\n",
    "- Quais partidos ou unidades federativas t√™m maior propens√£o a apresentar aumentos nos gastos em futuros mandatos?\n",
    "\n",
    "Estas perguntas direcionam a constru√ß√£o dos indicadores, visualiza√ß√µes e modelos preditivos ao longo do projeto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4S-Y6p8VQq2R"
   },
   "source": [
    "# 2. Entendimento dos Dados <a class=\"anchor\" id=\"entendimento-dados\"></a>\n",
    "A etapa de entendimento dos dados tem como objetivo fornecer uma vis√£o inicial e aprofundada da estrutura, conte√∫do e qualidade do conjunto de dados dispon√≠vel para an√°lise. Trata-se de uma fase fundamental no processo anal√≠tico, pois permite identificar caracter√≠sticas importantes dos dados, potenciais inconsist√™ncias, aus√™ncia de valores e padr√µes que podem influenciar diretamente na prepara√ß√£o, modelagem e interpreta√ß√£o dos resultados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-6TQJ_4Qq2R"
   },
   "source": [
    "## 2.1 Relat√≥rio Inicial <a class=\"anchor\" id=\"relatorio-inicial\"></a>\n",
    "O conjunto de dados utilizado neste projeto refere-se √†s despesas parlamentares registradas na Cota para o Exerc√≠cio da Atividade Parlamentar (CEAP), compreendendo os anos de 2023, 2024 e 2025. Os dados foram extra√≠dos da API p√∫blica da C√¢mara dos Deputados, que disponibiliza os registros em diversos formatos. Para este trabalho, optou-se pelo formato `.csv`, considerando a facilidade de leitura e manipula√ß√£o em ambientes Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "X9OlrvX3Qq2R"
   },
   "outputs": [],
   "source": [
    "# Importa√ß√£o das Bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "D85E5K77Qq2S"
   },
   "outputs": [],
   "source": [
    "# Leitura dos dados\n",
    "df_2023 = pd.read_csv(\"DataBase/Ano-2023.csv\", sep=\";\", encoding=\"utf-8\", low_memory=False)\n",
    "df_2024 = pd.read_csv(\"DataBase/Ano-2024.csv\", sep=\";\", encoding=\"utf-8\", low_memory=False)\n",
    "df_2025 = pd.read_csv(\"DataBase/Ano-2025.csv\", sep=\";\", encoding=\"utf-8\", low_memory=False)\n",
    "\n",
    "# Combina√ß√£o dos tr√™s dataframes\n",
    "df_completo = pd.concat([df_2023, df_2024, df_2025], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibi√ß√£o das 5 primeiras linhas\n",
    "display(df_completo.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZ8n1_pnQq2T"
   },
   "source": [
    "## 2.2 Descri√ß√£o dos Dados <a class=\"anchor\" id=\"descricao-dados\"></a>\n",
    "A seguir, s√£o apresentados o nome das colunas dispon√≠veis no dataset e o seu formato dimensional (linhas x colunas).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A tabela abaixo apresenta a descri√ß√£o de cada uma das vari√°veis dispon√≠veis no conjunto de dados utilizado.\n",
    "\n",
    "| Nome da Coluna                 | Descri√ß√£o                                                        |\n",
    "|-------------------------------|------------------------------------------------------------------|\n",
    "| `txNomeParlamentar`           | Nome do parlamentar                                              |\n",
    "| `cpf`                         | CPF do parlamentar (quando dispon√≠vel)                          |\n",
    "| `ideCadastro`                 | ID √∫nico do parlamentar                                          |\n",
    "| `nuCarteiraParlamentar`       | N√∫mero da carteira parlamentar                                   |\n",
    "| `nuLegislatura`               | N√∫mero da legislatura em exerc√≠cio                               |\n",
    "| `sgUF`                        | Unidade Federativa (estado)                                      |\n",
    "| `sgPartido`                   | Sigla do partido pol√≠tico                                        |\n",
    "| `codLegislatura`              | C√≥digo da legislatura                                            |\n",
    "| `numSubCota`                  | C√≥digo da subcota utilizada                                      |\n",
    "| `txtDescricao`                | Descri√ß√£o da subcota                                             |\n",
    "| `numEspecificacaoSubCota`     | C√≥digo da especifica√ß√£o da subcota                               |\n",
    "| `txtDescricaoEspecificacao`   | Descri√ß√£o detalhada da subcota                                   |\n",
    "| `txtFornecedor`               | Nome do fornecedor                                               |\n",
    "| `txtCNPJCPF`                  | CNPJ ou CPF do fornecedor                                        |\n",
    "| `txtNumero`                   | N√∫mero do documento fiscal                                       |\n",
    "| `indTipoDocumento`            | Tipo do documento (nota fiscal, recibo, etc.)                   |\n",
    "| `datEmissao`                  | Data de emiss√£o do documento                                     |\n",
    "| `vlrDocumento`                | Valor bruto do documento                                         |\n",
    "| `vlrGlosa`                    | Valor glosado/desconsiderado                                     |\n",
    "| `vlrLiquido`                  | Valor l√≠quido aceito                                             |\n",
    "| `numMes`                      | M√™s de refer√™ncia da despesa                                     |\n",
    "| `numAno`                      | Ano de refer√™ncia da despesa                                     |\n",
    "| `numParcela`                  | N√∫mero da parcela, quando aplic√°vel                              |\n",
    "| `txtPassageiro`               | Nome do passageiro (se transporte a√©reo)                         |\n",
    "| `txtTrecho`                   | Trecho da viagem (ida/volta)                                     |\n",
    "| `numLote`                     | N√∫mero do lote do documento                                      |\n",
    "| `numRessarcimento`            | N√∫mero de protocolo de ressarcimento                             |\n",
    "| `datPagamentoRestituicao`     | Data do pagamento de restitui√ß√£o                                 |\n",
    "| `vlrRestituicao`              | Valor restitu√≠do                                                 |\n",
    "| `nuDeputadoId`                | ID √∫nico do deputado                                             |\n",
    "| `ideDocumento`                | ID do documento                                                  |\n",
    "| `urlDocumento`                | Link para o documento oficial                                    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EemJ6DTeQq2U",
    "outputId": "7aa11b1f-b976-4a2a-f622-bab9cffdd1a7"
   },
   "outputs": [],
   "source": [
    "# Nomes das colunas\n",
    "df_completo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gnj33OcMQq2U",
    "outputId": "02529b54-4038-461c-f231-2ba7e0018cc2"
   },
   "outputs": [],
   "source": [
    "# Dimens√£o do dataframe\n",
    "df_completo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNxTQwN_Qq2V"
   },
   "source": [
    "## 2.3 Explora√ß√£o dos Dados <a class=\"anchor\" id=\"exploracao-dados\"></a>\n",
    "\n",
    "Essa etapa visa obter uma vis√£o geral das caracter√≠sticas dos dados, incluindo tipos de vari√°veis, estat√≠sticas descritivas e primeiros insights de distribui√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TwiVpT8FQq2W",
    "outputId": "ac44ac23-9621-40c0-a32a-61b7199f4960"
   },
   "outputs": [],
   "source": [
    "# Verifica√ß√£o de duplicatas\n",
    "df_completo.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estat√≠sticas descritivas\n",
    "df_completo.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estat√≠sticas descritivas\n",
    "df_completo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando valores nulos por coluna\n",
    "df_completo.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a quantidade de valores √∫nicos em algumas colunas-chave\n",
    "print(\"UFs:\", df_completo['sgUF'].nunique())\n",
    "print(\"Partidos:\", df_completo['sgPartido'].nunique())\n",
    "print(\"Tipos de despesa:\", df_completo['txtDescricao'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribui√ß√£o dos principais campos categ√≥ricos\n",
    "\n",
    "# UF\n",
    "uf_counts = df_completo['sgUF'].value_counts().reset_index()\n",
    "uf_counts.columns = ['UF', 'Total de Registros']\n",
    "display(Markdown(\"### Distribui√ß√£o por Unidade Federativa\"))\n",
    "display(uf_counts)\n",
    "\n",
    "# Partido\n",
    "partido_counts = df_completo['sgPartido'].value_counts().reset_index()\n",
    "partido_counts.columns = ['Partido', 'Total de Registros']\n",
    "display(Markdown(\"### Distribui√ß√£o por Partido\"))\n",
    "display(partido_counts)\n",
    "\n",
    "# Tipo de Despesa\n",
    "despesa_counts = df_completo['txtDescricao'].value_counts().reset_index()\n",
    "despesa_counts.columns = ['Tipo de Despesa', 'Total de Registros']\n",
    "display(Markdown(\"### Distribui√ß√£o por Tipo de Despesa\"))\n",
    "display(despesa_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzPUggSjQq2c"
   },
   "source": [
    "## 2.4 Verifica√ß√£o da Qualidade dos Dados<a class=\"anchor\" id=\"qualidade-dos-dados\"></a>\n",
    "Abaixo est√° um resumo quantitativo da qualidade dos dados ap√≥s a an√°lise explorat√≥ria inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo geral do dataset\n",
    "resumo_geral = pd.DataFrame({\n",
    "    \"Indicador\": [\n",
    "        \"Total de registros\",\n",
    "        \"Total de vari√°veis (colunas)\",\n",
    "        \"Registros duplicados\",\n",
    "        \"Valores inconsistentes (vlrDocumento < vlrLiquido)\"\n",
    "    ],\n",
    "    \"Valor\": [\n",
    "        df_completo.shape[0],\n",
    "        df_completo.shape[1],\n",
    "        df_completo.duplicated().sum(),\n",
    "        (df_completo['vlrDocumento'] < df_completo['vlrLiquido']).sum()\n",
    "    ]\n",
    "})\n",
    "\n",
    "display(Markdown(\"### Resumo Geral da Base de Dados\"))\n",
    "display(resumo_geral)\n",
    "\n",
    "# Colunas com valores nulos\n",
    "nulls = df_completo.isnull().sum()\n",
    "nulls = nulls[nulls > 0].sort_values(ascending=False).reset_index()\n",
    "nulls.columns = ['Coluna', 'Valores Nulos']\n",
    "\n",
    "display(Markdown(\"### Colunas com Valores Ausentes\"))\n",
    "display(nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcL0DjOzQq2c"
   },
   "source": [
    "# 3. Prepara√ß√£o dos Dados <a class=\"anchor\" id=\"preparacao-dados\"></a>\n",
    "\n",
    "\n",
    "Nesta etapa, realizamos o tratamento necess√°rio para transformar os dados brutos em uma base estruturada e adequada para aplica√ß√£o de modelos de aprendizado supervisionado. As a√ß√µes incluem: sele√ß√£o e limpeza de dados, gera√ß√£o de atributos derivados e integra√ß√£o das bases hist√≥ricas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQjMmUM5Qq2c"
   },
   "source": [
    "## 3.1 Sele√ß√£o dos Dados <a class=\"anchor\" id=\"selecao-dados\"></a>\n",
    "\n",
    "Nesta etapa inicial da **Prepara√ß√£o dos Dados**, realizamos a sele√ß√£o criteriosa das vari√°veis mais relevantes para o problema de predi√ß√£o do **valor l√≠quido da despesa parlamentar (`vlrLiquido`)**.\n",
    "\n",
    "O objetivo √© filtrar os dados brutos e manter somente as informa√ß√µes que possuem **rela√ß√£o direta com o comportamento dos gastos parlamentares**, otimizando o desempenho dos algoritmos de machine learning.\n",
    "\n",
    "---\n",
    "\n",
    "#### üî∏ Crit√©rios de Sele√ß√£o\n",
    "\n",
    "Selecionamos as colunas que possuem potencial explicativo e que apresentam valor informacional para o modelo supervisionado. As vari√°veis escolhidas foram:\n",
    "\n",
    "- **`sgUF`**: unidade federativa, que pode refletir realidades regionais de gastos.\n",
    "- **`sgPartido`**: partido pol√≠tico, poss√≠vel fator explicativo para padr√µes de despesa.\n",
    "- **`txtDescricao`**: tipo de despesa (ex: alimenta√ß√£o, aluguel, combust√≠vel).\n",
    "- **`vlrDocumento`**: valor bruto do documento fiscal apresentado.\n",
    "- **`numMes` e `numAno`**: per√≠odo da despesa, para an√°lise sazonal ou temporal.\n",
    "- **`vlrLiquido`**: vari√°vel-alvo que ser√° predita pelo modelo.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDRfR6L8Qq2d"
   },
   "source": [
    "## 3.2 Limpeza dos Dados <a class=\"anchor\" id=\"limpeza-dados\"></a>\n",
    "\n",
    "\n",
    "Nesta etapa, realizamos uma s√©rie de a√ß√µes de limpeza para garantir que os dados utilizados nos modelos estejam consistentes, sem ru√≠dos e com alta qualidade informacional. A prepara√ß√£o adequada dos dados √© essencial para que qualquer modelo de aprendizado de m√°quina produza resultados confi√°veis.\n",
    "\n",
    "As a√ß√µes tomadas nesta fase incluem:\n",
    "\n",
    "---\n",
    "\n",
    "#### üî∏ Remo√ß√£o de Registros Inconsistentes\n",
    "\n",
    "Eliminamos os registros em que o valor l√≠quido (`vlrLiquido`) era superior ao valor bruto do documento (`vlrDocumento`). Essa inconsist√™ncia viola a l√≥gica financeira da base de dados e poderia comprometer an√°lises futuras. Esses registros foram identificados, quantificados e removidos de forma criteriosa.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove linhas onde vlrLiquido > vlrDocumento\n",
    "df_modelo = df_completo[df_completo['vlrLiquido'] <= df_completo['vlrDocumento']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### üî∏ Tratamento de Valores Negativos\n",
    "\n",
    "Foram identificados valores negativos na coluna `vlrLiquido` ‚Äî o que n√£o representa um cen√°rio v√°lido para gastos parlamentares. Esses valores estavam presentes em todas as bases de 2023, 2024 e 2025:\n",
    "\n",
    "- **2023:** 9.383 registros\n",
    "- **2024:** 10.327 registros\n",
    "- **2025:** 2.626 registros\n",
    "\n",
    "Todos foram removidos ap√≥s verifica√ß√£o e exibi√ß√£o de amostras por ano. A limpeza foi validada com uma checagem final, confirmando que **nenhum valor negativo permaneceu**.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove registros onde vlrLiquido √© negativo\n",
    "df_modelo = df_modelo[df_modelo['vlrLiquido'] >= 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### üî∏ Elimina√ß√£o de Registros com Valores Ausentes (NaN)\n",
    "\n",
    "Ap√≥s a sele√ß√£o e transforma√ß√£o das colunas relevantes, identificamos **2.135 registros com valores ausentes**, totalizando **4.270 c√©lulas com `NaN`**. Esses dados foram descartados para evitar vi√©s no processo de modelagem, uma vez que a imputa√ß√£o poderia comprometer a acur√°cia dos modelos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove registros onde a coluna 'sgUF' possui valores nulos (NaN)\n",
    "df_modelo = df_modelo[df_modelo['sgUF'].notnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove registros onde a coluna 'sgPartido' possui valores nulos (NaN)\n",
    "df_modelo = df_modelo[df_modelo['sgPartido'].notnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### üî∏ Remo√ß√£o de Registros Duplicados\n",
    "\n",
    "Realizamos a verifica√ß√£o de duplicatas no conjunto de dados e removemos entradas repetidas para garantir que cada linha representasse uma observa√ß√£o √∫nica. Essa pr√°tica evita sobrepeso em certas categorias e garante imparcialidade nas an√°lises estat√≠sticas.\n",
    "\n",
    "**Na base tratado n√£o h√° registros duplicados**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### üî∏ Remo√ß√£o de Colunas Desnecess√°rias\n",
    "\n",
    "Foram exclu√≠das colunas que n√£o contribu√≠am para os objetivos do projeto, como identificadores √∫nicos (`CPF`, `CNPJ`, c√≥digos legislativos), atributos com alta cardinalidade ou informa√ß√µes redundantes. Essa etapa reduziu a complexidade do modelo e aumentou a interpretabilidade.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mant√©m apenas as colunas desejadas em df_modelo\n",
    "colunas_desejadas = ['sgUF', 'sgPartido', 'txtDescricao', 'numMes', 'numAno', 'vlrLiquido']\n",
    "df_modelo = df_modelo[colunas_desejadas].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### üî∏ Agrega√ß√£o atrav√©s da soma do vlrLiquido\n",
    "\n",
    "Agrega√ß√£o atrav√©s da soma do vlrLiquido, classificado pelos demais campos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um novo DataFrame agregando pela soma do vlrLiquido\n",
    "df_modelo = (\n",
    "    df_modelo\n",
    "    .groupby(['sgUF', 'sgPartido', 'txtDescricao', 'numMes', 'numAno'], as_index=False)\n",
    "    .agg(vlrLiquidoTotal=('vlrLiquido', 'sum'))\n",
    ")\n",
    "\n",
    "# Exibe as primeiras linhas do novo DataFrame\n",
    "display(df_modelo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "###  Resultado Final\n",
    "\n",
    "Ap√≥s todas as etapas de limpeza, o novo DataFrame final (`df_modelo`) apresenta:\n",
    "\n",
    "- **518.987 registros**\n",
    "- **6 colunas relevantes**\n",
    "- Nenhum valor `NaN` ou negativo\n",
    "- Dados prontos para modelagem supervisionada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "####  Amostra dos dados tratados:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Nesta etapa, realizamos um processo criterioso de saneamento da base de dados, com o objetivo de **garantir a integridade, consist√™ncia e confiabilidade das informa√ß√µes** que alimentar√£o os modelos de aprendizado supervisionado.\n",
    "\n",
    "A limpeza dos dados √© uma fase cr√≠tica, pois **modelos de Machine Learning s√£o altamente sens√≠veis a ru√≠dos, valores inv√°lidos e informa√ß√µes incompletas**. Um dado inconsistente pode comprometer toda a performance do modelo ‚Äî e pior, gerar conclus√µes enganosas para decis√µes reais.\n",
    "\n",
    "### A√ß√µes realizadas:\n",
    "\n",
    "1. **Remo√ß√£o de valores negativos em `vlrLiquido`:**  \n",
    "   Foram detectados e eliminados milhares de registros com valores negativos, o que representa **erros claros de entrada de dados**. Como o `vlrLiquido` representa o valor final pago em uma despesa, n√£o √© plaus√≠vel que ele seja negativo.\n",
    "\n",
    "2. **Elimina√ß√£o de registros com `vlrLiquido` maior que `vlrDocumento`:**  \n",
    "   Foram identificados **2 registros** em que o valor l√≠quido ultrapassava o valor bruto do documento, o que √© logicamente incorreto. Esses registros foram removidos.\n",
    "\n",
    "3. **Remo√ß√£o de valores ausentes (`NaN`)**  \n",
    "   Ap√≥s as transforma√ß√µes e constru√ß√µes de vari√°veis, foram encontrados **2.135 registros com valores ausentes** em colunas relevantes. Esses registros foram removidos para **evitar vi√©s nos algoritmos de predi√ß√£o** e assegurar que todas as vari√°veis estejam completas.\n",
    "\n",
    "4. **Exclus√£o de colunas irrelevantes ao modelo:**  \n",
    "   Diversas colunas foram descartadas por n√£o contribu√≠rem para a modelagem ou por conterem informa√ß√µes sens√≠veis e desnecess√°rias (como CPF, CNPJ, c√≥digos internos da C√¢mara, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "### Benef√≠cios diretos dessa etapa:\n",
    "\n",
    "- **Redu√ß√£o de ru√≠dos** que impactariam negativamente na acur√°cia dos modelos.\n",
    "- **Evita o overfitting** com dados duplicados ou corrompidos.\n",
    "- **Aumenta a confiabilidade das previs√µes**, ao garantir que os dados sigam uma l√≥gica de neg√≥cios clara.\n",
    "- **Permite extra√ß√£o de insights mais precisos**, facilitando compara√ß√µes, agrupamentos e an√°lises de tend√™ncia.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. An√°lise Explorat√≥ria dos Dados (EDA) <a class=\"anchor\" id=\"analise-dados\"></a>\n",
    "\n",
    "A fase de An√°lise Explorat√≥ria de Dados (EDA) √© crucial para aprofundar nosso entendimento sobre as despesas parlamentares. O objetivo aqui √© utilizar visualiza√ß√µes e estat√≠sticas para descobrir padr√µes, identificar anomalias e responder √†s quest√µes explorat√≥rias que levantamos na primeira fase do projeto.\n",
    "Para conduzir esta an√°lise de forma estruturada, seguiremos um caminho que vai do geral ao espec√≠fico, dividido em tr√™s abordagens principais:\n",
    "\n",
    "1.  **Vis√£o Agregada dos Gastos:** Iniciaremos com uma vis√£o macro, utilizando gr√°ficos de barras para identificar os principais atores e fatores de custo. Analisaremos os totais e m√©dias de gastos para responder a perguntas como:\n",
    "    * Quais parlamentares acumularam os maiores custos?\n",
    "\n",
    "    * Quais UFs e Partidos concentram o maior volume financeiro?\n",
    "    * Quais tipos de despesa possuem o maior valor m√©dio por transa√ß√£o?\n",
    "\n",
    "2.  **An√°lise da Distribui√ß√£o dos Valores:** Em seguida, vamos al√©m dos totais e m√©dias. Com o uso de boxplots, investigaremos a **distribui√ß√£o** dos valores de despesa (`vlrLiquido`) dentro das principais categorias (Partido e UF). Isso nos ajudar√° a entender a variabilidade, a mediana dos gastos e a presen√ßa de valores discrepantes em cada grupo.\n",
    "\n",
    "3.  **An√°lise de Perfil Espec√≠fico (Drill-Down):** Por fim, faremos uma an√°lise de \"drill-down\", focando em um insight espec√≠fico obtido na primeira etapa. Vamos isolar o parlamentar com o maior gasto acumulado e investigar em detalhe o seu perfil de despesas, entendendo quais s√£o suas categorias mais frequentes.\n",
    "\n",
    "Ao final desta se√ß√£o, teremos um conjunto de insights visuais que n√£o apenas respondem √†s nossas quest√µes, mas tamb√©m fornecem uma base s√≥lida para as decis√µes que tomaremos na etapa de **Modelagem**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **An√°lise das Principais Dimens√µes de Gasto**\n",
    "\n",
    "\n",
    "### 1Ô∏è - Top 5 Parlamentares por Custo Total\n",
    "> **O que mostra:** Os parlamentares com maior volume de gastos no per√≠odo analisado.  \n",
    "> **Insight:** Permite identificar concentra√ß√µes de gastos por indiv√≠duo e investigar comportamentos fora do padr√£o.\n",
    "\n",
    "### 2Ô∏è - Top 10 UFs por Gastos\n",
    "> **O que mostra:** Os estados da federa√ß√£o com maior soma de despesas parlamentares.  \n",
    "> **Insight:** Auxilia a visualizar a distribui√ß√£o geogr√°fica dos gastos.\n",
    "\n",
    "### 3Ô∏è - Top 10 Partidos por Gastos\n",
    "> **O que mostra:** Os partidos pol√≠ticos com maiores gastos m√©dios agregados.  \n",
    "> **Insight:** Pode revelar padr√µes partid√°rios nos gastos, com poss√≠veis implica√ß√µes pol√≠ticas.\n",
    "\n",
    "### 4Ô∏è - Tipos de Despesa com Maior Valor M√©dio\n",
    "> **O que mostra:** Quais tipos de despesa apresentam maior m√©dia de valores reembolsados.  \n",
    "> **Insight:** Ajuda a identificar os tipos de gastos mais onerosos, que podem demandar auditoria ou justificativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√≥digo para visualiza√ß√µes agregadas com Plotly\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "# Define um template padr√£o para o Plotly\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "# Fun√ß√£o para formatar como R$ com ponto de milhar e v√≠rgula decimal\n",
    "def formatar_valor(valor):\n",
    "# Garante que est√° lidando com o DataFrame correto\n",
    "    return f\"R$ {valor:,.2f}\".replace(\",\", \"X\").replace(\".\", \",\").replace(\"X\", \".\")\n",
    "\n",
    "# 2Ô∏è Top 10 UFs por Gasto Total\n",
    "top_ufs = (\n",
    "    df_modelo.groupby('sgUF')['vlrLiquidoTotal']\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .reset_index()\n",
    ")\n",
    "top_ufs['texto'] = top_ufs['vlrLiquidoTotal'].apply(formatar_valor)\n",
    "\n",
    "fig2 = px.bar(\n",
    "    top_ufs,\n",
    "    x='sgUF',\n",
    "    y='vlrLiquidoTotal',\n",
    "    orientation='v',\n",
    "    title='<b>UFs por Gastos Totais</b>',\n",
    "    labels={'vlrLiquidoTotal': 'Gasto Total (R$)', 'sgUF': 'UF'},\n",
    "    text='texto'\n",
    ")\n",
    "fig2.update_layout(showlegend=False, yaxis={'categoryorder':'total ascending'})\n",
    "fig2.update_traces(textposition='outside', marker_color='#EF553B')\n",
    "\n",
    "\n",
    "# 3Ô∏è Top 10 Partidos por Gasto Total\n",
    "top_partidos = (\n",
    "    df_modelo.groupby('sgPartido')['vlrLiquidoTotal']\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .reset_index()\n",
    ")\n",
    "top_partidos['texto'] = top_partidos['vlrLiquidoTotal'].apply(formatar_valor)\n",
    "\n",
    "fig3 = px.bar(\n",
    "    top_partidos,\n",
    "    x='sgPartido',\n",
    "    y='vlrLiquidoTotal',\n",
    "    orientation='v',\n",
    "    title='<b>Partidos por Gastos Totais</b>',\n",
    "    labels={'vlrLiquidoTotal': 'Gasto Total (R$)', 'sgPartido': 'Partido'},\n",
    "    text='texto'\n",
    ")\n",
    "fig3.update_layout(showlegend=False, yaxis={'categoryorder':'total ascending'})\n",
    "fig3.update_traces(textposition='outside', marker_color='#00CC96')\n",
    "\n",
    "\n",
    "# 4Ô∏è Top 10 Tipos de Despesa por Valor M√©dio\n",
    "top_tipos = (\n",
    "    df_modelo.groupby('txtDescricao')['vlrLiquidoTotal']\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .reset_index()\n",
    ")\n",
    "top_tipos['texto'] = top_tipos['vlrLiquidoTotal'].apply(formatar_valor)\n",
    "\n",
    "fig4 = px.bar(\n",
    "    top_tipos,\n",
    "    x='txtDescricao',\n",
    "    y='vlrLiquidoTotal',\n",
    "    orientation='v',\n",
    "    title='<b>Tipos de Despesa com Maior Valor M√©dio por Transa√ß√£o</b>',\n",
    "    labels={'vlrLiquidoTotal': 'Valor M√©dio (R$)', 'txtDescricao': 'Tipo de Despesa'},\n",
    "    text='texto'\n",
    ")\n",
    "fig4.update_layout(showlegend=False, yaxis={'categoryorder':'total ascending'})\n",
    "fig4.update_traces(textposition='outside', marker_color='#AB63FA')\n",
    "\n",
    "\n",
    "# Exibir os gr√°ficos\n",
    "fig2.show()\n",
    "fig3.show()\n",
    "fig4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvEceHzUQq2j"
   },
   "source": [
    "# 5. Modelagem <a class=\"anchor\" id=\"modelagem\"></a>\n",
    "As the first step in modelling, you'll select the actual modelling technique that you'll be using. Although you may have already selected a tool during the business understanding phase, at this stage you'll be selecting the specific modelling technique e.g. decision-tree building with C5.0, or neural network generation with back propagation. If multiple techniques are applied, perform this task separately for each technique.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9H-GXDBNQq2j"
   },
   "source": [
    "## 5.1. T√©cnicas de Modelagem <a class=\"anchor\" id=\"tecnicas-modelagem\"></a>\n",
    "Document the actual modelling technique that is to be used.\n",
    "\n",
    "Import Models below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "nhhwoVkVQq2k"
   },
   "outputs": [],
   "source": [
    "X = df.drop('y', axis=1)\n",
    "y = df['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uFK8exaK-68S"
   },
   "outputs": [],
   "source": [
    "# Normaliza√ß√£o dos dados num√©ricos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "categorical_features = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
    "numeric_features = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8ClvOxXQq2k"
   },
   "source": [
    "## 5.2. Teste de Modelos <a class=\"anchor\" id=\"teste-modelos\"></a>\n",
    "Many modelling techniques make specific assumptions about the data, for example that all attributes have uniform distributions, no missing values allowed, class attribute must be symbolic etc. Record any assumptions made.\n",
    "\n",
    "-\n",
    "-\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUz08h6RBC1a"
   },
   "outputs": [],
   "source": [
    "pipeline_lr = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(C=1.0, solver='liblinear'))\n",
    "])\n",
    "\n",
    "pipeline_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2))\n",
    "])\n",
    "\n",
    "pipeline_gb = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQFDFtQoQq2k"
   },
   "source": [
    "## 5.3. Constru√ß√£o do Modelo (Build) <a class=\"anchor\" id=\"construcao-modelo\"></a>\n",
    "Run the modelling tool on the prepared dataset to create one or more models.\n",
    "\n",
    "**Parameter settings** - With any modelling tool there are often a large number of parameters that can be adjusted. List the parameters and their chosen values, along with the rationale for the choice of parameter settings.\n",
    "\n",
    "**Models** - These are the actual models produced by the modelling tool, not a report on the models.\n",
    "\n",
    "**Model descriptions** - Describe the resulting models, report on the interpretation of the models and document any difficulties encountered with their meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192
    },
    "collapsed": true,
    "id": "JFUvxZVmQq2k",
    "outputId": "418627bc-a187-4460-b50f-bf8f876e8e59"
   },
   "outputs": [],
   "source": [
    "pipeline_lr.fit(X_train, y_train)\n",
    "pipeline_rf.fit(X_train, y_train)\n",
    "pipeline_gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZL6W-w7YQq2k"
   },
   "source": [
    "## 5.4. Avalia√ß√£o de Performance <a class=\"anchor\" id=\"avaliacao-modelo\"></a>\n",
    "Interpret the models according to your domain knowledge, your data mining success criteria and your desired test design. Judge the success of the application of modelling and discovery techniques technically, then contact business analysts and domain experts later in order to discuss the data mining results in the business context. This task only considers models, whereas the evaluation phase also takes into account all other results that were produced in the course of the project.\n",
    "\n",
    "At this stage you should rank the models and assess them according to the evaluation criteria. You should take the business objectives and business success criteria into account as far as you can here. In most data mining projects a single technique is applied more than once and data mining results are generated with several different techniques.\n",
    "\n",
    "**Model assessment** - Summarise the results of this task, list the qualities of your generated models (e.g.in terms of accuracy) and rank their quality in relation to each other.\n",
    "\n",
    "**Revised parameter settings** - According to the model assessment, revise parameter settings and tune them for the next modelling run. Iterate model building and assessment until you strongly believe that you have found the best model(s). Document all such revisions and assessments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U1YFLClIQq2k",
    "outputId": "bfdbddad-824f-4a40-96cb-6cec08c7cb7d"
   },
   "outputs": [],
   "source": [
    "model_metrics = {}\n",
    "\n",
    "# Lista de modelos para avaliar\n",
    "models = ['lr', 'rf', 'gb']\n",
    "\n",
    "for model_key in models:\n",
    "    try:\n",
    "        pipelines[model_key].fit(X_train, y_train)\n",
    "\n",
    "        y_pred = pipelines[model_key].predict(X_test)\n",
    "        y_proba = pipelines[model_key].predict_proba(X_test)[:, 1]  # Probabilidades para AUC-ROC\n",
    "\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        auc_roc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "        model_metrics[model_key] = {\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1-Score': f1,\n",
    "            'AUC-ROC': auc_roc\n",
    "        }\n",
    "\n",
    "        print(f\"Resultados para {model_key}:\")\n",
    "        print(f\"Precis√£o: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1-Score: {f1:.4f}\")\n",
    "        print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "        print(\"-----\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao treinar ou avaliar o modelo {model_key}: {e}\")\n",
    "\n",
    "for model_key in models:\n",
    "    try:\n",
    "        y_pred = pipelines[model_key].predict(X_test)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        print(f\"Matriz de Confus√£o para {model_key}:\")\n",
    "        print(cm)\n",
    "        print(\"-----\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao gerar matriz de confus√£o para {model_key}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Avalia√ß√£o do Modelo <a class=\"anchor\" id=\"avaliacao-modelo\"></a>\n",
    "\n",
    "## 6.1. Regress√£o Log√≠stica (lr): <a class=\"anchor\" id=\"regressao-logistica\"></a>\n",
    "\n",
    "Precis√£o: 69.26% - Este modelo tem uma boa taxa de precis√£o, indicando que quando prev√™ que um cliente se inscrever√°, est√° correto aproximadamente 69.26% das vezes.\n",
    "Recall: 40.30% - Capta 40.30% dos casos positivos reais, o que √© moderado.\n",
    "F1-Score: 50.95% - Um equil√≠brio razo√°vel entre precis√£o e recall.\n",
    "AUC-ROC: 92.92% - Excelente capacidade de discrimina√ß√£o entre as classes positivas e negativas.\n",
    "Matriz de Confus√£o: Com um n√∫mero relativamente baixo de falsos positivos (83) e uma quantidade moderada de falsos negativos (277).\n",
    "Random Forest (rf):\n",
    "\n",
    "Precis√£o: 65.06% - Ligeiramente inferior √† regress√£o log√≠stica em termos de precis√£o.\n",
    "Recall: 37.72% - Menor do que a regress√£o log√≠stica, indicando uma capacidade mais fraca de capturar todos os positivos reais.\n",
    "F1-Score: 47.75% - Reflete o compromisso entre precis√£o e recall inferior ao da regress√£o log√≠stica.\n",
    "AUC-ROC: 92.58% - Muito boa, mas ligeiramente inferior √† regress√£o log√≠stica.\n",
    "Matriz de Confus√£o: Mais falsos positivos (94) e falsos negativos (289) do que a regress√£o log√≠stica, indicando uma efici√™ncia geral mais baixa.\n",
    "Gradient Boosting (gb):\n",
    "\n",
    "Precis√£o: 69.42% - Similar √† regress√£o log√≠stica e ligeiramente superior ao Random Forest.\n",
    "Recall: 41.59% - O melhor recall dos tr√™s modelos, capturando uma propor√ß√£o maior de casos positivos.\n",
    "F1-Score: 52.02% - O melhor F1-Score, indicando o melhor equil√≠brio entre precis√£o e recall.\n",
    "AUC-ROC: 93.58% - A melhor das tr√™s, mostrando a superioridade do Gradient Boosting em discriminar entre as classes.\n",
    "Matriz de Confus√£o: Semelhante ao Random Forest em termos de falsos positivos, mas com menos falsos negativos, melhorando tanto a precis√£o quanto o recall.\n",
    "Conclus√µes e Recomenda√ß√µes\n",
    "Gradient Boosting parece ser o modelo mais forte em geral, apresentando o melhor equil√≠brio entre todas as m√©tricas. Com a maior AUC-ROC e o melhor F1-Score, ele demonstra uma capacidade superior de manejar a classifica√ß√£o de uma maneira equilibrada, tornando-o ideal para situa√ß√µes onde tanto a precis√£o quanto o recall s√£o importantes.\n",
    "\n",
    "Regress√£o Log√≠stica ainda se mostra uma op√ß√£o vi√°vel, especialmente se a interpretabilidade do modelo √© uma prioridade, visto que modelos lineares como este oferecem insights mais diretos sobre como as caracter√≠sticas est√£o influenciando as previs√µes.\n",
    "\n",
    "Random Forest, embora robusto e com um bom desempenho geral, parece ser ligeiramente superado pelos outros modelos em termos de m√©tricas chave neste cen√°rio espec√≠fico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Aplica√ß√£o pr√°tica (Deployment)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
