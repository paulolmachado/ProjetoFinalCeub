{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTNXidF3Qq2K"
   },
   "source": [
    "# **Ciência de Dados e Machine Learning**\n",
    "\n",
    "## **Projeto Final do Curso**\n",
    "\n",
    "---\n",
    "\n",
    "### **Alunos:**\n",
    "\n",
    "> Charles Bezerra - 52400351\n",
    "\n",
    "> Jheferson Warley - 52400071\n",
    "\n",
    "> Paulo Machado - 52400245\n",
    "\n",
    "---\n",
    "\n",
    "### Tema: **Despesas pela Cota para Exercício da Atividade Parlamentar**\n",
    "\n",
    "### Base de Dados: https://dadosabertos.camara.leg.br/swagger/api.html?tab=staticfile\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RfgYroaQq2N"
   },
   "source": [
    "Este projeto final do curso de **Ciência de Dados e Machine** Learning do UniCEUB se baseia na metodologia *Cross-Industry Standard Process for Data Mining - CRISP-DM* (https://www.sv-europe.com/crisp-dm-methodology/), oferecendo uma abordagem estruturada para planejar um projeto de mineração de dados de uma forma robusta.\n",
    "\n",
    "Este modelo representa uma sequência idealizada de eventos. Na prática, muitas das tarefas podem ser realizadas em uma ordem diferente, e frequentemente será necessário voltar a tarefas anteriores e repetir certas ações.\n",
    "\n",
    "<div>\n",
    "<img src=\"FasesCRISP-DM.png\" width=\"50%\">\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjrc0DUFQq2O"
   },
   "source": [
    "## **Etapas do Processo CRISP-DM**\n",
    "\n",
    "### 1. [Entendimento do Negócio](#business-understanding)\n",
    "Compreensão dos objetivos de negócio, contexto organizacional e definição das metas analíticas.\n",
    "\n",
    "- [1.1 Avaliação da Situação Atual](#avaliacao-da-situacao)\n",
    "- [1.2 Resultados Esperados](#resultados-esperados)\n",
    "- [1.3 Questões de Pesquisa](#questoes-de-pesquisa)\n",
    "<!-- - [1.4 Plano de Projeto](#plano-do-projeto) -->\n",
    "\n",
    "---\n",
    "\n",
    "### 2. [Entendimento dos Dados](#entendimento-dados)\n",
    "Exploração inicial dos dados, coleta e verificação da qualidade.\n",
    "\n",
    "- [2.1 Relatorio Inicial](#relatorio-inicial)\n",
    "- [2.2 Descrição dos Dados](#descricao-dados)\n",
    "- [2.3 Exploração dos Dados](#exploracao-dados)\n",
    "- [2.4 Verificação da Qualidade dos Dados](#qualidade-dos-dados)\n",
    "\n",
    "---\n",
    "\n",
    "### 3. [Preparação dos Dados](#preparacao-dados)\n",
    "Construção do dataset final que será utilizado para modelagem.\n",
    "\n",
    "- [3.1 Seleção dos Dados](#selecao-dados)\n",
    "- [3.2 Limpeza dos Dados](#limpeza-dados)\n",
    "- [3.3 Construção de Dados Derivados](#dados-derivados)\n",
    "- [3.4 Integração de Dados](#integracao-dados)\n",
    "- [3.5 Análise Exploratória de Dados](#analise-dados)\n",
    "\n",
    "---\n",
    "\n",
    "### 4. [Modelagem](#modelagem)\n",
    "Aplicação de técnicas de modelagem estatística ou de machine learning.\n",
    "\n",
    "- [5.1 Técnicas de Modelagem](#tecnicas-modelagem)\n",
    "- [5.2 Teste de Modelos](#teste-modelos)\n",
    "- [5.3 Construção dos Modelos](#construcao-modelo)\n",
    "- [5.4 Avaliação de Performance](#avaliacao-modelo)\n",
    "\n",
    "---\n",
    "\n",
    "### 5. [Avaliação](#avaliacao-modelo)\n",
    "Verificação se o modelo atende os objetivos de negócio definidos.\n",
    "\n",
    "- [6.1 Regressão Logística](#regressao-logistica)\n",
    "- [6.2 Revisão do Processo](#revisao-processo)\n",
    "- [6.3 Determinação dos Próximos Passos](#proximos-passos)\n",
    "\n",
    "---\n",
    "\n",
    "### 6. [Implementação (Deployment)](#implementacao)\n",
    "Entrega prática do modelo, seja em relatório, dashboard, sistema ou API.\n",
    "\n",
    "- [6.1 Planejamento da Implementação](#planejamento-implementacao)\n",
    "- [6.2 Monitoramento e Manutenção](#monitoramento)\n",
    "- [6.3 Documentação Final](#documentacao-final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pdYJHP76Qq2O"
   },
   "source": [
    "## 1. Entendimento do Negócio  <a class=\"anchor\" id=\"business-understanding\"></a>\n",
    "\n",
    "Atualmente, o cenário político brasileiro se mostra em foco, principalmente quando se trata de despesas relacionadas à sustentação do governo como todo. Neste contexto, as despesas parlamentares, limitadas por uma cota, são frequentemente noticiadas devido a seu alto custo. As cotas parlamentares variam conforme o estado do deputado e é destinado ao custeio de despesas relacionadas ao exercício do mandato. As despesas incluem passagens aéreas, locomoção, hospedagens, serviços de segurança, divulgação de atividades parlamentares e contratação de pessoal.\n",
    "\n",
    "\n",
    "A Câmara dos Deputados divulga através da plataforma de dados abertos do governo (https://dadosabertos.camara.leg.br/swagger/api.html?tab=staticfile) as despesas refentes ao consumo de cotas separadas por ano, Deputado, UF, tipo de despesas, entre outras classificações. Os arquivos podem ser baixador por ano, disponíveis desde o ano 2018, nos formatos XML, JSON, CSV, XLSX e ODS.\n",
    "\n",
    "\n",
    "Para este projeto, selecionamos os dados relativos ao ano de 2024 (ano completo mais recente) com arquivos no formato CSV para melhor tratamento dos dados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2SqAlWIyQq2P"
   },
   "source": [
    "## 1.1 Avaliação da Situação Atual<a class=\"anchor\" id=\"avaliacao-da-situacao\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFsmtXzxQq2P"
   },
   "source": [
    "A transparência nos gastos públicos tem ganhado relevância nos debates sociais e institucionais, principalmente no contexto político brasileiro. A Câmara dos Deputados disponibiliza, por meio do portal de Dados Abertos, informações detalhadas sobre a utilização da Cota para o Exercício da Atividade Parlamentar (CEAP), que contempla diversos tipos de despesas efetuadas pelos parlamentares no desempenho de suas funções.\n",
    "\n",
    "Apesar da disponibilidade dos dados, observa-se uma subutilização dessas informações por parte da sociedade civil e dos órgãos fiscalizadores. O volume e a complexidade dos dados dificultam análises diretas e conclusivas, exigindo ferramentas adequadas de tratamento, análise e visualização. Diante disso, este projeto visa utilizar técnicas de análise de dados e aprendizado de máquina para transformar os dados brutos em insights relevantes e acessíveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWxWA-87Qq2P"
   },
   "source": [
    "## 1.2 Resultados Esperados<a class=\"anchor\" id=\"resultaods-esperados\"></a>\n",
    "\n",
    "Este projeto tem como objetivo geral analisar os gastos parlamentares por meio da base de dados da CEAP, abrangendo os anos de 2023, 2024 e 2025. Os resultados esperados incluem:\n",
    "\n",
    "- Desenvolvimento de relatórios e dashboards analíticos para visualização dos dados por deputado, partido político, unidade federativa (UF), tipo de despesa, fornecedor e período (mês e ano).\n",
    "- Análises estatísticas descritivas e comparativas, a fim de identificar padrões de gastos e variações relevantes entre diferentes grupos.\n",
    "- Detecção de anomalias e possíveis irregularidades nos registros de despesas.\n",
    "- Aplicação de técnicas de aprendizado de máquina (Machine Learning) com o objetivo de construir modelos preditivos capazes de estimar os gastos parlamentares futuros por partido ou UF, com base nos dados históricos.\n",
    "\n",
    "O projeto segue a metodologia CRISP-DM, com foco na reprodutibilidade dos resultados e na criação de documentação clara e acessível."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Questões de Pesquisa<a class=\"anchor\" id=\"questoes-de-pesquisa\"></a>\n",
    "\n",
    "O projeto é orientado por um conjunto de questões exploratórias e preditivas, que servirão como guia para as etapas analíticas e de modelagem.\n",
    "\n",
    "### Questões Exploratórias\n",
    "\n",
    "- Quais partidos políticos apresentaram os maiores volumes de gasto no período analisado?\n",
    "- Quais unidades federativas concentram os maiores gastos?\n",
    "- Quais são os tipos de despesa mais recorrentes e qual seu impacto nos valores totais?\n",
    "- Como os gastos variam ao longo do tempo? Existe sazonalidade ou tendência?\n",
    "- Há fornecedores recorrentes nos maiores gastos? Qual seu perfil?\n",
    "\n",
    "### Questões Preditivas\n",
    "\n",
    "- É possível prever os gastos parlamentares futuros com base no histórico de dados?\n",
    "- Quais variáveis mais influenciam no volume de gastos (ex.: partido, UF, tipo de despesa, mês)?\n",
    "- Quais partidos ou unidades federativas têm maior propensão a apresentar aumentos nos gastos em futuros mandatos?\n",
    "\n",
    "Estas perguntas direcionam a construção dos indicadores, visualizações e modelos preditivos ao longo do projeto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4S-Y6p8VQq2R"
   },
   "source": [
    "# 2. Entendimento dos Dados <a class=\"anchor\" id=\"entendimento-dados\"></a>\n",
    "A etapa de entendimento dos dados tem como objetivo fornecer uma visão inicial e aprofundada da estrutura, conteúdo e qualidade do conjunto de dados disponível para análise. Trata-se de uma fase fundamental no processo analítico, pois permite identificar características importantes dos dados, potenciais inconsistências, ausência de valores e padrões que podem influenciar diretamente na preparação, modelagem e interpretação dos resultados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-6TQJ_4Qq2R"
   },
   "source": [
    "## 2.1 Relatório Inicial <a class=\"anchor\" id=\"relatorio-inicial\"></a>\n",
    "O conjunto de dados utilizado neste projeto refere-se às despesas parlamentares registradas na Cota para o Exercício da Atividade Parlamentar (CEAP), compreendendo os anos de 2023, 2024 e 2025. Os dados foram extraídos da API pública da Câmara dos Deputados, que disponibiliza os registros em diversos formatos. Para este trabalho, optou-se pelo formato `.csv`, considerando a facilidade de leitura e manipulação em ambientes Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "X9OlrvX3Qq2R"
   },
   "outputs": [],
   "source": [
    "# Importação das Bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "D85E5K77Qq2S"
   },
   "outputs": [],
   "source": [
    "# Leitura dos dados\n",
    "df_2023 = pd.read_csv(\"DataBase/Ano-2023.csv\", sep=\";\", encoding=\"utf-8\", low_memory=False)\n",
    "df_2024 = pd.read_csv(\"DataBase/Ano-2024.csv\", sep=\";\", encoding=\"utf-8\", low_memory=False)\n",
    "df_2025 = pd.read_csv(\"DataBase/Ano-2025.csv\", sep=\";\", encoding=\"utf-8\", low_memory=False)\n",
    "\n",
    "# Combinação dos três dataframes\n",
    "df_completo = pd.concat([df_2023, df_2024, df_2025], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibição das 5 primeiras linhas\n",
    "display(df_completo.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZ8n1_pnQq2T"
   },
   "source": [
    "## 2.2 Descrição dos Dados <a class=\"anchor\" id=\"descricao-dados\"></a>\n",
    "A seguir, são apresentados o nome das colunas disponíveis no dataset e o seu formato dimensional (linhas x colunas).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A tabela abaixo apresenta a descrição de cada uma das variáveis disponíveis no conjunto de dados utilizado.\n",
    "\n",
    "| Nome da Coluna                 | Descrição                                                        |\n",
    "|-------------------------------|------------------------------------------------------------------|\n",
    "| `txNomeParlamentar`           | Nome do parlamentar                                              |\n",
    "| `cpf`                         | CPF do parlamentar (quando disponível)                          |\n",
    "| `ideCadastro`                 | ID único do parlamentar                                          |\n",
    "| `nuCarteiraParlamentar`       | Número da carteira parlamentar                                   |\n",
    "| `nuLegislatura`               | Número da legislatura em exercício                               |\n",
    "| `sgUF`                        | Unidade Federativa (estado)                                      |\n",
    "| `sgPartido`                   | Sigla do partido político                                        |\n",
    "| `codLegislatura`              | Código da legislatura                                            |\n",
    "| `numSubCota`                  | Código da subcota utilizada                                      |\n",
    "| `txtDescricao`                | Descrição da subcota                                             |\n",
    "| `numEspecificacaoSubCota`     | Código da especificação da subcota                               |\n",
    "| `txtDescricaoEspecificacao`   | Descrição detalhada da subcota                                   |\n",
    "| `txtFornecedor`               | Nome do fornecedor                                               |\n",
    "| `txtCNPJCPF`                  | CNPJ ou CPF do fornecedor                                        |\n",
    "| `txtNumero`                   | Número do documento fiscal                                       |\n",
    "| `indTipoDocumento`            | Tipo do documento (nota fiscal, recibo, etc.)                   |\n",
    "| `datEmissao`                  | Data de emissão do documento                                     |\n",
    "| `vlrDocumento`                | Valor bruto do documento                                         |\n",
    "| `vlrGlosa`                    | Valor glosado/desconsiderado                                     |\n",
    "| `vlrLiquido`                  | Valor líquido aceito                                             |\n",
    "| `numMes`                      | Mês de referência da despesa                                     |\n",
    "| `numAno`                      | Ano de referência da despesa                                     |\n",
    "| `numParcela`                  | Número da parcela, quando aplicável                              |\n",
    "| `txtPassageiro`               | Nome do passageiro (se transporte aéreo)                         |\n",
    "| `txtTrecho`                   | Trecho da viagem (ida/volta)                                     |\n",
    "| `numLote`                     | Número do lote do documento                                      |\n",
    "| `numRessarcimento`            | Número de protocolo de ressarcimento                             |\n",
    "| `datPagamentoRestituicao`     | Data do pagamento de restituição                                 |\n",
    "| `vlrRestituicao`              | Valor restituído                                                 |\n",
    "| `nuDeputadoId`                | ID único do deputado                                             |\n",
    "| `ideDocumento`                | ID do documento                                                  |\n",
    "| `urlDocumento`                | Link para o documento oficial                                    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EemJ6DTeQq2U",
    "outputId": "7aa11b1f-b976-4a2a-f622-bab9cffdd1a7"
   },
   "outputs": [],
   "source": [
    "# Nomes das colunas\n",
    "df_completo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gnj33OcMQq2U",
    "outputId": "02529b54-4038-461c-f231-2ba7e0018cc2"
   },
   "outputs": [],
   "source": [
    "# Dimensão do dataframe\n",
    "df_completo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNxTQwN_Qq2V"
   },
   "source": [
    "## 2.3 Exploração dos Dados <a class=\"anchor\" id=\"exploracao-dados\"></a>\n",
    "\n",
    "Essa etapa visa obter uma visão geral das características dos dados, incluindo tipos de variáveis, estatísticas descritivas e primeiros insights de distribuição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TwiVpT8FQq2W",
    "outputId": "ac44ac23-9621-40c0-a32a-61b7199f4960"
   },
   "outputs": [],
   "source": [
    "# Verificação de duplicatas\n",
    "df_completo.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatísticas descritivas\n",
    "df_completo.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatísticas descritivas\n",
    "df_completo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando valores nulos por coluna\n",
    "df_completo.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a quantidade de valores únicos em algumas colunas-chave\n",
    "print(\"UFs:\", df_completo['sgUF'].nunique())\n",
    "print(\"Partidos:\", df_completo['sgPartido'].nunique())\n",
    "print(\"Tipos de despesa:\", df_completo['txtDescricao'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição dos principais campos categóricos\n",
    "\n",
    "# UF\n",
    "uf_counts = df_completo['sgUF'].value_counts().reset_index()\n",
    "uf_counts.columns = ['UF', 'Total de Registros']\n",
    "display(Markdown(\"### Distribuição por Unidade Federativa\"))\n",
    "display(uf_counts)\n",
    "\n",
    "# Partido\n",
    "partido_counts = df_completo['sgPartido'].value_counts().reset_index()\n",
    "partido_counts.columns = ['Partido', 'Total de Registros']\n",
    "display(Markdown(\"### Distribuição por Partido\"))\n",
    "display(partido_counts)\n",
    "\n",
    "# Tipo de Despesa\n",
    "despesa_counts = df_completo['txtDescricao'].value_counts().reset_index()\n",
    "despesa_counts.columns = ['Tipo de Despesa', 'Total de Registros']\n",
    "display(Markdown(\"### Distribuição por Tipo de Despesa\"))\n",
    "display(despesa_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzPUggSjQq2c"
   },
   "source": [
    "## 2.4 Verificação da Qualidade dos Dados<a class=\"anchor\" id=\"qualidade-dos-dados\"></a>\n",
    "Abaixo está um resumo quantitativo da qualidade dos dados após a análise exploratória inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo geral do dataset\n",
    "resumo_geral = pd.DataFrame({\n",
    "    \"Indicador\": [\n",
    "        \"Total de registros\",\n",
    "        \"Total de variáveis (colunas)\",\n",
    "        \"Registros duplicados\",\n",
    "        \"Valores inconsistentes (vlrDocumento < vlrLiquido)\"\n",
    "    ],\n",
    "    \"Valor\": [\n",
    "        df_completo.shape[0],\n",
    "        df_completo.shape[1],\n",
    "        df_completo.duplicated().sum(),\n",
    "        (df_completo['vlrDocumento'] < df_completo['vlrLiquido']).sum()\n",
    "    ]\n",
    "})\n",
    "\n",
    "display(Markdown(\"### Resumo Geral da Base de Dados\"))\n",
    "display(resumo_geral)\n",
    "\n",
    "# Colunas com valores nulos\n",
    "nulls = df_completo.isnull().sum()\n",
    "nulls = nulls[nulls > 0].sort_values(ascending=False).reset_index()\n",
    "nulls.columns = ['Coluna', 'Valores Nulos']\n",
    "\n",
    "display(Markdown(\"### Colunas com Valores Ausentes\"))\n",
    "display(nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcL0DjOzQq2c"
   },
   "source": [
    "# 3. Preparação dos Dados <a class=\"anchor\" id=\"preparacao-dados\"></a>\n",
    "\n",
    "\n",
    "Nesta etapa, realizamos o tratamento necessário para transformar os dados brutos em uma base estruturada e adequada para aplicação de modelos de aprendizado supervisionado. As ações incluem: seleção e limpeza de dados, geração de atributos derivados e integração das bases históricas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQjMmUM5Qq2c"
   },
   "source": [
    "## 3.1 Seleção dos Dados <a class=\"anchor\" id=\"selecao-dados\"></a>\n",
    "\n",
    "Nesta etapa inicial da **Preparação dos Dados**, realizamos a seleção criteriosa das variáveis mais relevantes para o problema de predição do **valor líquido da despesa parlamentar (`vlrLiquido`)**.\n",
    "\n",
    "O objetivo é filtrar os dados brutos e manter somente as informações que possuem **relação direta com o comportamento dos gastos parlamentares**, otimizando o desempenho dos algoritmos de machine learning.\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔸 Critérios de Seleção\n",
    "\n",
    "Selecionamos as colunas que possuem potencial explicativo e que apresentam valor informacional para o modelo supervisionado. As variáveis escolhidas foram:\n",
    "\n",
    "- **`sgUF`**: unidade federativa, que pode refletir realidades regionais de gastos.\n",
    "- **`sgPartido`**: partido político, possível fator explicativo para padrões de despesa.\n",
    "- **`txtDescricao`**: tipo de despesa (ex: alimentação, aluguel, combustível).\n",
    "- **`vlrDocumento`**: valor bruto do documento fiscal apresentado.\n",
    "- **`numMes` e `numAno`**: período da despesa, para análise sazonal ou temporal.\n",
    "- **`vlrLiquido`**: variável-alvo que será predita pelo modelo.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDRfR6L8Qq2d"
   },
   "source": [
    "## 3.2 Limpeza dos Dados <a class=\"anchor\" id=\"limpeza-dados\"></a>\n",
    "\n",
    "\n",
    "Nesta etapa, realizamos uma série de ações de limpeza para garantir que os dados utilizados nos modelos estejam consistentes, sem ruídos e com alta qualidade informacional. A preparação adequada dos dados é essencial para que qualquer modelo de aprendizado de máquina produza resultados confiáveis.\n",
    "\n",
    "As ações tomadas nesta fase incluem:\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔸 Remoção de Registros Inconsistentes\n",
    "\n",
    "Eliminamos os registros em que o valor líquido (`vlrLiquido`) era superior ao valor bruto do documento (`vlrDocumento`). Essa inconsistência viola a lógica financeira da base de dados e poderia comprometer análises futuras. Esses registros foram identificados, quantificados e removidos de forma criteriosa.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove linhas onde vlrLiquido > vlrDocumento\n",
    "df_modelo = df_completo[df_completo['vlrLiquido'] <= df_completo['vlrDocumento']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 🔸 Tratamento de Valores Negativos\n",
    "\n",
    "Foram identificados valores negativos na coluna `vlrLiquido` — o que não representa um cenário válido para gastos parlamentares. Esses valores estavam presentes em todas as bases de 2023, 2024 e 2025:\n",
    "\n",
    "- **2023:** 9.383 registros\n",
    "- **2024:** 10.327 registros\n",
    "- **2025:** 2.626 registros\n",
    "\n",
    "Todos foram removidos após verificação e exibição de amostras por ano. A limpeza foi validada com uma checagem final, confirmando que **nenhum valor negativo permaneceu**.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove registros onde vlrLiquido é negativo\n",
    "df_modelo = df_modelo[df_modelo['vlrLiquido'] >= 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 🔸 Eliminação de Registros com Valores Ausentes (NaN)\n",
    "\n",
    "Após a seleção e transformação das colunas relevantes, identificamos **2.135 registros com valores ausentes**, totalizando **4.270 células com `NaN`**. Esses dados foram descartados para evitar viés no processo de modelagem, uma vez que a imputação poderia comprometer a acurácia dos modelos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove registros onde a coluna 'sgUF' possui valores nulos (NaN)\n",
    "df_modelo = df_modelo[df_modelo['sgUF'].notnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove registros onde a coluna 'sgPartido' possui valores nulos (NaN)\n",
    "df_modelo = df_modelo[df_modelo['sgPartido'].notnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 🔸 Remoção de Registros Duplicados\n",
    "\n",
    "Realizamos a verificação de duplicatas no conjunto de dados e removemos entradas repetidas para garantir que cada linha representasse uma observação única. Essa prática evita sobrepeso em certas categorias e garante imparcialidade nas análises estatísticas.\n",
    "\n",
    "**Na base tratado não há registros duplicados**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 🔸 Remoção de Colunas Desnecessárias\n",
    "\n",
    "Foram excluídas colunas que não contribuíam para os objetivos do projeto, como identificadores únicos (`CPF`, `CNPJ`, códigos legislativos), atributos com alta cardinalidade ou informações redundantes. Essa etapa reduziu a complexidade do modelo e aumentou a interpretabilidade.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mantém apenas as colunas desejadas em df_modelo\n",
    "colunas_desejadas = ['sgUF', 'sgPartido', 'txtDescricao', 'numMes', 'numAno', 'vlrLiquido']\n",
    "df_modelo = df_modelo[colunas_desejadas].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 🔸 Agregação através da soma do vlrLiquido\n",
    "\n",
    "Agregação através da soma do vlrLiquido, classificado pelos demais campos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um novo DataFrame agregando pela soma do vlrLiquido\n",
    "df_modelo = (\n",
    "    df_modelo\n",
    "    .groupby(['sgUF', 'sgPartido', 'txtDescricao', 'numMes', 'numAno'], as_index=False)\n",
    "    .agg(vlrLiquidoTotal=('vlrLiquido', 'sum'))\n",
    ")\n",
    "\n",
    "# Exibe as primeiras linhas do novo DataFrame\n",
    "display(df_modelo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "###  Resultado Final\n",
    "\n",
    "Após todas as etapas de limpeza, o novo DataFrame final (`df_modelo`) apresenta:\n",
    "\n",
    "- **518.987 registros**\n",
    "- **6 colunas relevantes**\n",
    "- Nenhum valor `NaN` ou negativo\n",
    "- Dados prontos para modelagem supervisionada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "####  Amostra dos dados tratados:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Nesta etapa, realizamos um processo criterioso de saneamento da base de dados, com o objetivo de **garantir a integridade, consistência e confiabilidade das informações** que alimentarão os modelos de aprendizado supervisionado.\n",
    "\n",
    "A limpeza dos dados é uma fase crítica, pois **modelos de Machine Learning são altamente sensíveis a ruídos, valores inválidos e informações incompletas**. Um dado inconsistente pode comprometer toda a performance do modelo — e pior, gerar conclusões enganosas para decisões reais.\n",
    "\n",
    "### Ações realizadas:\n",
    "\n",
    "1. **Remoção de valores negativos em `vlrLiquido`:**  \n",
    "   Foram detectados e eliminados milhares de registros com valores negativos, o que representa **erros claros de entrada de dados**. Como o `vlrLiquido` representa o valor final pago em uma despesa, não é plausível que ele seja negativo.\n",
    "\n",
    "2. **Eliminação de registros com `vlrLiquido` maior que `vlrDocumento`:**  \n",
    "   Foram identificados **2 registros** em que o valor líquido ultrapassava o valor bruto do documento, o que é logicamente incorreto. Esses registros foram removidos.\n",
    "\n",
    "3. **Remoção de valores ausentes (`NaN`)**  \n",
    "   Após as transformações e construções de variáveis, foram encontrados **2.135 registros com valores ausentes** em colunas relevantes. Esses registros foram removidos para **evitar viés nos algoritmos de predição** e assegurar que todas as variáveis estejam completas.\n",
    "\n",
    "4. **Exclusão de colunas irrelevantes ao modelo:**  \n",
    "   Diversas colunas foram descartadas por não contribuírem para a modelagem ou por conterem informações sensíveis e desnecessárias (como CPF, CNPJ, códigos internos da Câmara, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "### Benefícios diretos dessa etapa:\n",
    "\n",
    "- **Redução de ruídos** que impactariam negativamente na acurácia dos modelos.\n",
    "- **Evita o overfitting** com dados duplicados ou corrompidos.\n",
    "- **Aumenta a confiabilidade das previsões**, ao garantir que os dados sigam uma lógica de negócios clara.\n",
    "- **Permite extração de insights mais precisos**, facilitando comparações, agrupamentos e análises de tendência.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Análise Exploratória dos Dados (EDA) <a class=\"anchor\" id=\"analise-dados\"></a>\n",
    "\n",
    "A fase de Análise Exploratória de Dados (EDA) é crucial para aprofundar nosso entendimento sobre as despesas parlamentares. O objetivo aqui é utilizar visualizações e estatísticas para descobrir padrões, identificar anomalias e responder às questões exploratórias que levantamos na primeira fase do projeto.\n",
    "Para conduzir esta análise de forma estruturada, seguiremos um caminho que vai do geral ao específico, dividido em três abordagens principais:\n",
    "\n",
    "1.  **Visão Agregada dos Gastos:** Iniciaremos com uma visão macro, utilizando gráficos de barras para identificar os principais atores e fatores de custo. Analisaremos os totais e médias de gastos para responder a perguntas como:\n",
    "    * Quais parlamentares acumularam os maiores custos?\n",
    "\n",
    "    * Quais UFs e Partidos concentram o maior volume financeiro?\n",
    "    * Quais tipos de despesa possuem o maior valor médio por transação?\n",
    "\n",
    "2.  **Análise da Distribuição dos Valores:** Em seguida, vamos além dos totais e médias. Com o uso de boxplots, investigaremos a **distribuição** dos valores de despesa (`vlrLiquido`) dentro das principais categorias (Partido e UF). Isso nos ajudará a entender a variabilidade, a mediana dos gastos e a presença de valores discrepantes em cada grupo.\n",
    "\n",
    "3.  **Análise de Perfil Específico (Drill-Down):** Por fim, faremos uma análise de \"drill-down\", focando em um insight específico obtido na primeira etapa. Vamos isolar o parlamentar com o maior gasto acumulado e investigar em detalhe o seu perfil de despesas, entendendo quais são suas categorias mais frequentes.\n",
    "\n",
    "Ao final desta seção, teremos um conjunto de insights visuais que não apenas respondem às nossas questões, mas também fornecem uma base sólida para as decisões que tomaremos na etapa de **Modelagem**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Análise das Principais Dimensões de Gasto**\n",
    "\n",
    "\n",
    "### 1️ - Top 5 Parlamentares por Custo Total\n",
    "> **O que mostra:** Os parlamentares com maior volume de gastos no período analisado.  \n",
    "> **Insight:** Permite identificar concentrações de gastos por indivíduo e investigar comportamentos fora do padrão.\n",
    "\n",
    "### 2️ - Top 10 UFs por Gastos\n",
    "> **O que mostra:** Os estados da federação com maior soma de despesas parlamentares.  \n",
    "> **Insight:** Auxilia a visualizar a distribuição geográfica dos gastos.\n",
    "\n",
    "### 3️ - Top 10 Partidos por Gastos\n",
    "> **O que mostra:** Os partidos políticos com maiores gastos médios agregados.  \n",
    "> **Insight:** Pode revelar padrões partidários nos gastos, com possíveis implicações políticas.\n",
    "\n",
    "### 4️ - Tipos de Despesa com Maior Valor Médio\n",
    "> **O que mostra:** Quais tipos de despesa apresentam maior média de valores reembolsados.  \n",
    "> **Insight:** Ajuda a identificar os tipos de gastos mais onerosos, que podem demandar auditoria ou justificativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código para visualizações agregadas com Plotly\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "# Define um template padrão para o Plotly\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "# Função para formatar como R$ com ponto de milhar e vírgula decimal\n",
    "def formatar_valor(valor):\n",
    "# Garante que está lidando com o DataFrame correto\n",
    "    return f\"R$ {valor:,.2f}\".replace(\",\", \"X\").replace(\".\", \",\").replace(\"X\", \".\")\n",
    "\n",
    "# 2️ Top 10 UFs por Gasto Total\n",
    "top_ufs = (\n",
    "    df_modelo.groupby('sgUF')['vlrLiquidoTotal']\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .reset_index()\n",
    ")\n",
    "top_ufs['texto'] = top_ufs['vlrLiquidoTotal'].apply(formatar_valor)\n",
    "\n",
    "fig2 = px.bar(\n",
    "    top_ufs,\n",
    "    x='sgUF',\n",
    "    y='vlrLiquidoTotal',\n",
    "    orientation='v',\n",
    "    title='<b>UFs por Gastos Totais</b>',\n",
    "    labels={'vlrLiquidoTotal': 'Gasto Total (R$)', 'sgUF': 'UF'},\n",
    "    text='texto'\n",
    ")\n",
    "fig2.update_layout(showlegend=False, yaxis={'categoryorder':'total ascending'})\n",
    "fig2.update_traces(textposition='outside', marker_color='#EF553B')\n",
    "\n",
    "\n",
    "# 3️ Top 10 Partidos por Gasto Total\n",
    "top_partidos = (\n",
    "    df_modelo.groupby('sgPartido')['vlrLiquidoTotal']\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .reset_index()\n",
    ")\n",
    "top_partidos['texto'] = top_partidos['vlrLiquidoTotal'].apply(formatar_valor)\n",
    "\n",
    "fig3 = px.bar(\n",
    "    top_partidos,\n",
    "    x='sgPartido',\n",
    "    y='vlrLiquidoTotal',\n",
    "    orientation='v',\n",
    "    title='<b>Partidos por Gastos Totais</b>',\n",
    "    labels={'vlrLiquidoTotal': 'Gasto Total (R$)', 'sgPartido': 'Partido'},\n",
    "    text='texto'\n",
    ")\n",
    "fig3.update_layout(showlegend=False, yaxis={'categoryorder':'total ascending'})\n",
    "fig3.update_traces(textposition='outside', marker_color='#00CC96')\n",
    "\n",
    "\n",
    "# 4️ Top 10 Tipos de Despesa por Valor Médio\n",
    "top_tipos = (\n",
    "    df_modelo.groupby('txtDescricao')['vlrLiquidoTotal']\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .reset_index()\n",
    ")\n",
    "top_tipos['texto'] = top_tipos['vlrLiquidoTotal'].apply(formatar_valor)\n",
    "\n",
    "fig4 = px.bar(\n",
    "    top_tipos,\n",
    "    x='txtDescricao',\n",
    "    y='vlrLiquidoTotal',\n",
    "    orientation='v',\n",
    "    title='<b>Tipos de Despesa com Maior Valor Médio por Transação</b>',\n",
    "    labels={'vlrLiquidoTotal': 'Valor Médio (R$)', 'txtDescricao': 'Tipo de Despesa'},\n",
    "    text='texto'\n",
    ")\n",
    "fig4.update_layout(showlegend=False, yaxis={'categoryorder':'total ascending'})\n",
    "fig4.update_traces(textposition='outside', marker_color='#AB63FA')\n",
    "\n",
    "\n",
    "# Exibir os gráficos\n",
    "fig2.show()\n",
    "fig3.show()\n",
    "fig4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvEceHzUQq2j"
   },
   "source": [
    "# 5. Modelagem <a class=\"anchor\" id=\"modelagem\"></a>\n",
    "As the first step in modelling, you'll select the actual modelling technique that you'll be using. Although you may have already selected a tool during the business understanding phase, at this stage you'll be selecting the specific modelling technique e.g. decision-tree building with C5.0, or neural network generation with back propagation. If multiple techniques are applied, perform this task separately for each technique.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9H-GXDBNQq2j"
   },
   "source": [
    "## 5.1. Técnicas de Modelagem <a class=\"anchor\" id=\"tecnicas-modelagem\"></a>\n",
    "Document the actual modelling technique that is to be used.\n",
    "\n",
    "Import Models below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "nhhwoVkVQq2k"
   },
   "outputs": [],
   "source": [
    "X = df.drop('y', axis=1)\n",
    "y = df['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uFK8exaK-68S"
   },
   "outputs": [],
   "source": [
    "# Normalização dos dados numéricos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "categorical_features = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
    "numeric_features = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8ClvOxXQq2k"
   },
   "source": [
    "## 5.2. Teste de Modelos <a class=\"anchor\" id=\"teste-modelos\"></a>\n",
    "Many modelling techniques make specific assumptions about the data, for example that all attributes have uniform distributions, no missing values allowed, class attribute must be symbolic etc. Record any assumptions made.\n",
    "\n",
    "-\n",
    "-\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUz08h6RBC1a"
   },
   "outputs": [],
   "source": [
    "pipeline_lr = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(C=1.0, solver='liblinear'))\n",
    "])\n",
    "\n",
    "pipeline_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2))\n",
    "])\n",
    "\n",
    "pipeline_gb = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQFDFtQoQq2k"
   },
   "source": [
    "## 5.3. Construção do Modelo (Build) <a class=\"anchor\" id=\"construcao-modelo\"></a>\n",
    "Run the modelling tool on the prepared dataset to create one or more models.\n",
    "\n",
    "**Parameter settings** - With any modelling tool there are often a large number of parameters that can be adjusted. List the parameters and their chosen values, along with the rationale for the choice of parameter settings.\n",
    "\n",
    "**Models** - These are the actual models produced by the modelling tool, not a report on the models.\n",
    "\n",
    "**Model descriptions** - Describe the resulting models, report on the interpretation of the models and document any difficulties encountered with their meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192
    },
    "collapsed": true,
    "id": "JFUvxZVmQq2k",
    "outputId": "418627bc-a187-4460-b50f-bf8f876e8e59"
   },
   "outputs": [],
   "source": [
    "pipeline_lr.fit(X_train, y_train)\n",
    "pipeline_rf.fit(X_train, y_train)\n",
    "pipeline_gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZL6W-w7YQq2k"
   },
   "source": [
    "## 5.4. Avaliação de Performance <a class=\"anchor\" id=\"avaliacao-modelo\"></a>\n",
    "Interpret the models according to your domain knowledge, your data mining success criteria and your desired test design. Judge the success of the application of modelling and discovery techniques technically, then contact business analysts and domain experts later in order to discuss the data mining results in the business context. This task only considers models, whereas the evaluation phase also takes into account all other results that were produced in the course of the project.\n",
    "\n",
    "At this stage you should rank the models and assess them according to the evaluation criteria. You should take the business objectives and business success criteria into account as far as you can here. In most data mining projects a single technique is applied more than once and data mining results are generated with several different techniques.\n",
    "\n",
    "**Model assessment** - Summarise the results of this task, list the qualities of your generated models (e.g.in terms of accuracy) and rank their quality in relation to each other.\n",
    "\n",
    "**Revised parameter settings** - According to the model assessment, revise parameter settings and tune them for the next modelling run. Iterate model building and assessment until you strongly believe that you have found the best model(s). Document all such revisions and assessments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U1YFLClIQq2k",
    "outputId": "bfdbddad-824f-4a40-96cb-6cec08c7cb7d"
   },
   "outputs": [],
   "source": [
    "model_metrics = {}\n",
    "\n",
    "# Lista de modelos para avaliar\n",
    "models = ['lr', 'rf', 'gb']\n",
    "\n",
    "for model_key in models:\n",
    "    try:\n",
    "        pipelines[model_key].fit(X_train, y_train)\n",
    "\n",
    "        y_pred = pipelines[model_key].predict(X_test)\n",
    "        y_proba = pipelines[model_key].predict_proba(X_test)[:, 1]  # Probabilidades para AUC-ROC\n",
    "\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        auc_roc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "        model_metrics[model_key] = {\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1-Score': f1,\n",
    "            'AUC-ROC': auc_roc\n",
    "        }\n",
    "\n",
    "        print(f\"Resultados para {model_key}:\")\n",
    "        print(f\"Precisão: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1-Score: {f1:.4f}\")\n",
    "        print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "        print(\"-----\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao treinar ou avaliar o modelo {model_key}: {e}\")\n",
    "\n",
    "for model_key in models:\n",
    "    try:\n",
    "        y_pred = pipelines[model_key].predict(X_test)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        print(f\"Matriz de Confusão para {model_key}:\")\n",
    "        print(cm)\n",
    "        print(\"-----\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao gerar matriz de confusão para {model_key}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Avaliação do Modelo <a class=\"anchor\" id=\"avaliacao-modelo\"></a>\n",
    "\n",
    "## 6.1. Regressão Logística (lr): <a class=\"anchor\" id=\"regressao-logistica\"></a>\n",
    "\n",
    "Precisão: 69.26% - Este modelo tem uma boa taxa de precisão, indicando que quando prevê que um cliente se inscreverá, está correto aproximadamente 69.26% das vezes.\n",
    "Recall: 40.30% - Capta 40.30% dos casos positivos reais, o que é moderado.\n",
    "F1-Score: 50.95% - Um equilíbrio razoável entre precisão e recall.\n",
    "AUC-ROC: 92.92% - Excelente capacidade de discriminação entre as classes positivas e negativas.\n",
    "Matriz de Confusão: Com um número relativamente baixo de falsos positivos (83) e uma quantidade moderada de falsos negativos (277).\n",
    "Random Forest (rf):\n",
    "\n",
    "Precisão: 65.06% - Ligeiramente inferior à regressão logística em termos de precisão.\n",
    "Recall: 37.72% - Menor do que a regressão logística, indicando uma capacidade mais fraca de capturar todos os positivos reais.\n",
    "F1-Score: 47.75% - Reflete o compromisso entre precisão e recall inferior ao da regressão logística.\n",
    "AUC-ROC: 92.58% - Muito boa, mas ligeiramente inferior à regressão logística.\n",
    "Matriz de Confusão: Mais falsos positivos (94) e falsos negativos (289) do que a regressão logística, indicando uma eficiência geral mais baixa.\n",
    "Gradient Boosting (gb):\n",
    "\n",
    "Precisão: 69.42% - Similar à regressão logística e ligeiramente superior ao Random Forest.\n",
    "Recall: 41.59% - O melhor recall dos três modelos, capturando uma proporção maior de casos positivos.\n",
    "F1-Score: 52.02% - O melhor F1-Score, indicando o melhor equilíbrio entre precisão e recall.\n",
    "AUC-ROC: 93.58% - A melhor das três, mostrando a superioridade do Gradient Boosting em discriminar entre as classes.\n",
    "Matriz de Confusão: Semelhante ao Random Forest em termos de falsos positivos, mas com menos falsos negativos, melhorando tanto a precisão quanto o recall.\n",
    "Conclusões e Recomendações\n",
    "Gradient Boosting parece ser o modelo mais forte em geral, apresentando o melhor equilíbrio entre todas as métricas. Com a maior AUC-ROC e o melhor F1-Score, ele demonstra uma capacidade superior de manejar a classificação de uma maneira equilibrada, tornando-o ideal para situações onde tanto a precisão quanto o recall são importantes.\n",
    "\n",
    "Regressão Logística ainda se mostra uma opção viável, especialmente se a interpretabilidade do modelo é uma prioridade, visto que modelos lineares como este oferecem insights mais diretos sobre como as características estão influenciando as previsões.\n",
    "\n",
    "Random Forest, embora robusto e com um bom desempenho geral, parece ser ligeiramente superado pelos outros modelos em termos de métricas chave neste cenário específico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Aplicação prática (Deployment)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
