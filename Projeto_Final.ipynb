{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTNXidF3Qq2K"
   },
   "source": [
    "# **Ci√™ncia de Dados e Machine Learning**\n",
    "\n",
    "## **Projeto Final do Curso**\n",
    "\n",
    "---\n",
    "\n",
    "### **Alunos:**\n",
    "\n",
    "> Charles Bezerra - 52400351\n",
    "\n",
    "> Jheferson Warley - 52400071\n",
    "\n",
    "> Paulo Machado - 52400245\n",
    "\n",
    "---\n",
    "\n",
    "### Tema: **Despesas pela Cota para Exerc√≠cio da Atividade Parlamentar**\n",
    "\n",
    "### Base de Dados: https://dadosabertos.camara.leg.br/swagger/api.html?tab=staticfile\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RfgYroaQq2N"
   },
   "source": [
    "Este projeto final do curso de **Ci√™ncia de Dados e Machine** Learning do UniCEUB se baseia na metodologia *Cross-Industry Standard Process for Data Mining - CRISP-DM* (https://www.sv-europe.com/crisp-dm-methodology/), oferecendo uma abordagem estruturada para planejar um projeto de minera√ß√£o de dados de uma forma robusta.\n",
    "\n",
    "Este modelo representa uma sequ√™ncia idealizada de eventos. Na pr√°tica, muitas das tarefas podem ser realizadas em uma ordem diferente, e frequentemente ser√° necess√°rio voltar a tarefas anteriores e repetir certas a√ß√µes.\n",
    "\n",
    "<div>\n",
    "<img src=\"FasesCRISP-DM.png\" width=\"50%\">\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjrc0DUFQq2O"
   },
   "source": [
    "## **Etapas do Processo CRISP-DM**\n",
    "\n",
    "### 1. [Entendimento do Neg√≥cio](#business-understanding)\n",
    "Compreens√£o dos objetivos de neg√≥cio, contexto organizacional e defini√ß√£o das metas anal√≠ticas.\n",
    "\n",
    "- [1.1 Avalia√ß√£o da Situa√ß√£o Atual](#avaliacao-da-situacao)\n",
    "- [1.2 Resultados Esperados](#resultados-esperados)\n",
    "- [1.3 Quest√µes de Pesquisa](#questoes-de-pesquisa)\n",
    "<!-- - [1.4 Plano de Projeto](#plano-do-projeto) -->\n",
    "\n",
    "---\n",
    "\n",
    "### 2. [Entendimento dos Dados](#entendimento-dados)\n",
    "Explora√ß√£o inicial dos dados, coleta e verifica√ß√£o da qualidade.\n",
    "\n",
    "- [2.1 Relatorio Inicial](#relatorio-inicial)\n",
    "- [2.2 Descri√ß√£o dos Dados](#descricao-dados)\n",
    "- [2.3 Explora√ß√£o dos Dados](#exploracao-dados)\n",
    "- [2.4 Verifica√ß√£o da Qualidade dos Dados](#qualidade-dos-dados)\n",
    "\n",
    "---\n",
    "\n",
    "### 3. [Prepara√ß√£o dos Dados](#preparacao-dados)\n",
    "Constru√ß√£o do dataset final que ser√° utilizado para modelagem.\n",
    "\n",
    "- [3.1 Sele√ß√£o dos Dados](#selecao-dados)\n",
    "- [3.2 Limpeza dos Dados](#limpeza-dados)\n",
    "- [3.3 Constru√ß√£o de Dados Derivados](#dados-derivados)\n",
    "- [3.4 Integra√ß√£o de Dados](#integracao-dados)\n",
    "- [3.5 An√°lise Explorat√≥ria de Dados](#analise-dados)\n",
    "\n",
    "---\n",
    "\n",
    "### 4. [Modelagem](#modelagem)\n",
    "Aplica√ß√£o de t√©cnicas de modelagem estat√≠stica ou de machine learning.\n",
    "\n",
    "- [5.1 T√©cnicas de Modelagem](#tecnicas-modelagem)\n",
    "- [5.2 Teste de Modelos](#teste-modelos)\n",
    "- [5.3 Constru√ß√£o dos Modelos](#construcao-modelo)\n",
    "- [5.4 Avalia√ß√£o de Performance](#avaliacao-modelo)\n",
    "\n",
    "---\n",
    "\n",
    "### 5. [Avalia√ß√£o](#avaliacao-modelo)\n",
    "Verifica√ß√£o se o modelo atende os objetivos de neg√≥cio definidos.\n",
    "\n",
    "- [6.1 Regress√£o Log√≠stica](#regressao-logistica)\n",
    "- [6.2 Revis√£o do Processo](#revisao-processo)\n",
    "- [6.3 Determina√ß√£o dos Pr√≥ximos Passos](#proximos-passos)\n",
    "\n",
    "---\n",
    "\n",
    "### 6. [Implementa√ß√£o (Deployment)](#implementacao)\n",
    "Entrega pr√°tica do modelo, seja em relat√≥rio, dashboard, sistema ou API.\n",
    "\n",
    "- [6.1 Planejamento da Implementa√ß√£o](#planejamento-implementacao)\n",
    "- [6.2 Monitoramento e Manuten√ß√£o](#monitoramento)\n",
    "- [6.3 Documenta√ß√£o Final](#documentacao-final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pdYJHP76Qq2O"
   },
   "source": [
    "## 1. Entendimento do Neg√≥cio  <a class=\"anchor\" id=\"business-understanding\"></a>\n",
    "\n",
    "Atualmente, o cen√°rio pol√≠tico brasileiro se mostra em foco, principalmente quando se trata de despesas relacionadas √† sustenta√ß√£o do governo como todo. Neste contexto, as despesas parlamentares, limitadas por uma cota, s√£o frequentemente noticiadas devido a seu alto custo. As cotas parlamentares variam conforme o estado do deputado e √© destinado ao custeio de despesas relacionadas ao exerc√≠cio do mandato. As despesas incluem passagens a√©reas, locomo√ß√£o, hospedagens, servi√ßos de seguran√ßa, divulga√ß√£o de atividades parlamentares e contrata√ß√£o de pessoal.\n",
    "\n",
    "\n",
    "A C√¢mara dos Deputados divulga atrav√©s da plataforma de dados abertos do governo (https://dadosabertos.camara.leg.br/swagger/api.html?tab=staticfile) as despesas refentes ao consumo de cotas separadas por ano, Deputado, UF, tipo de despesas, entre outras classifica√ß√µes. Os arquivos podem ser baixador por ano, dispon√≠veis desde o ano 2018, nos formatos XML, JSON, CSV, XLSX e ODS.\n",
    "\n",
    "\n",
    "Para este projeto, selecionamos os dados relativos ao ano de 2024 (ano completo mais recente) com arquivos no formato CSV para melhor tratamento dos dados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2SqAlWIyQq2P"
   },
   "source": [
    "## 1.1 Avalia√ß√£o da Situa√ß√£o Atual<a class=\"anchor\" id=\"avaliacao-da-situacao\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFsmtXzxQq2P"
   },
   "source": [
    "A transpar√™ncia nos gastos p√∫blicos tem ganhado relev√¢ncia nos debates sociais e institucionais, principalmente no contexto pol√≠tico brasileiro. A C√¢mara dos Deputados disponibiliza, por meio do portal de Dados Abertos, informa√ß√µes detalhadas sobre a utiliza√ß√£o da Cota para o Exerc√≠cio da Atividade Parlamentar (CEAP), que contempla diversos tipos de despesas efetuadas pelos parlamentares no desempenho de suas fun√ß√µes.\n",
    "\n",
    "Apesar da disponibilidade dos dados, observa-se uma subutiliza√ß√£o dessas informa√ß√µes por parte da sociedade civil e dos √≥rg√£os fiscalizadores. O volume e a complexidade dos dados dificultam an√°lises diretas e conclusivas, exigindo ferramentas adequadas de tratamento, an√°lise e visualiza√ß√£o. Diante disso, este projeto visa utilizar t√©cnicas de an√°lise de dados e aprendizado de m√°quina para transformar os dados brutos em insights relevantes e acess√≠veis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWxWA-87Qq2P"
   },
   "source": [
    "## 1.2 Resultados Esperados<a class=\"anchor\" id=\"resultaods-esperados\"></a>\n",
    "\n",
    "Este projeto tem como objetivo geral analisar os gastos parlamentares por meio da base de dados da CEAP, abrangendo os anos de 2023, 2024 e 2025. Os resultados esperados incluem:\n",
    "\n",
    "- Desenvolvimento de relat√≥rios e dashboards anal√≠ticos para visualiza√ß√£o dos dados por deputado, partido pol√≠tico, unidade federativa (UF), tipo de despesa, fornecedor e per√≠odo (m√™s e ano).\n",
    "- An√°lises estat√≠sticas descritivas e comparativas, a fim de identificar padr√µes de gastos e varia√ß√µes relevantes entre diferentes grupos.\n",
    "- Detec√ß√£o de anomalias e poss√≠veis irregularidades nos registros de despesas.\n",
    "- Aplica√ß√£o de t√©cnicas de aprendizado de m√°quina (Machine Learning) com o objetivo de construir modelos preditivos capazes de estimar os gastos parlamentares futuros por partido ou UF, com base nos dados hist√≥ricos.\n",
    "\n",
    "O projeto segue a metodologia CRISP-DM, com foco na reprodutibilidade dos resultados e na cria√ß√£o de documenta√ß√£o clara e acess√≠vel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Quest√µes de Pesquisa<a class=\"anchor\" id=\"questoes-de-pesquisa\"></a>\n",
    "\n",
    "O projeto √© orientado por um conjunto de quest√µes explorat√≥rias e preditivas, que servir√£o como guia para as etapas anal√≠ticas e de modelagem.\n",
    "\n",
    "### Quest√µes Explorat√≥rias\n",
    "\n",
    "- Quais partidos pol√≠ticos apresentaram os maiores volumes de gasto no per√≠odo analisado?\n",
    "- Quais unidades federativas concentram os maiores gastos?\n",
    "- Quais s√£o os tipos de despesa mais recorrentes e qual seu impacto nos valores totais?\n",
    "- Como os gastos variam ao longo do tempo? Existe sazonalidade ou tend√™ncia?\n",
    "- H√° fornecedores recorrentes nos maiores gastos? Qual seu perfil?\n",
    "\n",
    "### Quest√µes Preditivas\n",
    "\n",
    "- √â poss√≠vel prever os gastos parlamentares futuros com base no hist√≥rico de dados?\n",
    "- Quais vari√°veis mais influenciam no volume de gastos (ex.: partido, UF, tipo de despesa, m√™s)?\n",
    "- Quais partidos ou unidades federativas t√™m maior propens√£o a apresentar aumentos nos gastos em futuros mandatos?\n",
    "\n",
    "Estas perguntas direcionam a constru√ß√£o dos indicadores, visualiza√ß√µes e modelos preditivos ao longo do projeto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4S-Y6p8VQq2R"
   },
   "source": [
    "# 2. Entendimento dos Dados <a class=\"anchor\" id=\"entendimento-dados\"></a>\n",
    "A etapa de entendimento dos dados tem como objetivo fornecer uma vis√£o inicial e aprofundada da estrutura, conte√∫do e qualidade do conjunto de dados dispon√≠vel para an√°lise. Trata-se de uma fase fundamental no processo anal√≠tico, pois permite identificar caracter√≠sticas importantes dos dados, potenciais inconsist√™ncias, aus√™ncia de valores e padr√µes que podem influenciar diretamente na prepara√ß√£o, modelagem e interpreta√ß√£o dos resultados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-6TQJ_4Qq2R"
   },
   "source": [
    "## 2.1 Relat√≥rio Inicial <a class=\"anchor\" id=\"relatorio-inicial\"></a>\n",
    "O conjunto de dados utilizado neste projeto refere-se √†s despesas parlamentares registradas na Cota para o Exerc√≠cio da Atividade Parlamentar (CEAP), compreendendo os anos de 2023, 2024 e 2025. Os dados foram extra√≠dos da API p√∫blica da C√¢mara dos Deputados, que disponibiliza os registros em diversos formatos. Para este trabalho, optou-se pelo formato `.csv`, considerando a facilidade de leitura e manipula√ß√£o em ambientes Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "X9OlrvX3Qq2R"
   },
   "outputs": [],
   "source": [
    "# Importa√ß√£o das Bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "D85E5K77Qq2S"
   },
   "outputs": [],
   "source": [
    "# Leitura dos dados\n",
    "df_2023 = pd.read_csv(\"DataBase/Ano-2023.csv\", sep=\";\", encoding=\"utf-8\", low_memory=False)\n",
    "df_2024 = pd.read_csv(\"DataBase/Ano-2024.csv\", sep=\";\", encoding=\"utf-8\", low_memory=False)\n",
    "df_2025 = pd.read_csv(\"DataBase/Ano-2025.csv\", sep=\";\", encoding=\"utf-8\", low_memory=False)\n",
    "\n",
    "# Combina√ß√£o dos tr√™s dataframes\n",
    "df_completo = pd.concat([df_2023, df_2024, df_2025], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibi√ß√£o das 5 primeiras linhas\n",
    "display(df_completo.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZ8n1_pnQq2T"
   },
   "source": [
    "## 2.2 Descri√ß√£o dos Dados <a class=\"anchor\" id=\"descricao-dados\"></a>\n",
    "A seguir, s√£o apresentados o nome das colunas dispon√≠veis no dataset e o seu formato dimensional (linhas x colunas).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A tabela abaixo apresenta a descri√ß√£o de cada uma das vari√°veis dispon√≠veis no conjunto de dados utilizado.\n",
    "\n",
    "| Nome da Coluna                 | Descri√ß√£o                                                        |\n",
    "|-------------------------------|------------------------------------------------------------------|\n",
    "| `txNomeParlamentar`           | Nome do parlamentar                                              |\n",
    "| `cpf`                         | CPF do parlamentar (quando dispon√≠vel)                          |\n",
    "| `ideCadastro`                 | ID √∫nico do parlamentar                                          |\n",
    "| `nuCarteiraParlamentar`       | N√∫mero da carteira parlamentar                                   |\n",
    "| `nuLegislatura`               | N√∫mero da legislatura em exerc√≠cio                               |\n",
    "| `sgUF`                        | Unidade Federativa (estado)                                      |\n",
    "| `sgPartido`                   | Sigla do partido pol√≠tico                                        |\n",
    "| `codLegislatura`              | C√≥digo da legislatura                                            |\n",
    "| `numSubCota`                  | C√≥digo da subcota utilizada                                      |\n",
    "| `txtDescricao`                | Descri√ß√£o da subcota                                             |\n",
    "| `numEspecificacaoSubCota`     | C√≥digo da especifica√ß√£o da subcota                               |\n",
    "| `txtDescricaoEspecificacao`   | Descri√ß√£o detalhada da subcota                                   |\n",
    "| `txtFornecedor`               | Nome do fornecedor                                               |\n",
    "| `txtCNPJCPF`                  | CNPJ ou CPF do fornecedor                                        |\n",
    "| `txtNumero`                   | N√∫mero do documento fiscal                                       |\n",
    "| `indTipoDocumento`            | Tipo do documento (nota fiscal, recibo, etc.)                   |\n",
    "| `datEmissao`                  | Data de emiss√£o do documento                                     |\n",
    "| `vlrDocumento`                | Valor bruto do documento                                         |\n",
    "| `vlrGlosa`                    | Valor glosado/desconsiderado                                     |\n",
    "| `vlrLiquido`                  | Valor l√≠quido aceito                                             |\n",
    "| `numMes`                      | M√™s de refer√™ncia da despesa                                     |\n",
    "| `numAno`                      | Ano de refer√™ncia da despesa                                     |\n",
    "| `numParcela`                  | N√∫mero da parcela, quando aplic√°vel                              |\n",
    "| `txtPassageiro`               | Nome do passageiro (se transporte a√©reo)                         |\n",
    "| `txtTrecho`                   | Trecho da viagem (ida/volta)                                     |\n",
    "| `numLote`                     | N√∫mero do lote do documento                                      |\n",
    "| `numRessarcimento`            | N√∫mero de protocolo de ressarcimento                             |\n",
    "| `datPagamentoRestituicao`     | Data do pagamento de restitui√ß√£o                                 |\n",
    "| `vlrRestituicao`              | Valor restitu√≠do                                                 |\n",
    "| `nuDeputadoId`                | ID √∫nico do deputado                                             |\n",
    "| `ideDocumento`                | ID do documento                                                  |\n",
    "| `urlDocumento`                | Link para o documento oficial                                    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EemJ6DTeQq2U",
    "outputId": "7aa11b1f-b976-4a2a-f622-bab9cffdd1a7"
   },
   "outputs": [],
   "source": [
    "# Nomes das colunas\n",
    "df_completo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gnj33OcMQq2U",
    "outputId": "02529b54-4038-461c-f231-2ba7e0018cc2"
   },
   "outputs": [],
   "source": [
    "# Dimens√£o do dataframe\n",
    "df_completo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNxTQwN_Qq2V"
   },
   "source": [
    "## 2.3 Explora√ß√£o dos Dados <a class=\"anchor\" id=\"exploracao-dados\"></a>\n",
    "\n",
    "Essa etapa visa obter uma vis√£o geral das caracter√≠sticas dos dados, incluindo tipos de vari√°veis, estat√≠sticas descritivas e primeiros insights de distribui√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TwiVpT8FQq2W",
    "outputId": "ac44ac23-9621-40c0-a32a-61b7199f4960"
   },
   "outputs": [],
   "source": [
    "# Verifica√ß√£o de duplicatas\n",
    "df_completo.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estat√≠sticas descritivas\n",
    "df_completo.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estat√≠sticas descritivas\n",
    "df_completo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando valores nulos por coluna\n",
    "df_completo.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a quantidade de valores √∫nicos em algumas colunas-chave\n",
    "print(\"UFs:\", df_completo['sgUF'].nunique())\n",
    "print(\"Partidos:\", df_completo['sgPartido'].nunique())\n",
    "print(\"Tipos de despesa:\", df_completo['txtDescricao'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribui√ß√£o dos principais campos categ√≥ricos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# UF\n",
    "uf_counts = df_completo['sgUF'].value_counts().reset_index()\n",
    "uf_counts.columns = ['UF', 'Total de Registros']\n",
    "display(Markdown(\"### Distribui√ß√£o por Unidade Federativa\"))\n",
    "plt.figure(figsize=(10,5))\n",
    "ax1 = sns.barplot(data=uf_counts, x='UF', y='Total de Registros', palette='Blues_d')\n",
    "plt.title('Distribui√ß√£o por Unidade Federativa')\n",
    "plt.xlabel('UF')\n",
    "plt.ylabel('Total de Registros')\n",
    "plt.xticks(rotation=45)\n",
    "for p in ax1.patches:\n",
    "    ax1.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                 ha='center', va='bottom', fontsize=9, color='black', xytext=(0, 3), textcoords='offset points')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Partido\n",
    "partido_counts = df_completo['sgPartido'].value_counts().reset_index()\n",
    "partido_counts.columns = ['Partido', 'Total de Registros']\n",
    "display(Markdown(\"### Distribui√ß√£o por Partido\"))\n",
    "plt.figure(figsize=(12,5))\n",
    "ax2 = sns.barplot(data=partido_counts, x='Partido', y='Total de Registros', palette='Greens_d')\n",
    "plt.title('Distribui√ß√£o por Partido')\n",
    "plt.xlabel('Partido')\n",
    "plt.ylabel('Total de Registros')\n",
    "plt.xticks(rotation=45)\n",
    "for p in ax2.patches:\n",
    "    ax2.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                 ha='center', va='bottom', fontsize=9, color='black', xytext=(0, 3), textcoords='offset points')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tipo de Despesa\n",
    "# Exibir apenas os 15 principais tipos para melhor visualiza√ß√£o\n",
    "despesa_counts = df_completo['txtDescricao'].value_counts().reset_index()\n",
    "despesa_counts.columns = ['Tipo de Despesa', 'Total de Registros']\n",
    "display(Markdown(\"### Distribui√ß√£o por Tipo de Despesa (Top 15)\"))\n",
    "plt.figure(figsize=(12,6))\n",
    "ax3 = sns.barplot(data=despesa_counts.head(15), x='Tipo de Despesa', y='Total de Registros', palette='Oranges_d')\n",
    "plt.title('Distribui√ß√£o por Tipo de Despesa (Top 15)')\n",
    "plt.xlabel('Tipo de Despesa')\n",
    "plt.ylabel('Total de Registros')\n",
    "plt.xticks(rotation=75)\n",
    "for p in ax3.patches:\n",
    "    ax3.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                 ha='center', va='bottom', fontsize=9, color='black', xytext=(0, 3), textcoords='offset points')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzPUggSjQq2c"
   },
   "source": [
    "## 2.4 Verifica√ß√£o da Qualidade dos Dados<a class=\"anchor\" id=\"qualidade-dos-dados\"></a>\n",
    "Abaixo est√° um resumo quantitativo da qualidade dos dados ap√≥s a an√°lise explorat√≥ria inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo geral do dataset\n",
    "resumo_geral = pd.DataFrame({\n",
    "    \"Indicador\": [\n",
    "        \"Total de registros\",\n",
    "        \"Total de vari√°veis (colunas)\",\n",
    "        \"Registros duplicados\",\n",
    "        \"Valores inconsistentes (vlrDocumento < vlrLiquido)\",\n",
    "        \"Total valor liquido negativo\",\n",
    "        \"Total UF NULOS\"\n",
    "    ],\n",
    "    \"Valor\": [\n",
    "        df_completo.shape[0],\n",
    "        df_completo.shape[1],\n",
    "        df_completo.duplicated().sum(),\n",
    "        (df_completo['vlrDocumento'] < df_completo['vlrLiquido']).sum(),\n",
    "        (df_completo['vlrLiquido'] < 0 ).sum(),\n",
    "    ]\n",
    "})\n",
    "\n",
    "display(Markdown(\"### Resumo Geral da Base de Dados\"))\n",
    "display(resumo_geral)\n",
    "\n",
    "# Colunas com valores nulos\n",
    "nulls = df_completo.isnull().sum()\n",
    "nulls = nulls[nulls > 0].sort_values(ascending=False).reset_index()\n",
    "nulls.columns = ['Coluna', 'Valores Nulos']\n",
    "\n",
    "display(Markdown(\"### Colunas com Valores Ausentes\"))\n",
    "display(nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcL0DjOzQq2c"
   },
   "source": [
    "# 3. Prepara√ß√£o dos Dados <a class=\"anchor\" id=\"preparacao-dados\"></a>\n",
    "\n",
    "\n",
    "Nesta etapa, realizamos o tratamento necess√°rio para transformar os dados brutos em uma base estruturada e adequada para aplica√ß√£o de modelos de aprendizado supervisionado. As a√ß√µes incluem: sele√ß√£o e limpeza de dados, gera√ß√£o de atributos derivados e integra√ß√£o das bases hist√≥ricas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQjMmUM5Qq2c"
   },
   "source": [
    "## 3.1 Sele√ß√£o dos Dados <a class=\"anchor\" id=\"selecao-dados\"></a>\n",
    "\n",
    "Nesta etapa inicial da **Prepara√ß√£o dos Dados**, realizamos a sele√ß√£o criteriosa das vari√°veis mais relevantes para o problema de predi√ß√£o do **valor l√≠quido da despesa parlamentar (`vlrLiquido`)**.\n",
    "\n",
    "O objetivo √© filtrar os dados brutos e manter somente as informa√ß√µes que possuem **rela√ß√£o direta com o comportamento dos gastos parlamentares**, otimizando o desempenho dos algoritmos de machine learning.\n",
    "\n",
    "---\n",
    "\n",
    "#### üî∏ Crit√©rios de Sele√ß√£o\n",
    "\n",
    "Selecionamos as colunas que possuem potencial explicativo e que apresentam valor informacional para o modelo supervisionado. As vari√°veis escolhidas foram:\n",
    "\n",
    "- **`txNomeParlamentar`**: nome do deputado. Utilizada para gerar uma feature derivada de custo total por parlamentar.\n",
    "- **`sgUF`**: unidade federativa, que pode refletir realidades regionais de gastos.\n",
    "- **`sgPartido`**: partido pol√≠tico, poss√≠vel fator explicativo para padr√µes de despesa.\n",
    "- **`txtDescricao`**: tipo de despesa (ex: alimenta√ß√£o, aluguel, combust√≠vel).\n",
    "- **`vlrDocumento`**: valor bruto do documento fiscal apresentado.\n",
    "- **`numMes` e `numAno`**: per√≠odo da despesa, para an√°lise sazonal ou temporal.\n",
    "- **`vlrLiquido`**: vari√°vel-alvo que ser√° predita pelo modelo.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "g4kDHLdXquwb",
    "outputId": "2e1a32f8-35c5-4e93-8d7d-9b05451514c3"
   },
   "outputs": [],
   "source": [
    "# # Sele√ß√£o de colunas relevantes\n",
    "# colunas_selecionadas = [\n",
    "#     'sgUF', 'sgPartido','numMes', 'numAno', 'vlrLiquido']\n",
    "\n",
    "# df_modelo = df_completo[colunas_selecionadas].copy()\n",
    "\n",
    "# # Custo total por ano (valor agregado no projeto)\n",
    "# custo_anual = df_modelo.groupby('sgUF', 'sgPartido','numMes', 'numAno', 'vlrLiquido')['vlrLiquido'].transform('sum')\n",
    "# df_modelo['custo_total_anual'] = custo_anual\n",
    "\n",
    "# from IPython.display import display, Markdown\n",
    "# display(Markdown(\"**Amostra da base com colunas selecionadas e nova feature de custo por parlamentar:**\"))\n",
    "# display(df_modelo.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDRfR6L8Qq2d"
   },
   "source": [
    "## 3.2 Limpeza dos Dados <a class=\"anchor\" id=\"limpeza-dados\"></a>\n",
    "\n",
    "\n",
    "Nesta etapa, realizamos uma s√©rie de a√ß√µes de limpeza para garantir que os dados utilizados nos modelos estejam consistentes, sem ru√≠dos e com alta qualidade informacional. A prepara√ß√£o adequada dos dados √© essencial para que qualquer modelo de aprendizado de m√°quina produza resultados confi√°veis.\n",
    "\n",
    "As a√ß√µes tomadas nesta fase incluem:\n",
    "\n",
    "---\n",
    "\n",
    "#### üî∏ Remo√ß√£o de Registros Inconsistentes\n",
    "\n",
    "Eliminamos os registros em que o valor l√≠quido (`vlrLiquido`) era superior ao valor bruto do documento (`vlrDocumento`). Essa inconsist√™ncia viola a l√≥gica financeira da base de dados e poderia comprometer an√°lises futuras. Esses registros foram identificados, quantificados e removidos de forma criteriosa.\n",
    "\n",
    "---\n",
    "\n",
    "#### üî∏ Tratamento de Valores Negativos\n",
    "\n",
    "Foram identificados valores negativos na coluna `vlrLiquido` ‚Äî o que n√£o representa um cen√°rio v√°lido para gastos parlamentares. Esses valores estavam presentes em todas as bases de 2023, 2024 e 2025:\n",
    "\n",
    "- **2023:** 9.383 registros\n",
    "- **2024:** 10.327 registros\n",
    "- **2025:** 2.626 registros\n",
    "\n",
    "Todos foram removidos ap√≥s verifica√ß√£o e exibi√ß√£o de amostras por ano. A limpeza foi validada com uma checagem final, confirmando que **nenhum valor negativo permaneceu**.\n",
    "\n",
    "---\n",
    "\n",
    "#### üî∏ Elimina√ß√£o de Registros com Valores Ausentes (NaN)\n",
    "\n",
    "Ap√≥s a sele√ß√£o e transforma√ß√£o das colunas relevantes, identificamos **2.135 registros com valores ausentes**, totalizando **4.270 c√©lulas com `NaN`**. Esses dados foram descartados para evitar vi√©s no processo de modelagem, uma vez que a imputa√ß√£o poderia comprometer a acur√°cia dos modelos.\n",
    "\n",
    "---\n",
    "\n",
    "#### üî∏ Remo√ß√£o de Registros Duplicados\n",
    "\n",
    "Realizamos a verifica√ß√£o de duplicatas no conjunto de dados e removemos entradas repetidas para garantir que cada linha representasse uma observa√ß√£o √∫nica. Essa pr√°tica evita sobrepeso em certas categorias e garante imparcialidade nas an√°lises estat√≠sticas.\n",
    "\n",
    "---\n",
    "\n",
    "#### üî∏ Remo√ß√£o de Colunas Desnecess√°rias\n",
    "\n",
    "Foram exclu√≠das colunas que n√£o contribu√≠am para os objetivos do projeto, como identificadores √∫nicos (`CPF`, `CNPJ`, c√≥digos legislativos), atributos com alta cardinalidade ou informa√ß√µes redundantes. Essa etapa reduziu a complexidade do modelo e aumentou a interpretabilidade.\n",
    "\n",
    "---\n",
    "\n",
    "#### üî∏ Cria√ß√£o de Feature Agregada: `custo_total_parlamentar`\n",
    "\n",
    "Para enriquecer a base de dados, criamos a vari√°vel `custo_total_parlamentar`, que representa o total de gastos acumulados por parlamentar ao longo dos anos. Essa feature √© √∫til tanto para an√°lises descritivas quanto para futuras previs√µes.\n",
    "\n",
    "---\n",
    "\n",
    "###  Resultado Final\n",
    "\n",
    "Ap√≥s todas as etapas de limpeza, o novo DataFrame final (`df_modelo`) apresenta:\n",
    "\n",
    "- **518.989 registros**\n",
    "- **9 colunas relevantes**\n",
    "- Nenhum valor `NaN` ou negativo\n",
    "- Dados prontos para modelagem supervisionada\n",
    "\n",
    "---\n",
    "\n",
    "####  Amostra dos dados tratados:\n",
    "\n",
    "| txNomeParlamentar | sgUF | sgPartido | txtDescricao | vlrDocumento | numMes | numAno | vlrLiquido | custo_total_parlamentar |\n",
    "|-------------------|------|-----------|-----------------------------|----------------|---------|--------|-------------|--------------------------|\n",
    "| Danilo Forte      | CE   | UNI√ÉO     | MANUTEN√á√ÉO DE ESCRIT√ìRIO... | 400.00         | 1       | 2023   | 400.00      | 1.389.529,54             |\n",
    "| Danilo Forte      | CE   | UNI√ÉO     | MANUTEN√á√ÉO DE ESCRIT√ìRIO... | 2.215.00       | 1       | 2023   | 2.215.00    | 1.389.529,54             |\n",
    "| ...               | ...  | ...       | ...                         | ...            | ...     | ...    | ...         | ...                      |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminhos corrigidos com separador \";\"\n",
    "arquivos = {\n",
    "    '2023': 'DataBase/Ano-2023.csv',\n",
    "    '2024': 'DataBase/Ano-2024.csv',\n",
    "    '2025': 'DataBase/Ano-2025.csv'\n",
    "}\n",
    "\n",
    "# Lista para armazenar os DataFrames limpos\n",
    "dfs_limpos = []\n",
    "\n",
    "display(Markdown(\"## Limpeza de valores negativos em `vlrLiquido` por ano\"))\n",
    "\n",
    "# Loop pelos arquivos\n",
    "for ano, caminho in arquivos.items():\n",
    "    # Leitura com separador \";\" e encoding\n",
    "    df = pd.read_csv(caminho, sep=';', encoding='utf-8', low_memory=False)\n",
    "    \n",
    "    # Convers√£o segura para float\n",
    "    df['vlrLiquido'] = pd.to_numeric(df['vlrLiquido'], errors='coerce')\n",
    "    \n",
    "    # Identifica√ß√£o de negativos\n",
    "    negativos_df = df[df['vlrLiquido'] < 0]\n",
    "    qtd_negativos = negativos_df.shape[0]\n",
    "\n",
    "    # Exibi√ß√£o dos resultados\n",
    "    display(Markdown(f\"### Limpeza de valores negativos na base de {ano}\"))\n",
    "    display(Markdown(f\"**Total de registros negativos encontrados:** `{qtd_negativos}`\"))\n",
    "\n",
    "    if qtd_negativos > 0:\n",
    "        display(negativos_df[['txNomeParlamentar', 'sgUF', 'sgPartido', 'vlrLiquido']].head())\n",
    "    \n",
    "    # Remo√ß√£o dos registros negativos\n",
    "    df = df[df['vlrLiquido'] >= 0]\n",
    "    \n",
    "    # Adiciona a coluna de ano para controle futuro\n",
    "    df['ano_base'] = int(ano)\n",
    "    \n",
    "    # Salva na lista\n",
    "    dfs_limpos.append(df)\n",
    "\n",
    "# Unifica√ß√£o dos DataFrames limpos\n",
    "df_completo = pd.concat(dfs_limpos, ignore_index=True)\n",
    "\n",
    "# Exibi√ß√£o final\n",
    "display(Markdown(\"## Dados unificados e limpos com sucesso\"))\n",
    "display(Markdown(f\"**Total de registros no `df_completo`:** `{df_completo.shape[0]}`\"))\n",
    "display(Markdown(f\"**Total de vari√°veis:** `{df_completo.shape[1]}`\"))\n",
    "display(df_completo.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Verificando se restaram valores negativos ap√≥s a limpeza\n",
    "negativos_restantes = df_completo[df_completo['vlrLiquido'] < 0]\n",
    "qtd_restantes = negativos_restantes.shape[0]\n",
    "\n",
    "# Exibir o resultado da verifica√ß√£o\n",
    "if qtd_restantes == 0:\n",
    "    display(Markdown(\" **Nenhum valor negativo encontrado na coluna `vlrLiquido`. A limpeza foi bem-sucedida!**\"))\n",
    "else:\n",
    "    display(Markdown(f\" **Ainda existem `{qtd_restantes}` registros com valores negativos em `vlrLiquido`.**\"))\n",
    "    display(negativos_restantes[['txNomeParlamentar', 'sgUF', 'sgPartido', 'vlrLiquido']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Continua√ß√£o do 3.1 Sele√ß√£o dos Dados com os dados limpos \n",
    "\n",
    "# 2Ô∏è - Sele√ß√£o de colunas relevantes e cria√ß√£o da nova feature\n",
    "colunas_selecionadas = [\n",
    "    'txNomeParlamentar', 'sgUF', 'sgPartido', 'txtDescricao',\n",
    "    'vlrDocumento', 'numMes', 'numAno', 'vlrLiquido'\n",
    "]\n",
    "\n",
    "# Cria uma nova base apenas com as colunas relevantes\n",
    "df_modelo = df_completo[colunas_selecionadas].copy()\n",
    "\n",
    "# 3Ô∏è - Cria√ß√£o da coluna de custo total por parlamentar\n",
    "df_modelo['custo_total_parlamentar'] = df_modelo.groupby('txNomeParlamentar')['vlrLiquido'].transform('sum')\n",
    "\n",
    "# 4Ô∏è - Exibi√ß√£o final\n",
    "from IPython.display import display, Markdown\n",
    "display(Markdown(\"### Amostra da base `df_modelo` com coluna `custo_total_parlamentar`:\"))\n",
    "display(df_modelo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1Ô∏è Identificar registros com valores ausentes\n",
    "na_total = df_modelo.isnull().sum().sum()\n",
    "linhas_nan = df_modelo[df_modelo.isnull().any(axis=1)]\n",
    "\n",
    "display(Markdown(\"## Verifica√ß√£o de valores ausentes (`NaN`) em `df_modelo`\"))\n",
    "display(Markdown(f\"**Total de registros com valores ausentes:** `{linhas_nan.shape[0]}`\"))\n",
    "display(Markdown(f\"**Total de valores `NaN` na base:** `{na_total}`\"))\n",
    "\n",
    "if linhas_nan.shape[0] > 0:\n",
    "    display(Markdown(\"**Exemplo de registros com valores ausentes:**\"))\n",
    "    display(linhas_nan.head())\n",
    "\n",
    "# 2Ô∏è Remover registros com qualquer valor ausente\n",
    "df_modelo = df_modelo.dropna().reset_index(drop=True)\n",
    "\n",
    "# 3Ô∏è Exibir como ficou a base depois da limpeza\n",
    "display(Markdown(\"##  `df_modelo` ap√≥s remo√ß√£o dos registros com valores ausentes\"))\n",
    "display(Markdown(f\"**Total de registros restantes:** `{df_modelo.shape[0]}`\"))\n",
    "display(Markdown(f\"**Total de colunas:** `{df_modelo.shape[1]}`\"))\n",
    "display(df_modelo.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover registros onde vlrLiquido > vlrDocumento\n",
    "df_modelo = df_modelo[df_modelo['vlrLiquido'] <= df_modelo['vlrDocumento']].reset_index(drop=True)\n",
    "\n",
    "display(Markdown(\"‚úÖ **Registros inconsistentes removidos com sucesso!**\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar a coluna faixa_valor com base no valor l√≠quido\n",
    "df_modelo['faixa_valor'] = pd.cut(\n",
    "    df_modelo['vlrLiquido'],\n",
    "    bins=[0, 250, 1000, 2500, 10000, float('inf')],\n",
    "    labels=['Muito Baixo', 'Baixo', 'M√©dio', 'Alto', 'Muito Alto']\n",
    ")\n",
    "\n",
    "display(Markdown(\"‚úÖ **Coluna `faixa_valor` recriada com sucesso!**\"))\n",
    "display(df_modelo[['vlrLiquido', 'faixa_valor']].sample(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Nesta etapa, realizamos um processo criterioso de saneamento da base de dados, com o objetivo de **garantir a integridade, consist√™ncia e confiabilidade das informa√ß√µes** que alimentar√£o os modelos de aprendizado supervisionado.\n",
    "\n",
    "A limpeza dos dados √© uma fase cr√≠tica, pois **modelos de Machine Learning s√£o altamente sens√≠veis a ru√≠dos, valores inv√°lidos e informa√ß√µes incompletas**. Um dado inconsistente pode comprometer toda a performance do modelo ‚Äî e pior, gerar conclus√µes enganosas para decis√µes reais.\n",
    "\n",
    "### A√ß√µes realizadas:\n",
    "\n",
    "1. **Remo√ß√£o de valores negativos em `vlrLiquido`:**  \n",
    "   Foram detectados e eliminados milhares de registros com valores negativos, o que representa **erros claros de entrada de dados**. Como o `vlrLiquido` representa o valor final pago em uma despesa, n√£o √© plaus√≠vel que ele seja negativo.\n",
    "\n",
    "2. **Elimina√ß√£o de registros com `vlrLiquido` maior que `vlrDocumento`:**  \n",
    "   Foram identificados **2 registros** em que o valor l√≠quido ultrapassava o valor bruto do documento, o que √© logicamente incorreto. Esses registros foram removidos.\n",
    "\n",
    "3. **Remo√ß√£o de valores ausentes (`NaN`)**  \n",
    "   Ap√≥s as transforma√ß√µes e constru√ß√µes de vari√°veis, foram encontrados **2.135 registros com valores ausentes** em colunas relevantes. Esses registros foram removidos para **evitar vi√©s nos algoritmos de predi√ß√£o** e assegurar que todas as vari√°veis estejam completas.\n",
    "\n",
    "4. **Exclus√£o de colunas irrelevantes ao modelo:**  \n",
    "   Diversas colunas foram descartadas por n√£o contribu√≠rem para a modelagem ou por conterem informa√ß√µes sens√≠veis e desnecess√°rias (como CPF, CNPJ, c√≥digos internos da C√¢mara, etc.).\n",
    "\n",
    "5. **Reconstru√ß√£o da vari√°vel `faixa_valor`:**  \n",
    "   Foi recriada uma vari√°vel categ√≥rica com base no valor l√≠quido (`vlrLiquido`), segmentando os gastos em faixas como:\n",
    "   - Muito Baixo (at√© R$250)\n",
    "   - Baixo (at√© R$1.000)\n",
    "   - M√©dio (at√© R$2.500)\n",
    "   - Alto (at√© R$10.000)\n",
    "   - Muito Alto (acima de R$10.000)\n",
    "\n",
    "   Essa vari√°vel poder√° ser **utilizada em an√°lises estat√≠sticas, visualiza√ß√µes e at√© como feature para modelos classificat√≥rios**.\n",
    "\n",
    "---\n",
    "\n",
    "### Benef√≠cios diretos dessa etapa:\n",
    "\n",
    "- **Redu√ß√£o de ru√≠dos** que impactariam negativamente na acur√°cia dos modelos.\n",
    "- **Evita o overfitting** com dados duplicados ou corrompidos.\n",
    "- **Aumenta a confiabilidade das previs√µes**, ao garantir que os dados sigam uma l√≥gica de neg√≥cios clara.\n",
    "- **Permite extra√ß√£o de insights mais precisos**, facilitando compara√ß√µes, agrupamentos e an√°lises de tend√™ncia.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrQDOkhBQq2h"
   },
   "source": [
    "## 3.3 Constru√ß√£o de Dados Derivados   <a class=\"anchor\" id=\"dados-derivados\"></a>\n",
    "\n",
    "\n",
    "Nesta etapa do CRISP-DM, realizamos a **engenharia de atributos** ‚Äî um passo estrat√©gico onde criamos novas vari√°veis a partir das j√° existentes com o objetivo de enriquecer a base de dados, ampliar a capacidade preditiva dos modelos e facilitar an√°lises explorat√≥rias.\n",
    "\n",
    "### Objetivo\n",
    "Criar **atributos derivados** que ajudem a capturar padr√µes de comportamento de gastos dos parlamentares ao longo do tempo, considerando vari√°veis como UF, partido pol√≠tico e tipos de despesas.\n",
    "\n",
    "---\n",
    "\n",
    "### Vari√°veis Derivadas Criadas:\n",
    "\n",
    "1. **`gasto_uf`**: soma do valor l√≠quido (`vlrLiquido`) por UF  \n",
    "   ‚Üí Ajuda a entender qual estado apresenta maior volume de gastos.\n",
    "\n",
    "2. **`gasto_partido`**: soma do valor l√≠quido por partido pol√≠tico (`sgPartido`)  \n",
    "   ‚Üí Permite investigar se h√° padr√£o de gasto por filia√ß√£o partid√°ria.\n",
    "\n",
    "3. **`vlr_medio_por_tipo`**: valor m√©dio por tipo de despesa (`txtDescricao`)  \n",
    "   ‚Üí Evidencia quais tipos de despesa t√™m maior custo m√©dio.\n",
    "\n",
    "4. **`ano_mes`**: coluna criada combinando `numAno` e `numMes`  \n",
    "   ‚Üí Facilita an√°lises temporais e s√©ries hist√≥ricas.\n",
    "\n",
    "5. **`faixa_valor`**: categoriza√ß√£o dos valores l√≠quidos em faixas (\"At√© 500\", \"500‚Äì1000\", \"1000‚Äì2000\", \"Acima de 2000\")  \n",
    "   ‚Üí Essencial para entender a distribui√ß√£o dos valores e criar segmenta√ß√µes visuais.\n",
    "\n",
    "---\n",
    "\n",
    "### Benef√≠cios das vari√°veis derivadas para o modelo\n",
    "\n",
    "-  **Aumentam o poder explicativo dos modelos supervisionados**, ao fornecer mais contexto.\n",
    "-  **Melhoram a visualiza√ß√£o e a interpreta√ß√£o dos dados**, tanto em an√°lises explorat√≥rias quanto em relat√≥rios gerenciais.\n",
    "-  **Permitem identificar padr√µes, desvios ou inconsist√™ncias** com mais facilidade.\n",
    "-  **Transformam dados brutos em informa√ß√µes mais robustas e contextualizadas**, aproximando os dados da realidade do neg√≥cio.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "cG1gaT08Qq2h"
   },
   "outputs": [],
   "source": [
    "# 3.3 Constru√ß√£o de Dados Derivados\n",
    "\n",
    "\n",
    "# M√©dia de gastos mensais por parlamentar\n",
    "gastos_mensais = df_modelo.groupby(['txNomeParlamentar', 'numAno', 'numMes'])['vlrLiquido'].sum().reset_index()\n",
    "media_mensal = gastos_mensais.groupby('txNomeParlamentar')['vlrLiquido'].mean()\n",
    "df_modelo['media_mensal_parlamentar'] = df_modelo['txNomeParlamentar'].map(media_mensal)\n",
    "\n",
    "# Total de gasto por UF\n",
    "gasto_uf = df_modelo.groupby('sgUF')['vlrLiquido'].sum()\n",
    "df_modelo['gasto_uf'] = df_modelo['sgUF'].map(gasto_uf)\n",
    "\n",
    "# Total de gasto por partido\n",
    "gasto_partido = df_modelo.groupby('sgPartido')['vlrLiquido'].sum()\n",
    "df_modelo['gasto_partido'] = df_modelo['sgPartido'].map(gasto_partido)\n",
    "\n",
    "# Quantidade de despesas por parlamentar\n",
    "qtd_despesas = df_modelo['txNomeParlamentar'].value_counts()\n",
    "df_modelo['qtd_despesas_parlamentar'] = df_modelo['txNomeParlamentar'].map(qtd_despesas)\n",
    "\n",
    "# Valor m√©dio por tipo de despesa\n",
    "vlr_medio_tipo = df_modelo.groupby('txtDescricao')['vlrLiquido'].mean()\n",
    "df_modelo['vlr_medio_por_tipo'] = df_modelo['txtDescricao'].map(vlr_medio_tipo)\n",
    "\n",
    "# Exibi√ß√£o\n",
    "display(Markdown(\"## Novas vari√°veis derivadas adicionadas com sucesso\"))\n",
    "display(Markdown(f\"**Shape atual do `df_modelo`:** {df_modelo.shape[0]} registros e {df_modelo.shape[1]} colunas\"))\n",
    "display(df_modelo.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdig3vgbQq2i"
   },
   "source": [
    "## 3.4 Integra√ß√£o de Dados  <a class=\"anchor\" id=\"integracao-dados\"></a>\n",
    "\n",
    "\n",
    "Nesta etapa, consolidamos os dados de diferentes anos (2023, 2024 e 2025) em um √∫nico DataFrame (`df_completo`). Isso foi fundamental para garantir que a an√°lise futura tenha **vis√£o longitudinal** e **comparabilidade temporal**.\n",
    "\n",
    "### A√ß√µes realizadas:\n",
    "- Leitura dos arquivos separados por ano, com estrutura padronizada\n",
    "- Convers√£o de tipos de dados (ex: `vlrLiquido` como float)\n",
    "- Inclus√£o da coluna `ano_base` para identifica√ß√£o da origem temporal\n",
    "- Remo√ß√£o de registros inv√°lidos (valores negativos, `NaN`)\n",
    "- Elimina√ß√£o de registros duplicados\n",
    "- Concatena√ß√£o das tr√™s bases em um √∫nico conjunto integrado\n",
    "\n",
    "### Benef√≠cios da Integra√ß√£o:\n",
    "- Permite an√°lises hist√≥ricas e temporais\n",
    "- Garante coes√£o estrutural para uso em modelos preditivos\n",
    "- Aumenta o volume de dados, fortalecendo a robustez estat√≠stica\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Fdb51UHGQq2i",
    "outputId": "44ddea98-0ea3-431e-e3a0-bb2ca60929d9"
   },
   "outputs": [],
   "source": [
    "# Verificando se existe a coluna 'ano_base'\n",
    "print(df_completo['ano_base'].unique())  # Deve retornar: [2023, 2024, 2025]\n",
    "\n",
    "# Verificando a quantidade de registros por ano\n",
    "df_completo['ano_base'].value_counts()\n",
    "\n",
    "# Verificando duplicatas (caso j√° n√£o tenha sido feito)\n",
    "duplicatas = df_completo.duplicated()\n",
    "print(f\"Total de registros duplicados: {duplicatas.sum()}\")\n",
    "\n",
    "display(Markdown(\"\"\"\n",
    "### üîó Integra√ß√£o de Dados Realizada com Sucesso\n",
    "\n",
    "Durante a etapa 3.4 da metodologia CRISP-DM, realizamos a integra√ß√£o das bases hist√≥ricas de **gastos parlamentares dos anos de 2023, 2024 e 2025**. A consolida√ß√£o foi feita com base na padroniza√ß√£o das colunas e no uso da vari√°vel `ano_base` para identificar a origem de cada registro.\n",
    "\n",
    "#### ‚úÖ Valida√ß√µes realizadas:\n",
    "\n",
    "- **Anos presentes na base integrada**: `2023`, `2024`, `2025`\n",
    "- **Verifica√ß√£o de duplicatas**: Nenhum registro duplicado encontrado (`0 registros duplicados`)\n",
    "\n",
    "Essas valida√ß√µes garantem que o `DataFrame df_completo` est√° pronto para ser utilizado nas pr√≥ximas etapas do projeto, com **confian√ßa na qualidade e integridade dos dados**.\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBP0giRBQq2i"
   },
   "source": [
    "### Construct Our Primary Data Set\n",
    "Join data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. An√°lise Explorat√≥ria dos Dados (EDA) <a class=\"anchor\" id=\"analise-dados\"></a>\n",
    "\n",
    "A fase de An√°lise Explorat√≥ria de Dados (EDA) √© crucial para aprofundar nosso entendimento sobre as despesas parlamentares. O objetivo aqui √© utilizar visualiza√ß√µes e estat√≠sticas para descobrir padr√µes, identificar anomalias e responder √†s quest√µes explorat√≥rias que levantamos na primeira fase do projeto.\n",
    "Para conduzir esta an√°lise de forma estruturada, seguiremos um caminho que vai do geral ao espec√≠fico, dividido em tr√™s abordagens principais:\n",
    "\n",
    "1.  **Vis√£o Agregada dos Gastos:** Iniciaremos com uma vis√£o macro, utilizando gr√°ficos de barras para identificar os principais atores e fatores de custo. Analisaremos os totais e m√©dias de gastos para responder a perguntas como:\n",
    "    * Quais parlamentares acumularam os maiores custos?\n",
    "\n",
    "    * Quais UFs e Partidos concentram o maior volume financeiro?\n",
    "    * Quais tipos de despesa possuem o maior valor m√©dio por transa√ß√£o?\n",
    "\n",
    "2.  **An√°lise da Distribui√ß√£o dos Valores:** Em seguida, vamos al√©m dos totais e m√©dias. Com o uso de boxplots, investigaremos a **distribui√ß√£o** dos valores de despesa (`vlrLiquido`) dentro das principais categorias (Partido e UF). Isso nos ajudar√° a entender a variabilidade, a mediana dos gastos e a presen√ßa de valores discrepantes em cada grupo.\n",
    "\n",
    "3.  **An√°lise de Perfil Espec√≠fico (Drill-Down):** Por fim, faremos uma an√°lise de \"drill-down\", focando em um insight espec√≠fico obtido na primeira etapa. Vamos isolar o parlamentar com o maior gasto acumulado e investigar em detalhe o seu perfil de despesas, entendendo quais s√£o suas categorias mais frequentes.\n",
    "\n",
    "Ao final desta se√ß√£o, teremos um conjunto de insights visuais que n√£o apenas respondem √†s nossas quest√µes, mas tamb√©m fornecem uma base s√≥lida para as decis√µes que tomaremos na etapa de **Modelagem**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **An√°lise das Principais Dimens√µes de Gasto**\n",
    "\n",
    "\n",
    "### 1Ô∏è - Top 5 Parlamentares por Custo Total\n",
    "> **O que mostra:** Os parlamentares com maior volume de gastos no per√≠odo analisado.  \n",
    "> **Insight:** Permite identificar concentra√ß√µes de gastos por indiv√≠duo e investigar comportamentos fora do padr√£o.\n",
    "\n",
    "### 2Ô∏è - Top 10 UFs por Gastos\n",
    "> **O que mostra:** Os estados da federa√ß√£o com maior soma de despesas parlamentares.  \n",
    "> **Insight:** Auxilia a visualizar a distribui√ß√£o geogr√°fica dos gastos.\n",
    "\n",
    "### 3Ô∏è - Top 10 Partidos por Gastos\n",
    "> **O que mostra:** Os partidos pol√≠ticos com maiores gastos m√©dios agregados.  \n",
    "> **Insight:** Pode revelar padr√µes partid√°rios nos gastos, com poss√≠veis implica√ß√µes pol√≠ticas.\n",
    "\n",
    "### 4Ô∏è - Tipos de Despesa com Maior Valor M√©dio\n",
    "> **O que mostra:** Quais tipos de despesa apresentam maior m√©dia de valores reembolsados.  \n",
    "> **Insight:** Ajuda a identificar os tipos de gastos mais onerosos, que podem demandar auditoria ou justificativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√≥digo para visualiza√ß√µes agregadas com Plotly\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "# Define um template padr√£o para o Plotly\n",
    "pio.templates.default = \"plotly_white\"\n",
    "df_modelo = pd.DataFrame(df_completo)\n",
    "\n",
    "# Fun√ß√£o para formatar como R$ com ponto de milhar e v√≠rgula decimal\n",
    "def formatar_valor(valor):\n",
    "# Garante que est√° lidando com o DataFrame correto\n",
    "    return f\"R$ {valor:,.2f}\".replace(\",\", \"X\").replace(\".\", \",\").replace(\"X\", \".\")\n",
    "\n",
    "# 1Ô∏è Top 5 Parlamentares por Custo Total\n",
    "top_parlamentares = (\n",
    "    df_modelo.groupby('txNomeParlamentar')['custo_total_parlamentar']\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(5)\n",
    "    .reset_index()\n",
    ")\n",
    "top_parlamentares['texto'] = top_parlamentares['custo_total_parlamentar'].apply(formatar_valor)\n",
    "\n",
    "fig1 = px.bar(\n",
    "    top_parlamentares,\n",
    "    x='custo_total_parlamentar',\n",
    "    y='txNomeParlamentar',\n",
    "    orientation='h',\n",
    "    title='<b>Top 5 Parlamentares por Custo Total Acumulado</b>',\n",
    "    labels={'custo_total_parlamentar': 'Custo Total (R$)', 'txNomeParlamentar': 'Parlamentar'},\n",
    "    text='texto'\n",
    ")\n",
    "fig1.update_layout(showlegend=False, yaxis={'categoryorder':'total ascending'})\n",
    "fig1.update_traces(textposition='outside', marker_color='#636EFA')\n",
    "\n",
    "\n",
    "# 2Ô∏è Top 10 UFs por Gasto Total\n",
    "top_ufs = (\n",
    "    df_modelo.groupby('sgUF')['gasto_uf']\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(10)\n",
    "    .reset_index()\n",
    ")\n",
    "top_ufs['texto'] = top_ufs['gasto_uf'].apply(formatar_valor)\n",
    "\n",
    "fig2 = px.bar(\n",
    "    top_ufs,\n",
    "    x='gasto_uf',\n",
    "    y='sgUF',\n",
    "    orientation='h',\n",
    "    title='<b>Top 10 UFs por Gastos Totais</b>',\n",
    "    labels={'gasto_uf': 'Gasto Total (R$)', 'sgUF': 'UF'},\n",
    "    text='texto'\n",
    ")\n",
    "fig2.update_layout(showlegend=False, yaxis={'categoryorder':'total ascending'})\n",
    "fig2.update_traces(textposition='outside', marker_color='#EF553B')\n",
    "\n",
    "\n",
    "# 3Ô∏è Top 10 Partidos por Gasto Total\n",
    "top_partidos = (\n",
    "    df_modelo.groupby('sgPartido')['gasto_partido']\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(10)\n",
    "    .reset_index()\n",
    ")\n",
    "top_partidos['texto'] = top_partidos['gasto_partido'].apply(formatar_valor)\n",
    "\n",
    "fig3 = px.bar(\n",
    "    top_partidos,\n",
    "    x='gasto_partido',\n",
    "    y='sgPartido',\n",
    "    orientation='h',\n",
    "    title='<b>Top 10 Partidos por Gastos Totais</b>',\n",
    "    labels={'gasto_partido': 'Gasto Total (R$)', 'sgPartido': 'Partido'},\n",
    "    text='texto'\n",
    ")\n",
    "fig3.update_layout(showlegend=False, yaxis={'categoryorder':'total ascending'})\n",
    "fig3.update_traces(textposition='outside', marker_color='#00CC96')\n",
    "\n",
    "\n",
    "# 4Ô∏è Top 10 Tipos de Despesa por Valor M√©dio\n",
    "top_tipos = (\n",
    "    df_modelo.groupby('txtDescricao')['vlr_medio_por_tipo']\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(10)\n",
    "    .reset_index()\n",
    ")\n",
    "top_tipos['texto'] = top_tipos['vlr_medio_por_tipo'].apply(formatar_valor)\n",
    "\n",
    "fig4 = px.bar(\n",
    "    top_tipos,\n",
    "    x='vlr_medio_por_tipo',\n",
    "    y='txtDescricao',\n",
    "    orientation='v',\n",
    "    title='<b>Top 10 Tipos de Despesa com Maior Valor M√©dio por Transa√ß√£o</b>',\n",
    "    labels={'vlr_medio_por_tipo': 'Valor M√©dio (R$)', 'txtDescricao': 'Tipo de Despesa'},\n",
    "    text='texto'\n",
    ")\n",
    "fig4.update_layout(showlegend=False, yaxis={'categoryorder':'total ascending'})\n",
    "fig4.update_traces(textposition='outside', marker_color='#AB63FA')\n",
    "\n",
    "\n",
    "# Exibir os gr√°ficos\n",
    "fig1.show()\n",
    "fig2.show()\n",
    "fig3.show()\n",
    "fig4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **An√°lise Bivariada e Multivariada**\n",
    "\n",
    "Nesta se√ß√£o, cruzamos vari√°veis para encontrar rela√ß√µes e padr√µes mais complexos. Vamos focar em como o valor das despesas (`vlrLiquido`) varia entre as diferentes categorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para plotar boxplots interativos com Plotly\n",
    "def plot_boxplot_by_category(df, category_col, value_col, title, n=10):\n",
    "    top_categories = df[category_col].value_counts().nlargest(n).index\n",
    "    df_filtered = df[df[category_col].isin(top_categories)]\n",
    "    \n",
    "    fig = px.box(df_filtered, \n",
    "                 x=category_col, \n",
    "                 y=value_col,\n",
    "                 title=title,\n",
    "                 points=False) # 'points=False' para n√£o poluir com outliers\n",
    "    fig.update_layout(xaxis={'categoryorder':'total descending'})\n",
    "    fig.show()\n",
    "\n",
    "# Gasto por Partido\n",
    "plot_boxplot_by_category(df_modelo, 'sgPartido', 'vlrLiquido', 'Distribui√ß√£o do Valor L√≠quido por Partido (Top 10)')\n",
    "\n",
    "# Gasto por UF\n",
    "plot_boxplot_by_category(df_modelo, 'sgUF', 'vlrLiquido', 'Distribui√ß√£o do Valor L√≠quido por UF (Top 10)')\n",
    "\n",
    "\n",
    "display(Markdown(\"\"\"\n",
    "**Interpreta√ß√£o:**\n",
    "* **Valor por Partido:** Os boxplots mostram a mediana, os quartis e a dispers√£o dos valores de despesa por partido. Embora a frequ√™ncia seja alta para PL e PT, a an√°lise dos valores pode revelar que outros partidos t√™m despesas com mediana ou valores m√°ximos mais altos. √â importante observar a altura das \"caixas\" (intervalo interquartil) e a posi√ß√£o da linha da mediana.\n",
    "\"\"\"))\n",
    "\n",
    "\n",
    "* **Valor por UF:** Alguns estados podem ter uma mediana de gastos mais alta que outros, mesmo com menos registros. Isso pode ser devido a custos de vida regionais mais altos ou a uma cultura de gastos diferente entre as bancadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **An√°lise de Perfil Detalhada**\n",
    "\n",
    "A EDA tamb√©m serve para aprofundar a an√°lise em pontos de interesse. Vamos investigar o perfil de gasto do parlamentar que mais gastou e, em seguida, analisar quais partidos mais utilizam o tipo de despesa de maior valor m√©dio.\n",
    "\n",
    "#### **Perfil de Gastos do Top 1 Parlamentar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Identificar o parlamentar com o maior custo total\n",
    "top_parlamentar_nome = top_parlamentares.iloc[0]['txNomeParlamentar']\n",
    "\n",
    "# 2. Filtrar o DataFrame para conter apenas as despesas desse parlamentar\n",
    "df_top_parlamentar = df_modelo[df_modelo['txNomeParlamentar'] == top_parlamentar_nome]\n",
    "\n",
    "# 3. Gerar um gr√°fico dos tipos de despesa para esse parlamentar\n",
    "fig = px.bar(\n",
    "    df_top_parlamentar['txtDescricao'].value_counts().reset_index(),\n",
    "    x='count',\n",
    "    y='txtDescricao',\n",
    "    orientation='h',\n",
    "    title=f'<b>Tipos de Despesa Mais Frequentes para: {top_parlamentar_nome}</b>',\n",
    "    labels={'count': 'Frequ√™ncia', 'txtDescricao': 'Tipo de Despesa'}\n",
    ")\n",
    "fig.update_layout(yaxis={'categoryorder':'total ascending'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvEceHzUQq2j"
   },
   "source": [
    "# 5. Modelagem <a class=\"anchor\" id=\"modelagem\"></a>\n",
    "As the first step in modelling, you'll select the actual modelling technique that you'll be using. Although you may have already selected a tool during the business understanding phase, at this stage you'll be selecting the specific modelling technique e.g. decision-tree building with C5.0, or neural network generation with back propagation. If multiple techniques are applied, perform this task separately for each technique.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9H-GXDBNQq2j"
   },
   "source": [
    "## 5.1. T√©cnicas de Modelagem <a class=\"anchor\" id=\"tecnicas-modelagem\"></a>\n",
    "Document the actual modelling technique that is to be used.\n",
    "\n",
    "Import Models below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "nhhwoVkVQq2k"
   },
   "outputs": [],
   "source": [
    "X = df.drop('y', axis=1)\n",
    "y = df['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uFK8exaK-68S"
   },
   "outputs": [],
   "source": [
    "# Normaliza√ß√£o dos dados num√©ricos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "categorical_features = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
    "numeric_features = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8ClvOxXQq2k"
   },
   "source": [
    "## 5.2. Teste de Modelos <a class=\"anchor\" id=\"teste-modelos\"></a>\n",
    "Many modelling techniques make specific assumptions about the data, for example that all attributes have uniform distributions, no missing values allowed, class attribute must be symbolic etc. Record any assumptions made.\n",
    "\n",
    "-\n",
    "-\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUz08h6RBC1a"
   },
   "outputs": [],
   "source": [
    "pipeline_lr = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(C=1.0, solver='liblinear'))\n",
    "])\n",
    "\n",
    "pipeline_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2))\n",
    "])\n",
    "\n",
    "pipeline_gb = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQFDFtQoQq2k"
   },
   "source": [
    "## 5.3. Constru√ß√£o do Modelo (Build) <a class=\"anchor\" id=\"construcao-modelo\"></a>\n",
    "Run the modelling tool on the prepared dataset to create one or more models.\n",
    "\n",
    "**Parameter settings** - With any modelling tool there are often a large number of parameters that can be adjusted. List the parameters and their chosen values, along with the rationale for the choice of parameter settings.\n",
    "\n",
    "**Models** - These are the actual models produced by the modelling tool, not a report on the models.\n",
    "\n",
    "**Model descriptions** - Describe the resulting models, report on the interpretation of the models and document any difficulties encountered with their meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192
    },
    "collapsed": true,
    "id": "JFUvxZVmQq2k",
    "outputId": "418627bc-a187-4460-b50f-bf8f876e8e59"
   },
   "outputs": [],
   "source": [
    "pipeline_lr.fit(X_train, y_train)\n",
    "pipeline_rf.fit(X_train, y_train)\n",
    "pipeline_gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZL6W-w7YQq2k"
   },
   "source": [
    "## 5.4. Avalia√ß√£o de Performance <a class=\"anchor\" id=\"avaliacao-modelo\"></a>\n",
    "Interpret the models according to your domain knowledge, your data mining success criteria and your desired test design. Judge the success of the application of modelling and discovery techniques technically, then contact business analysts and domain experts later in order to discuss the data mining results in the business context. This task only considers models, whereas the evaluation phase also takes into account all other results that were produced in the course of the project.\n",
    "\n",
    "At this stage you should rank the models and assess them according to the evaluation criteria. You should take the business objectives and business success criteria into account as far as you can here. In most data mining projects a single technique is applied more than once and data mining results are generated with several different techniques.\n",
    "\n",
    "**Model assessment** - Summarise the results of this task, list the qualities of your generated models (e.g.in terms of accuracy) and rank their quality in relation to each other.\n",
    "\n",
    "**Revised parameter settings** - According to the model assessment, revise parameter settings and tune them for the next modelling run. Iterate model building and assessment until you strongly believe that you have found the best model(s). Document all such revisions and assessments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U1YFLClIQq2k",
    "outputId": "bfdbddad-824f-4a40-96cb-6cec08c7cb7d"
   },
   "outputs": [],
   "source": [
    "model_metrics = {}\n",
    "\n",
    "# Lista de modelos para avaliar\n",
    "models = ['lr', 'rf', 'gb']\n",
    "\n",
    "for model_key in models:\n",
    "    try:\n",
    "        pipelines[model_key].fit(X_train, y_train)\n",
    "\n",
    "        y_pred = pipelines[model_key].predict(X_test)\n",
    "        y_proba = pipelines[model_key].predict_proba(X_test)[:, 1]  # Probabilidades para AUC-ROC\n",
    "\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        auc_roc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "        model_metrics[model_key] = {\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1-Score': f1,\n",
    "            'AUC-ROC': auc_roc\n",
    "        }\n",
    "\n",
    "        print(f\"Resultados para {model_key}:\")\n",
    "        print(f\"Precis√£o: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1-Score: {f1:.4f}\")\n",
    "        print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "        print(\"-----\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao treinar ou avaliar o modelo {model_key}: {e}\")\n",
    "\n",
    "for model_key in models:\n",
    "    try:\n",
    "        y_pred = pipelines[model_key].predict(X_test)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        print(f\"Matriz de Confus√£o para {model_key}:\")\n",
    "        print(cm)\n",
    "        print(\"-----\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao gerar matriz de confus√£o para {model_key}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Avalia√ß√£o do Modelo <a class=\"anchor\" id=\"avaliacao-modelo\"></a>\n",
    "\n",
    "## 6.1. Regress√£o Log√≠stica (lr): <a class=\"anchor\" id=\"regressao-logistica\"></a>\n",
    "\n",
    "Precis√£o: 69.26% - Este modelo tem uma boa taxa de precis√£o, indicando que quando prev√™ que um cliente se inscrever√°, est√° correto aproximadamente 69.26% das vezes.\n",
    "Recall: 40.30% - Capta 40.30% dos casos positivos reais, o que √© moderado.\n",
    "F1-Score: 50.95% - Um equil√≠brio razo√°vel entre precis√£o e recall.\n",
    "AUC-ROC: 92.92% - Excelente capacidade de discrimina√ß√£o entre as classes positivas e negativas.\n",
    "Matriz de Confus√£o: Com um n√∫mero relativamente baixo de falsos positivos (83) e uma quantidade moderada de falsos negativos (277).\n",
    "Random Forest (rf):\n",
    "\n",
    "Precis√£o: 65.06% - Ligeiramente inferior √† regress√£o log√≠stica em termos de precis√£o.\n",
    "Recall: 37.72% - Menor do que a regress√£o log√≠stica, indicando uma capacidade mais fraca de capturar todos os positivos reais.\n",
    "F1-Score: 47.75% - Reflete o compromisso entre precis√£o e recall inferior ao da regress√£o log√≠stica.\n",
    "AUC-ROC: 92.58% - Muito boa, mas ligeiramente inferior √† regress√£o log√≠stica.\n",
    "Matriz de Confus√£o: Mais falsos positivos (94) e falsos negativos (289) do que a regress√£o log√≠stica, indicando uma efici√™ncia geral mais baixa.\n",
    "Gradient Boosting (gb):\n",
    "\n",
    "Precis√£o: 69.42% - Similar √† regress√£o log√≠stica e ligeiramente superior ao Random Forest.\n",
    "Recall: 41.59% - O melhor recall dos tr√™s modelos, capturando uma propor√ß√£o maior de casos positivos.\n",
    "F1-Score: 52.02% - O melhor F1-Score, indicando o melhor equil√≠brio entre precis√£o e recall.\n",
    "AUC-ROC: 93.58% - A melhor das tr√™s, mostrando a superioridade do Gradient Boosting em discriminar entre as classes.\n",
    "Matriz de Confus√£o: Semelhante ao Random Forest em termos de falsos positivos, mas com menos falsos negativos, melhorando tanto a precis√£o quanto o recall.\n",
    "Conclus√µes e Recomenda√ß√µes\n",
    "Gradient Boosting parece ser o modelo mais forte em geral, apresentando o melhor equil√≠brio entre todas as m√©tricas. Com a maior AUC-ROC e o melhor F1-Score, ele demonstra uma capacidade superior de manejar a classifica√ß√£o de uma maneira equilibrada, tornando-o ideal para situa√ß√µes onde tanto a precis√£o quanto o recall s√£o importantes.\n",
    "\n",
    "Regress√£o Log√≠stica ainda se mostra uma op√ß√£o vi√°vel, especialmente se a interpretabilidade do modelo √© uma prioridade, visto que modelos lineares como este oferecem insights mais diretos sobre como as caracter√≠sticas est√£o influenciando as previs√µes.\n",
    "\n",
    "Random Forest, embora robusto e com um bom desempenho geral, parece ser ligeiramente superado pelos outros modelos em termos de m√©tricas chave neste cen√°rio espec√≠fico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Aplica√ß√£o pr√°tica (Deployment)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
