{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTNXidF3Qq2K"
   },
   "source": [
    "# **Ciência de Dados e Machine Learning**\n",
    "\n",
    "## **Projeto Final do Curso**\n",
    "\n",
    "---\n",
    "\n",
    "### **Alunos:**\n",
    "\n",
    "> Charles Bezerra - 52400351\n",
    "\n",
    "> Jheferson Warley - 52400071\n",
    "\n",
    "> Paulo Machado - 52400245\n",
    "\n",
    "---\n",
    "\n",
    "### Tema: **Despesas pela Cota para Exercício da Atividade Parlamentar**\n",
    "\n",
    "### Base de Dados: https://dadosabertos.camara.leg.br/swagger/api.html?tab=staticfile\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RfgYroaQq2N"
   },
   "source": [
    "Este projeto final do curso de **Ciência de Dados e Machine** Learning do UniCEUB se baseia na metodologia *Cross-Industry Standard Process for Data Mining - CRISP-DM* (https://www.sv-europe.com/crisp-dm-methodology/), oferecendo uma abordagem estruturada para planejar um projeto de mineração de dados de uma forma robusta.\n",
    "\n",
    "Este modelo representa uma sequência idealizada de eventos. Na prática, muitas das tarefas podem ser realizadas em uma ordem diferente, e frequentemente será necessário voltar a tarefas anteriores e repetir certas ações.\n",
    "\n",
    "<div>\n",
    "<img src=\"FasesCRISP-DM.png\" width=\"50%\">\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjrc0DUFQq2O"
   },
   "source": [
    "## **Etapas do Processo CRISP-DM**\n",
    "\n",
    "### 1. [Entendimento do Negócio](#business-understanding)\n",
    "Compreensão dos objetivos de negócio, contexto organizacional e definição das metas analíticas.\n",
    "\n",
    "- [1.1 Avaliação da Situação Atual](#avaliacao-da-situacao)\n",
    "- [1.2 Resultados Esperados](#resultados-esperados)\n",
    "- [1.3 Questões de Pesquisa](#questoes-de-pesquisa)\n",
    "<!-- - [1.4 Plano de Projeto](#plano-do-projeto) -->\n",
    "\n",
    "---\n",
    "\n",
    "### 2. [Entendimento dos Dados](#entendimento-dados)\n",
    "Exploração inicial dos dados, coleta e verificação da qualidade.\n",
    "\n",
    "- [2.1 Relatorio Inicial](#relatorio-inicial)\n",
    "- [2.2 Descrição dos Dados](#descricao-dados)\n",
    "- [2.3 Exploração dos Dados](#exploracao-dados)\n",
    "- [2.4 Verificação da Qualidade dos Dados](#qualidade-dos-dados)\n",
    "\n",
    "---\n",
    "\n",
    "### 3. [Preparação dos Dados](#preparacao-dados)\n",
    "Construção do dataset final que será utilizado para modelagem.\n",
    "\n",
    "- [3.1 Seleção dos Dados](#selecao-dados)\n",
    "- [3.2 Limpeza dos Dados](#limpeza-dados)\n",
    "- [3.3 Análise Exploratória de Dados](#analise-dados)\n",
    "\n",
    "---\n",
    "\n",
    "### 4. [Modelagem](#modelagem)\n",
    "Aplicação de técnicas de modelagem estatística ou de machine learning.\n",
    "\n",
    "- [4.1 Técnicas de Modelagem](#tecnicas-modelagem)\n",
    "- [4.2 Teste de Modelos](#teste-modelos)\n",
    "- [4.3 Construção dos Modelos](#construcao-modelo)\n",
    "- [4.4 Avaliação de Performance](#avaliacao-modelo)\n",
    "\n",
    "---\n",
    "\n",
    "### 5. [Avaliação do Modelo](#avaliacao-modelo)\n",
    "Verificação se os modelos preditivos atendem aos objetivos de negócio definidos para estimativa dos gastos parlamentares.\n",
    "\n",
    "- [5.1 Avaliação da Performance dos Modelos](#Avaliação-da-Performance-dos-Modelos)\n",
    "- [5.2 Interpretação dos Resultados](#interpretacao-dos-resultados)\n",
    "- [5.3 Revisão do Processo e Próximos Passos](#revisao-do-processo-e-proximos-passos)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 6. [Implementação (Deployment)](#implementacao)\n",
    "Entrega prática do modelo, seja em relatório, dashboard, sistema ou API.\n",
    "\n",
    "- [6.1 Planejamento da Implementação](#planejamento-implementacao)\n",
    "- [6.2 Monitoramento e Manutenção](#monitoramento)\n",
    "- [6.3 Documentação Final](#documentacao-final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pdYJHP76Qq2O"
   },
   "source": [
    "## 1. Entendimento do Negócio  <a class=\"anchor\" id=\"business-understanding\"></a>\n",
    "\n",
    "Atualmente, o cenário político brasileiro se mostra em foco, principalmente quando se trata de despesas relacionadas à sustentação do governo como todo. Neste contexto, as despesas parlamentares, limitadas por uma cota, são frequentemente noticiadas devido a seu alto custo. As cotas parlamentares variam conforme o estado do deputado e é destinado ao custeio de despesas relacionadas ao exercício do mandato. As despesas incluem passagens aéreas, locomoção, hospedagens, serviços de segurança, divulgação de atividades parlamentares e contratação de pessoal.\n",
    "\n",
    "\n",
    "A Câmara dos Deputados divulga através da plataforma de dados abertos do governo (https://dadosabertos.camara.leg.br/swagger/api.html?tab=staticfile) as despesas refentes ao consumo de cotas separadas por ano, Deputado, UF, tipo de despesas, entre outras classificações. Os arquivos podem ser baixador por ano, disponíveis desde o ano 2018, nos formatos XML, JSON, CSV, XLSX e ODS.\n",
    "\n",
    "\n",
    "Para este projeto, selecionamos os dados relativos ao ano de 2024 (ano completo mais recente) com arquivos no formato CSV para melhor tratamento dos dados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2SqAlWIyQq2P"
   },
   "source": [
    "## 1.1 Avaliação da Situação Atual<a class=\"anchor\" id=\"avaliacao-da-situacao\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFsmtXzxQq2P"
   },
   "source": [
    "A transparência nos gastos públicos tem ganhado relevância nos debates sociais e institucionais, principalmente no contexto político brasileiro. A Câmara dos Deputados disponibiliza, por meio do portal de Dados Abertos, informações detalhadas sobre a utilização da Cota para o Exercício da Atividade Parlamentar (CEAP), que contempla diversos tipos de despesas efetuadas pelos parlamentares no desempenho de suas funções.\n",
    "\n",
    "Apesar da disponibilidade dos dados, observa-se uma subutilização dessas informações por parte da sociedade civil e dos órgãos fiscalizadores. O volume e a complexidade dos dados dificultam análises diretas e conclusivas, exigindo ferramentas adequadas de tratamento, análise e visualização. Diante disso, este projeto visa utilizar técnicas de análise de dados e aprendizado de máquina para transformar os dados brutos em insights relevantes e acessíveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWxWA-87Qq2P"
   },
   "source": [
    "## 1.2 Resultados Esperados<a class=\"anchor\" id=\"resultaods-esperados\"></a>\n",
    "\n",
    "Este projeto tem como objetivo geral analisar os gastos parlamentares por meio da base de dados da CEAP, abrangendo os anos de 2023, 2024 e 2025. Os resultados esperados incluem:\n",
    "\n",
    "- Desenvolvimento de relatórios e dashboards analíticos para visualização dos dados por deputado, partido político, unidade federativa (UF), tipo de despesa, fornecedor e período (mês e ano).\n",
    "- Análises estatísticas descritivas e comparativas, a fim de identificar padrões de gastos e variações relevantes entre diferentes grupos.\n",
    "- Detecção de anomalias e possíveis irregularidades nos registros de despesas.\n",
    "- Aplicação de técnicas de aprendizado de máquina (Machine Learning) com o objetivo de construir modelos preditivos capazes de estimar os gastos parlamentares futuros por partido ou UF, com base nos dados históricos.\n",
    "\n",
    "O projeto segue a metodologia CRISP-DM, com foco na reprodutibilidade dos resultados e na criação de documentação clara e acessível."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Questões de Pesquisa<a class=\"anchor\" id=\"questoes-de-pesquisa\"></a>\n",
    "\n",
    "O projeto é orientado por um conjunto de questões exploratórias e preditivas, que servirão como guia para as etapas analíticas e de modelagem.\n",
    "\n",
    "### Questões Exploratórias\n",
    "\n",
    "- Quais partidos políticos apresentaram os maiores volumes de gasto no período analisado?\n",
    "- Quais unidades federativas concentram os maiores gastos?\n",
    "- Quais são os tipos de despesa mais recorrentes e qual seu impacto nos valores totais?\n",
    "- Como os gastos variam ao longo do tempo? Existe sazonalidade ou tendência?\n",
    "- Há fornecedores recorrentes nos maiores gastos? Qual seu perfil?\n",
    "\n",
    "### Questões Preditivas\n",
    "\n",
    "- É possível prever os gastos parlamentares futuros com base no histórico de dados?\n",
    "- Quais variáveis mais influenciam no volume de gastos (ex.: partido, UF, tipo de despesa, mês)?\n",
    "- Quais partidos ou unidades federativas têm maior propensão a apresentar aumentos nos gastos em futuros mandatos?\n",
    "\n",
    "Estas perguntas direcionam a construção dos indicadores, visualizações e modelos preditivos ao longo do projeto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4S-Y6p8VQq2R"
   },
   "source": [
    "# 2. Entendimento dos Dados <a class=\"anchor\" id=\"entendimento-dados\"></a>\n",
    "A etapa de entendimento dos dados tem como objetivo fornecer uma visão inicial e aprofundada da estrutura, conteúdo e qualidade do conjunto de dados disponível para análise. Trata-se de uma fase fundamental no processo analítico, pois permite identificar características importantes dos dados, potenciais inconsistências, ausência de valores e padrões que podem influenciar diretamente na preparação, modelagem e interpretação dos resultados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-6TQJ_4Qq2R"
   },
   "source": [
    "## 2.1 Relatório Inicial <a class=\"anchor\" id=\"relatorio-inicial\"></a>\n",
    "O conjunto de dados utilizado neste projeto refere-se às despesas parlamentares registradas na Cota para o Exercício da Atividade Parlamentar (CEAP), compreendendo os anos de 2023, 2024 e 2025. Os dados foram extraídos da API pública da Câmara dos Deputados, que disponibiliza os registros em diversos formatos. Para este trabalho, optou-se pelo formato `.csv`, considerando a facilidade de leitura e manipulação em ambientes Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "X9OlrvX3Qq2R"
   },
   "outputs": [],
   "source": [
    "# Importação das Bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from catboost import CatBoostRegressor,Pool\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from IPython.display import display, Markdown\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "# Ignora todos os FutureWarning\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "D85E5K77Qq2S"
   },
   "outputs": [],
   "source": [
    "# Leitura dos dados\n",
    "df_2023 = pd.read_csv(\"DataBase/Ano-2023.csv\", sep=\";\", encoding=\"utf-8\", low_memory=False)\n",
    "df_2024 = pd.read_csv(\"DataBase/Ano-2024.csv\", sep=\";\", encoding=\"utf-8\", low_memory=False)\n",
    "df_2025 = pd.read_csv(\"DataBase/Ano-2025.csv\", sep=\";\", encoding=\"utf-8\", low_memory=False)\n",
    "\n",
    "# Combinação dos três dataframes\n",
    "df_completo = pd.concat([df_2023, df_2024, df_2025], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibição das 5 primeiras linhas\n",
    "display(df_completo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZ8n1_pnQq2T"
   },
   "source": [
    "## 2.2 Descrição dos Dados <a class=\"anchor\" id=\"descricao-dados\"></a>\n",
    "A seguir, são apresentados o nome das colunas disponíveis no dataset e o seu formato dimensional (linhas x colunas).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A tabela abaixo apresenta a descrição de cada uma das variáveis disponíveis no conjunto de dados utilizado.\n",
    "\n",
    "| Nome da Coluna                 | Descrição                                                        |\n",
    "|-------------------------------|------------------------------------------------------------------|\n",
    "| `txNomeParlamentar`           | Nome do parlamentar                                              |\n",
    "| `cpf`                         | CPF do parlamentar (quando disponível)                          |\n",
    "| `ideCadastro`                 | ID único do parlamentar                                          |\n",
    "| `nuCarteiraParlamentar`       | Número da carteira parlamentar                                   |\n",
    "| `nuLegislatura`               | Número da legislatura em exercício                               |\n",
    "| `sgUF`                        | Unidade Federativa (estado)                                      |\n",
    "| `sgPartido`                   | Sigla do partido político                                        |\n",
    "| `codLegislatura`              | Código da legislatura                                            |\n",
    "| `numSubCota`                  | Código da subcota utilizada                                      |\n",
    "| `txtDescricao`                | Descrição da subcota                                             |\n",
    "| `numEspecificacaoSubCota`     | Código da especificação da subcota                               |\n",
    "| `txtDescricaoEspecificacao`   | Descrição detalhada da subcota                                   |\n",
    "| `txtFornecedor`               | Nome do fornecedor                                               |\n",
    "| `txtCNPJCPF`                  | CNPJ ou CPF do fornecedor                                        |\n",
    "| `txtNumero`                   | Número do documento fiscal                                       |\n",
    "| `indTipoDocumento`            | Tipo do documento (nota fiscal, recibo, etc.)                   |\n",
    "| `datEmissao`                  | Data de emissão do documento                                     |\n",
    "| `vlrDocumento`                | Valor bruto do documento                                         |\n",
    "| `vlrGlosa`                    | Valor glosado/desconsiderado                                     |\n",
    "| `vlrLiquido`                  | Valor líquido aceito                                             |\n",
    "| `numMes`                      | Mês de referência da despesa                                     |\n",
    "| `numAno`                      | Ano de referência da despesa                                     |\n",
    "| `numParcela`                  | Número da parcela, quando aplicável                              |\n",
    "| `txtPassageiro`               | Nome do passageiro (se transporte aéreo)                         |\n",
    "| `txtTrecho`                   | Trecho da viagem (ida/volta)                                     |\n",
    "| `numLote`                     | Número do lote do documento                                      |\n",
    "| `numRessarcimento`            | Número de protocolo de ressarcimento                             |\n",
    "| `datPagamentoRestituicao`     | Data do pagamento de restituição                                 |\n",
    "| `vlrRestituicao`              | Valor restituído                                                 |\n",
    "| `nuDeputadoId`                | ID único do deputado                                             |\n",
    "| `ideDocumento`                | ID do documento                                                  |\n",
    "| `urlDocumento`                | Link para o documento oficial                                    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EemJ6DTeQq2U",
    "outputId": "7aa11b1f-b976-4a2a-f622-bab9cffdd1a7"
   },
   "outputs": [],
   "source": [
    "# Nomes das colunas\n",
    "df_completo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gnj33OcMQq2U",
    "outputId": "02529b54-4038-461c-f231-2ba7e0018cc2"
   },
   "outputs": [],
   "source": [
    "# Dimensão do dataframe\n",
    "df_completo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNxTQwN_Qq2V"
   },
   "source": [
    "## 2.3 Exploração dos Dados <a class=\"anchor\" id=\"exploracao-dados\"></a>\n",
    "\n",
    "Essa etapa visa obter uma visão geral das características dos dados, incluindo tipos de variáveis, estatísticas descritivas e primeiros insights de distribuição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TwiVpT8FQq2W",
    "outputId": "ac44ac23-9621-40c0-a32a-61b7199f4960"
   },
   "outputs": [],
   "source": [
    "# Verificação de duplicatas\n",
    "qtde_duplicated = df_completo.duplicated().sum()\n",
    "print(f'Quantidade de duplicados: {qtde_duplicated}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatísticas descritivas\n",
    "df_completo.describe(include='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando valores nulos por coluna\n",
    "df_completo.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a quantidade de valores únicos em algumas colunas-chave\n",
    "print(\"UFs:\", df_completo['sgUF'].nunique())\n",
    "print(\"Partidos:\", df_completo['sgPartido'].nunique())\n",
    "print(\"Tipos de despesa:\", df_completo['txtDescricao'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribuição dos principais campos categóricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UF\n",
    "uf_counts = df_completo['sgUF'].value_counts().reset_index()\n",
    "uf_counts.columns = ['UF', 'Total de Registros']\n",
    "display(Markdown(\"### Distribuição por Unidade Federativa\"))\n",
    "plt.figure(figsize=(10,5))\n",
    "ax1 = sns.barplot(data=uf_counts, x='UF', y='Total de Registros', palette='Blues_d', legend=False, hue='UF')\n",
    "plt.title('Distribuição por Unidade Federativa')\n",
    "plt.xlabel('UF')\n",
    "plt.ylabel('Total de Registros')\n",
    "plt.xticks(rotation=45)\n",
    "for p in ax1.patches:\n",
    "    ax1.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                 ha='center', va='bottom', fontsize=9, color='black', xytext=(0, 3), textcoords='offset points')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partido\n",
    "partido_counts = df_completo['sgPartido'].value_counts().reset_index()\n",
    "partido_counts.columns = ['Partido', 'Total de Registros']\n",
    "display(Markdown(\"### Distribuição por Partido\"))\n",
    "plt.figure(figsize=(12,5))\n",
    "ax2 = sns.barplot(data=partido_counts, x='Partido', y='Total de Registros', palette='Greens_d', legend=False, hue='Partido')\n",
    "plt.title('Distribuição por Partido')\n",
    "plt.xlabel('Partido')\n",
    "plt.ylabel('Total de Registros')\n",
    "plt.xticks(rotation=45)\n",
    "for p in ax2.patches:\n",
    "    ax2.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                 ha='center', va='bottom', fontsize=9, color='black', xytext=(0, 3), textcoords='offset points')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipo de Despesa\n",
    "despesa_counts = df_completo['txtDescricao'].value_counts().reset_index()\n",
    "despesa_counts.columns = ['Tipo de Despesa', 'Total de Registros']\n",
    "display(Markdown(\"### Distribuição por Tipo de Despesa (Top 15)\"))\n",
    "plt.figure(figsize=(12,6))\n",
    "ax3 = sns.barplot(data=despesa_counts.head(15), x='Tipo de Despesa', y='Total de Registros', palette='Oranges_d', legend=False, hue='Tipo de Despesa', )\n",
    "plt.title('Distribuição por Tipo de Despesa (Top 15)')\n",
    "plt.xlabel('Tipo de Despesa')\n",
    "plt.ylabel('Total de Registros')\n",
    "plt.xticks(rotation=75)\n",
    "for p in ax3.patches:\n",
    "    ax3.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                 ha='center', va='bottom', fontsize=9, color='black', xytext=(0, 3), textcoords='offset points')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzPUggSjQq2c"
   },
   "source": [
    "## 2.4 Verificação da Qualidade dos Dados<a class=\"anchor\" id=\"qualidade-dos-dados\"></a>\n",
    "Abaixo está um resumo quantitativo da qualidade dos dados após a análise exploratória inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo geral do dataset\n",
    "resumo_geral = pd.DataFrame({\n",
    "    \"Indicador\": [\n",
    "        \"Total de registros\",\n",
    "        \"Total de variáveis (colunas)\",\n",
    "        \"Registros duplicados\",\n",
    "        \"Valores inconsistentes (vlrDocumento < vlrLiquido)\",\n",
    "        \"Total valor liquido negativo\"\n",
    "    ],\n",
    "    \"Valor\": [\n",
    "        df_completo.shape[0],\n",
    "        df_completo.shape[1],\n",
    "        df_completo.duplicated().sum(),\n",
    "        (df_completo['vlrDocumento'] < df_completo['vlrLiquido']).sum(),\n",
    "        (df_completo['vlrLiquido'] < 0 ).sum()\n",
    "    ]\n",
    "})\n",
    "\n",
    "display(Markdown(\"### Resumo Geral da Base de Dados\"))\n",
    "display(resumo_geral)\n",
    "\n",
    "# Colunas com valores nulos\n",
    "nulls = df_completo.isnull().sum()\n",
    "nulls = nulls[nulls > 0].sort_values(ascending=False).reset_index()\n",
    "nulls.columns = ['Coluna', 'Valores Nulos']\n",
    "\n",
    "display(Markdown(\"### Colunas com Valores Ausentes\"))\n",
    "display(nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcL0DjOzQq2c"
   },
   "source": [
    "# 3. Preparação dos Dados <a class=\"anchor\" id=\"preparacao-dados\"></a>\n",
    "\n",
    "\n",
    "Nesta etapa, realizamos o tratamento necessário para transformar os dados brutos em uma base estruturada e adequada para aplicação de modelos de aprendizado supervisionado. As ações incluem: seleção e limpeza de dados, geração de atributos derivados e integração das bases históricas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQjMmUM5Qq2c"
   },
   "source": [
    "## 3.1 Seleção dos Dados <a class=\"anchor\" id=\"selecao-dados\"></a>\n",
    "\n",
    "Nesta etapa inicial da **Preparação dos Dados**, realizamos a seleção criteriosa das variáveis mais relevantes para o problema de predição do **valor líquido da despesa parlamentar (`vlrLiquido`)**.\n",
    "\n",
    "O objetivo é filtrar os dados brutos e manter somente as informações que possuem **relação direta com o comportamento dos gastos parlamentares**, otimizando o desempenho dos algoritmos de machine learning.\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔸 Critérios de Seleção\n",
    "\n",
    "Selecionamos as colunas que possuem potencial explicativo e que apresentam valor informacional para o modelo supervisionado. As variáveis escolhidas foram:\n",
    "\n",
    "- **`sgUF`**: unidade federativa, que pode refletir realidades regionais de gastos.\n",
    "- **`sgPartido`**: partido político, possível fator explicativo para padrões de despesa.\n",
    "- **`txtDescricao`**: tipo de despesa (ex: alimentação, aluguel, combustível).\n",
    "- **`vlrDocumento`**: valor bruto do documento fiscal apresentado.\n",
    "- **`numAno`**: período da despesa, para análise sazonal ou temporal.\n",
    "- **`vlrLiquido`**: variável-alvo que será predita pelo modelo.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDRfR6L8Qq2d"
   },
   "source": [
    "## 3.2 Limpeza dos Dados <a class=\"anchor\" id=\"limpeza-dados\"></a>\n",
    "\n",
    "\n",
    "Nesta etapa, realizamos uma série de ações de limpeza para garantir que os dados utilizados nos modelos estejam consistentes, sem ruídos e com alta qualidade informacional. A preparação adequada dos dados é essencial para que qualquer modelo de aprendizado de máquina produza resultados confiáveis.\n",
    "\n",
    "As ações tomadas nesta fase incluem:\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔸 Remoção de Registros Inconsistentes\n",
    "\n",
    "Eliminamos os registros em que o valor líquido (`vlrLiquido`) era superior ao valor bruto do documento (`vlrDocumento`). Essa inconsistência viola a lógica financeira da base de dados e poderia comprometer análises futuras. Esses registros foram identificados, quantificados e removidos de forma criteriosa.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove linhas onde vlrLiquido > vlrDocumento\n",
    "df_modelo = df_completo[df_completo['vlrLiquido'] <= df_completo['vlrDocumento']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 🔸 Tratamento de Valores Negativos\n",
    "\n",
    "Foram identificados valores negativos na coluna `vlrLiquido` — o que não representa um cenário válido para gastos parlamentares. Esses valores estavam presentes em todas as bases de 2023, 2024 e 2025:\n",
    "\n",
    "- **2023:** 9.383 registros\n",
    "- **2024:** 10.327 registros\n",
    "- **2025:** 2.626 registros\n",
    "\n",
    "Todos foram removidos após verificação e exibição de amostras por ano. A limpeza foi validada com uma checagem final, confirmando que **nenhum valor negativo permaneceu**.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove registros onde vlrLiquido é negativo\n",
    "df_modelo = df_modelo[df_modelo['vlrLiquido'] >= 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 🔸 Eliminação de Registros com Valores Ausentes (NaN)\n",
    "\n",
    "Após a seleção e transformação das colunas relevantes, identificamos **2.135 registros com valores ausentes**, totalizando **4.270 células com `NaN`**. Esses dados foram descartados para evitar viés no processo de modelagem, uma vez que a imputação poderia comprometer a acurácia dos modelos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove registros onde a coluna 'sgUF' possui valores nulos (NaN)\n",
    "df_modelo = df_modelo[df_modelo['sgUF'].notnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove registros onde a coluna 'sgPartido' possui valores nulos (NaN)\n",
    "df_modelo = df_modelo[df_modelo['sgPartido'].notnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 🔸 Remoção de Registros Duplicados\n",
    "\n",
    "Realizamos a verificação de duplicatas no conjunto de dados e removemos entradas repetidas para garantir que cada linha representasse uma observação única. Essa prática evita sobrepeso em certas categorias e garante imparcialidade nas análises estatísticas.\n",
    "\n",
    "**Na base tratado não há registros duplicados**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 🔸 Remoção de Colunas Desnecessárias\n",
    "\n",
    "Foram excluídas colunas que não contribuíam para os objetivos do projeto, como identificadores únicos (`CPF`, `CNPJ`, códigos legislativos), atributos com alta cardinalidade ou informações redundantes. Essa etapa reduziu a complexidade do modelo e aumentou a interpretabilidade.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mantém apenas as colunas desejadas em df_modelo\n",
    "colunas_desejadas = ['sgUF', 'sgPartido', 'txtDescricao', 'numAno', 'vlrLiquido']\n",
    "df_modelo = df_modelo[colunas_desejadas].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 🔸 Conversão da coluna numAno em valor categórico\n",
    "\n",
    "Quando uma variável como numAno representa categorias (por exemplo, anos como 2019, 2020, 2021 etc.) e não uma medida contínua, faz total sentido tratá-la como variável categórica. Isso evita que o modelo interprete erroneamente relações ordinais ou contínuas entre os anos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo['numAno'] = df_modelo['numAno'].astype('int').astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 🔸 Agregação através da soma do vlrLiquido\n",
    "\n",
    "Agregação através da soma do vlrLiquido, classificado pelos demais campos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um novo DataFrame agregando pela soma do vlrLiquido\n",
    "df_modelo = (\n",
    "    df_modelo\n",
    "    .groupby(['sgUF', 'sgPartido', 'txtDescricao', 'numAno'], as_index=False)\n",
    "    .agg(vlrLiquidoTotal=('vlrLiquido', 'sum'))\n",
    ")\n",
    "\n",
    "\n",
    "# Exibe as primeiras linhas do novo DataFrame\n",
    "display(df_modelo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "###  Resultado Final\n",
    "\n",
    "Após todas as etapas de limpeza, o novo DataFrame final (`df_modelo`) apresenta:\n",
    "\n",
    "- **6490 registros**\n",
    "- **5 colunas relevantes**\n",
    "- Nenhum valor `NaN` ou negativo\n",
    "- Dados prontos para modelagem supervisionada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "####  Amostra dos dados tratados:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Nesta etapa, realizamos um processo criterioso de saneamento da base de dados, com o objetivo de **garantir a integridade, consistência e confiabilidade das informações** que alimentarão os modelos de aprendizado supervisionado.\n",
    "\n",
    "A limpeza dos dados é uma fase crítica, pois **modelos de Machine Learning são altamente sensíveis a ruídos, valores inválidos e informações incompletas**. Um dado inconsistente pode comprometer toda a performance do modelo — e pior, gerar conclusões enganosas para decisões reais.\n",
    "\n",
    "### Ações realizadas:\n",
    "\n",
    "1. **Remoção de valores negativos em `vlrLiquido`:**  \n",
    "   Foram detectados e eliminados milhares de registros com valores negativos, o que representa **erros claros de entrada de dados**. Como o `vlrLiquido` representa o valor final pago em uma despesa, não é plausível que ele seja negativo.\n",
    "\n",
    "2. **Eliminação de registros com `vlrLiquido` maior que `vlrDocumento`:**  \n",
    "   Foram identificados **2 registros** em que o valor líquido ultrapassava o valor bruto do documento, o que é logicamente incorreto. Esses registros foram removidos.\n",
    "\n",
    "3. **Remoção de valores ausentes (`NaN`)**  \n",
    "   Após as transformações e construções de variáveis, foram encontrados **2.135 registros com valores ausentes** em colunas relevantes. Esses registros foram removidos para **evitar viés nos algoritmos de predição** e assegurar que todas as variáveis estejam completas.\n",
    "\n",
    "4. **Exclusão de colunas irrelevantes ao modelo:**  \n",
    "   Diversas colunas foram descartadas por não contribuírem para a modelagem ou por conterem informações sensíveis e desnecessárias (como CPF, CNPJ, códigos internos da Câmara, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "### Benefícios diretos dessa etapa:\n",
    "\n",
    "- **Redução de ruídos** que impactariam negativamente na acurácia dos modelos.\n",
    "- **Evita o overfitting** com dados duplicados ou corrompidos.\n",
    "- **Aumenta a confiabilidade das previsões**, ao garantir que os dados sigam uma lógica de negócios clara.\n",
    "- **Permite extração de insights mais precisos**, facilitando comparações, agrupamentos e análises de tendência.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Análise Exploratória dos Dados (EDA) <a class=\"anchor\" id=\"analise-dados\"></a>\n",
    "\n",
    "\n",
    "A análise exploratória foi fundamental para entender o comportamento dos gastos parlamentares e detectar padrões interessantes no dataset. Abaixo, são apresentados os principais destaques visuais:\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 UFs com Maior Média de Gastos\n",
    "\n",
    "O primeiro gráfico mostra a média dos valores líquidos por Unidade Federativa (UF). A visualização permite identificar quais estados concentram os maiores gastos médios.\n",
    "\n",
    "- **Insight:** Estados com maior representatividade política ou maior número de parlamentares podem influenciar esses valores.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Partidos com Maior Média de Gastos\n",
    "\n",
    "Neste gráfico, analisamos os partidos políticos com maiores médias de despesas líquidas entre seus representantes.\n",
    "\n",
    "- **Insight:** Partidos com mais cadeiras no Congresso tendem a apresentar maiores valores agregados. No entanto, o foco está na **média por parlamentar**, revelando padrões internos de gastos por legenda.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Tipos de Despesa com Maior Valor Médio por Transação\n",
    "\n",
    "Este gráfico horizontal apresenta os **tipos de despesas** com maior valor médio por transação realizada.\n",
    "\n",
    "- **Insight:** Gastos como **locação de veículos**, **divulgação da atividade parlamentar** e **manutenção de escritório** aparecem entre os maiores custos médios, indicando despesas pontuais de alto valor.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Essas visualizações são essenciais para gerar hipóteses que poderão ser testadas na modelagem preditiva e ajudar na construção de variáveis derivadas com potencial explicativo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código para visualizações agregadas com Plotly\n",
    "\n",
    "# Define um template padrão para o Plotly\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "# Converte apresentação do valor para brasileiro (R$)\n",
    "def formatar_valor(valor):\n",
    "    return f\"R$ {valor:,.2f}\".replace(\",\", \"X\").replace(\".\", \",\").replace(\"X\", \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 UFs por Gasto Total\n",
    "top_ufs = (\n",
    "    df_modelo.groupby('sgUF')['vlrLiquidoTotal']\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .reset_index()\n",
    ")\n",
    "top_ufs['texto'] = top_ufs['vlrLiquidoTotal'].apply(formatar_valor)\n",
    "\n",
    "fig1 = px.bar(\n",
    "    top_ufs,\n",
    "    x='sgUF',\n",
    "    y='vlrLiquidoTotal',\n",
    "    orientation='v',\n",
    "    title='<b>UFs por Gastos Totais</b>',\n",
    "    labels={'vlrLiquidoTotal': 'Gasto Total (R$)', 'sgUF': 'UF'},\n",
    "    text='texto'\n",
    ")\n",
    "fig1.update_layout(showlegend=False, yaxis={'categoryorder':'total ascending'})\n",
    "fig1.update_traces(textposition='outside', marker_color='#EF553B')\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Partidos por Gasto Total\n",
    "top_partidos = (\n",
    "    df_modelo.groupby('sgPartido')['vlrLiquidoTotal']\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .reset_index()\n",
    ")\n",
    "top_partidos['texto'] = top_partidos['vlrLiquidoTotal'].apply(formatar_valor)\n",
    "\n",
    "fig2 = px.bar(\n",
    "    top_partidos,\n",
    "    x='sgPartido',\n",
    "    y='vlrLiquidoTotal',\n",
    "    orientation='v',\n",
    "    title='<b>Partidos por Gastos Totais</b>',\n",
    "    labels={'vlrLiquidoTotal': 'Gasto Total (R$)', 'sgPartido': 'Partido'},\n",
    "    text='texto'\n",
    ")\n",
    "fig2.update_layout(showlegend=False, yaxis={'categoryorder':'total ascending'})\n",
    "fig2.update_traces(textposition='outside', marker_color='#00CC96')\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Tipos de Despesa com Maior Valor Médio \n",
    "\n",
    "top_tipos = (\n",
    "    df_modelo.groupby('txtDescricao')['vlrLiquidoTotal']\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Formatando valores como texto no padrão brasileiro\n",
    "top_tipos['texto'] = top_tipos['vlrLiquidoTotal'].apply(formatar_valor)\n",
    "\n",
    "# Gráfico com tipos de despesa no eixo Y (barra horizontal)\n",
    "fig3 = px.bar(\n",
    "    top_tipos,\n",
    "    x='vlrLiquidoTotal',\n",
    "    y='txtDescricao',\n",
    "    orientation='h',\n",
    "    title='<b>Tipos de Despesa com Maior Valor Médio por Transação</b>',\n",
    "    labels={'vlrLiquidoTotal': 'Valor Médio (R$)', 'txtDescricao': 'Tipo de Despesa'},\n",
    "    text='texto'\n",
    ")\n",
    "\n",
    "fig3.update_layout(\n",
    "    showlegend=False,\n",
    "    xaxis_tickformat=',.2f',\n",
    "    yaxis=dict(categoryorder='total ascending'),\n",
    "    height=800  # aumenta a altura do gráfico para caber melhor os rótulos\n",
    ")\n",
    "\n",
    "fig3.update_traces(\n",
    "    textposition='outside',\n",
    "    marker_color='#AB63FA'\n",
    ")\n",
    "\n",
    "fig3.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvEceHzUQq2j"
   },
   "source": [
    "# 4. Modelagem <a class=\"anchor\" id=\"modelagem\"></a>\n",
    "Nesta etapa, construímos e testamos diferentes modelos de regressão para prever os valores líquidos (`vlrLiquidoTotal`) das despesas parlamentares, com foco na performance e interpretabilidade. Duas abordagens foram adotadas: Random Forest e CatBoost.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9H-GXDBNQq2j"
   },
   "source": [
    "## 4.1. Técnicas de Modelagem <a class=\"anchor\" id=\"tecnicas-modelagem\"></a>\n",
    "Foram selecionadas duas técnicas supervisionadas de regressão:\n",
    "\n",
    "- **Random Forest Regressor**: um modelo de ensemble baseado em árvores de decisão. Requer tratamento explícito das variáveis categóricas (via OneHotEncoder).\n",
    "- **CatBoost Regressor**: algoritmo especializado para lidar com variáveis categóricas de forma nativa, sem a necessidade de codificação manual.\n",
    "\n",
    "Essas abordagens foram encapsuladas em pipelines que garantem consistência no pré-processamento e na modelagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "nhhwoVkVQq2k"
   },
   "outputs": [],
   "source": [
    "# Separação da variável target\n",
    "X = df_modelo.drop('vlrLiquidoTotal', axis=1)\n",
    "y = df_modelo['vlrLiquidoTotal']\n",
    "\n",
    "categorical_cols = ['sgUF', 'sgPartido', 'txtDescricao', 'numAno']\n",
    "\n",
    "# Divisão dos dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline 1: Random Forest com OneHotEncoder\n",
    "preprocessor_rf = ColumnTransformer(\n",
    "    transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)]\n",
    ")\n",
    "\n",
    "pipeline_rf = Pipeline(steps=[\n",
    "    ('preprocessamento', preprocessor_rf),\n",
    "    ('modelo', RandomForestRegressor(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline 2: CatBoost (lida com categorias diretamente)\n",
    "pipeline_cb = Pipeline(steps=[\n",
    "    ('modelo', CatBoostRegressor(verbose=0, cat_features=categorical_cols))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8ClvOxXQq2k"
   },
   "source": [
    "## 4.2. Teste de Modelos <a class=\"anchor\" id=\"teste-modelos\"></a>\n",
    "Ambos os modelos foram treinados e avaliados com **Root Mean Squared Error (RMSE)** como métrica principal.\n",
    "\n",
    "**Resultados iniciais (sem otimização):**\n",
    "- Random Forest – RMSE: `14428982591.47198`\n",
    "- CatBoost – RMSE: `8239011221.177081`\n",
    "\n",
    "> A partir disso, foi possível observar que ambos os modelos conseguiram aprender padrões relevantes, mas havia espaço para otimização.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento e avaliação\n",
    "pipeline_rf.fit(X_train, y_train)\n",
    "y_pred_rf = pipeline_rf.predict(X_test)\n",
    "print(\"Random Forest - RMSE:\", mean_squared_error(y_test, y_pred_rf))\n",
    "\n",
    "pipeline_cb.fit(X_train, y_train)\n",
    "y_pred_cb = pipeline_cb.predict(X_test)\n",
    "print(\"CatBoost - RMSE:\", mean_squared_error(y_test, y_pred_cb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQFDFtQoQq2k"
   },
   "source": [
    "## 4.3. Construção do Modelo (Build) <a class=\"anchor\" id=\"construcao-modelo\"></a>\n",
    "\n",
    "Nesta etapa, realizamos o **ajuste fino (tuning)** dos modelos utilizando a técnica de validação cruzada com `GridSearchCV`. Esse processo é essencial para **maximizar a performance preditiva** e evitar o sobreajuste.\n",
    "\n",
    "---\n",
    "\n",
    "### Random Forest com GridSearchCV\n",
    "\n",
    "A busca por hiperparâmetros ótimos foi aplicada ao modelo de Random Forest, com os seguintes parâmetros testados:\n",
    "\n",
    "- `n_estimators`: número de árvores na floresta → [50, 100]\n",
    "- `max_depth`: profundidade máxima de cada árvore → [None, 5, 10]\n",
    "\n",
    "O ajuste foi feito com validação cruzada (`cv=3`) e a métrica de avaliação foi o **RMSE negativo** (porque o `GridSearchCV` busca maximizar scores).\n",
    "\n",
    "**Melhores parâmetros encontrados:**\n",
    "```python\n",
    "Melhores parâmetros: {'modelo__max_depth': 10, 'modelo__n_estimators': 100}\n",
    "Melhor RMSE: 191.567, aproximadamente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1. Random Forest: Ajustar os melhores hiperparâmetros de forma automática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'modelo__n_estimators': [50, 100],\n",
    "    'modelo__max_depth': [None, 5, 10]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(pipeline_rf, param_grid, cv=3, scoring='neg_root_mean_squared_error')\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "# 🔹 Resultados do GridSearchCV - Random Forest\n",
    "melhores_param_rf = grid_rf.best_params_\n",
    "melhor_rmse_rf = -grid_rf.best_score_\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "###  Resultados do Random Forest (GridSearchCV)\n",
    "- **Melhores Parâmetros:** `{melhores_param_rf}`\n",
    "- **Melhor RMSE (validação cruzada):** `{melhor_rmse_rf:,.2f}`\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2. Random Forest: Visualizar as categorias mais influentes na previsão do preço."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importância das features (após o one-hot encoding)\n",
    "modelo_treinado = grid_rf.best_estimator_.named_steps['modelo']\n",
    "nomes_features = grid_rf.best_estimator_.named_steps['preprocessamento'].transformers_[0][1].get_feature_names_out(categorical_cols)\n",
    "\n",
    "importancias = pd.Series(modelo_treinado.feature_importances_, index=nomes_features).sort_values(ascending=False)\n",
    "\n",
    "# Top 20 features mais importantes\n",
    "top_n = 20\n",
    "importancias_top = importancias.head(top_n)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=importancias_top.values, y=importancias_top.index, palette=\"crest\")\n",
    "plt.title(f\"Top {top_n} Variáveis Mais Importantes - Random Forest\", fontsize=14)\n",
    "plt.xlabel(\"Importância\", fontsize=12)\n",
    "plt.ylabel(\"Variáveis\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3. CatBoost: Ajustar os melhores hiperparâmetros de forma automática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustando pipeline para uso com GridSearchCV\n",
    "# Precisamos criar uma função para embutir o Pool do CatBoost, já que ele lida com categorias internamente\n",
    "class CatBoostPipeline(Pipeline):\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        # Identifica colunas categóricas por índice\n",
    "        cat_features = [X.columns.get_loc(col) for col in X.select_dtypes(include='object').columns]\n",
    "        self.steps[-1][1].fit(X, y, cat_features=cat_features)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, **predict_params):\n",
    "        return self.steps[-1][1].predict(X)\n",
    "\n",
    "# Novo pipeline com CatBoost\n",
    "pipeline_cb = CatBoostPipeline(steps=[('modelo', CatBoostRegressor(verbose=0))])\n",
    "\n",
    "param_grid_cb = {\n",
    "    'modelo__depth': [4, 6, 8],\n",
    "    'modelo__learning_rate': [0.01, 0.1],\n",
    "    'modelo__iterations': [100, 200]\n",
    "}\n",
    "\n",
    "grid_cb = GridSearchCV(pipeline_cb, param_grid_cb, cv=3, scoring='neg_root_mean_squared_error')\n",
    "grid_cb.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "melhores_param_cb = grid_cb.best_params_\n",
    "melhor_rmse_cb = -grid_cb.best_score_\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "### Resultados do CatBoost (GridSearchCV)\n",
    "- **Melhores Parâmetros:** `{melhores_param_cb}`\n",
    "- **Melhor RMSE (validação cruzada):** `{melhor_rmse_cb:,.2f}`\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.4. CatBoost: Visualizar as categorias mais influentes na previsão do preço."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importância das variáveis\n",
    "modelo_cb = grid_cb.best_estimator_.named_steps['modelo']\n",
    "importancias_cb = modelo_cb.get_feature_importance()\n",
    "nomes_cb = X_train.columns\n",
    "\n",
    "df_importancias = pd.Series(importancias_cb, index=nomes_cb).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(x=df_importancias.values, y=df_importancias.index)\n",
    "plt.title(\"Importância das Variáveis - CatBoost\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZL6W-w7YQq2k"
   },
   "source": [
    "## 4.4. Avaliação de Performance <a class=\"anchor\" id=\"avaliacao-modelo\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1. Análise comparativa entre os modelos\n",
    "\n",
    "Antes de prosseguirmos com a avaliaão de performance dos modelos testados, seguem algumas métricas fundamentais úteis:\n",
    "\n",
    "- **RMSE (Root Mean Squared Error)** – Penaliza mais erros grandes.\n",
    "- **MAE (Mean Absolute Error)** – Mais robusta a outliers.\n",
    "- **R² (Coeficiente de Determinação)** – Mede o quão bem os dados se ajustam à regressão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U1YFLClIQq2k",
    "outputId": "bfdbddad-824f-4a40-96cb-6cec08c7cb7d"
   },
   "outputs": [],
   "source": [
    "# Previsões\n",
    "y_pred_rf = grid_rf.predict(X_test)\n",
    "y_pred_cb = grid_cb.predict(X_test)\n",
    "\n",
    "# Função para consolidar as métricas\n",
    "def avaliar_modelo(y_true, y_pred):\n",
    "    return {\n",
    "        'RMSE': mean_squared_error(y_true, y_pred),\n",
    "        'MAE': mean_absolute_error(y_true, y_pred),\n",
    "        'R²': r2_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "# Avaliação dos modelos\n",
    "avaliacao_rf = avaliar_modelo(y_test, y_pred_rf)\n",
    "avaliacao_cb = avaliar_modelo(y_test, y_pred_cb)\n",
    "\n",
    "# 🔹 Comparativo Final dos Modelos\n",
    "avaliacao_rf = avaliar_modelo(y_test, y_pred_rf)\n",
    "avaliacao_cb = avaliar_modelo(y_test, y_pred_cb)\n",
    "df_resultados = pd.DataFrame([avaliacao_rf, avaliacao_cb], index=['Random Forest', 'CatBoost'])\n",
    "\n",
    "display(Markdown(\"### Comparativo de Métricas dos Modelos (conjunto de teste):\"))\n",
    "display(df_resultados.style.format(\"{:,.2f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Primeiro, pegue o melhor pipeline encontrado pelo GridSearchCV\n",
    "melhor_pipeline = grid_cb.best_estimator_\n",
    "\n",
    "# Agora, extraia APENAS o passo do modelo treinado de dentro do pipeline\n",
    "modelo_final = melhor_pipeline.named_steps['modelo']\n",
    "\n",
    "# Salve APENAS o modelo final. Este será um objeto CatBoostRegressor padrão.\n",
    "joblib.dump(modelo_final, 'Modelo/Artefatos/modelo.bin')\n",
    "\n",
    "print(\"Modelo CatBoost final salvo com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados.plot(kind='bar', figsize=(8, 5))\n",
    "plt.title('Comparação de Desempenho dos Modelos')\n",
    "plt.ylabel('Valor')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filtro apenas da métrica R²\n",
    "r2_resultados = df_resultados[['R²']].copy().reset_index()\n",
    "r2_resultados.columns = ['Modelo', 'R²']\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(7, 4))\n",
    "sns.barplot(data=r2_resultados, x='Modelo', y='R²', palette='coolwarm')\n",
    "\n",
    "plt.title(\"Comparativo do R² entre os Modelos\")\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel(\"Coeficiente de Determinação (R²)\")\n",
    "plt.xlabel(\"Modelo\")\n",
    "\n",
    "# Adiciona os valores nas barras\n",
    "for index, row in r2_resultados.iterrows():\n",
    "    plt.text(x=index, y=row['R²'] + 0.02, s=f\"{row['R²']:.2f}\", ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Avaliação do Modelo <a class=\"anchor\" id=\"avaliacao-modelo\"></a>\n",
    "\n",
    "\n",
    "Nesta etapa, avaliamos se os modelos treinados atendem aos objetivos do projeto, especialmente no que diz respeito à **precisão na estimativa dos gastos parlamentares**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Avaliação da Performance dos Modelos <a class=\"anchor\" id=\"avaliacao-da-performance-dos-modelos\"></a>\n",
    "\n",
    "Nesta etapa, avaliamos a performance dos modelos de regressão treinados para prever o valor líquido das despesas parlamentares (`vlrLiquidoTotal`). Foram aplicados dois algoritmos:\n",
    "\n",
    "- **Random Forest Regressor**, com pré-processamento via OneHotEncoder.\n",
    "- **CatBoost Regressor**, que lida nativamente com variáveis categóricas.\n",
    "\n",
    "#### Métricas Utilizadas:\n",
    "\n",
    "- **RMSE (Root Mean Squared Error)**: mede o erro quadrático médio. Quanto menor, melhor.\n",
    "- **MAE (Mean Absolute Error)**: erro absoluto médio entre valores reais e previstos.\n",
    "- **R² (Coeficiente de Determinação)**: mede o quanto o modelo explica da variabilidade dos dados.\n",
    "\n",
    "#### Resultados Obtidos:\n",
    "\n",
    "| Modelo         | RMSE                  | MAE           | R²    |\n",
    "|----------------|------------------------|----------------|-------|\n",
    "| Random Forest  | R$ 14.428.982.591,47   | R$ 55.159,50   | 0.56  |\n",
    "| CatBoost       | R$ 8.963.990.729,78    | R$ 42.582,03   | 0.73  |\n",
    "\n",
    "*Conclusão:* O **CatBoost superou o Random Forest** em todas as métricas avaliadas, especialmente no RMSE e no R², mostrando-se mais eficiente em prever o valor final das despesas com menor erro e maior capacidade explicativa.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Interpretação dos Resultados <a class=\"anchor\" id=\"interpretacao-dos-resultados\"></a>\n",
    "\n",
    "A análise da importância das variáveis indicou que os fatores que mais influenciam o valor líquido das despesas são:\n",
    "\n",
    "- **Tipo de Despesa (`txtDescricao`)**: foi a variável mais relevante em ambos os modelos.\n",
    "- **UF e Partido**: também aparecem com forte impacto, indicando possíveis variações regionais e partidárias.\n",
    "- **Ano (`numAno`)**: pode refletir padrões anuais de gastos ou ciclos eleitorais.\n",
    "\n",
    "A partir dos gráficos gerados, foi possível visualizar:\n",
    "\n",
    "- Os partidos e estados com maiores valores médios de despesas.\n",
    "- O impacto médio por tipo de despesa.\n",
    "- A comparação direta entre os modelos com gráficos de barras e o R² individual.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Revisão do Processo e Próximos Passos <a class=\"anchor\" id=\"revisao-do-processo-e-proximos-passos\"></a>\n",
    "\n",
    "#### Revisão do Processo\n",
    "O projeto seguiu todas as etapas da metodologia **CRISP-DM**, desde o entendimento do problema de negócio até a modelagem e avaliação:\n",
    "\n",
    "1. Coleta de dados de diferentes anos do portal da Câmara.\n",
    "2. Limpeza, integração e criação de variáveis derivadas.\n",
    "3. Análise exploratória e visualizações interativas.\n",
    "4. Modelagem preditiva com dois algoritmos robustos.\n",
    "5. Avaliação com métricas de regressão e interpretação dos resultados.\n",
    "\n",
    "#### Próximos Passos\n",
    "\n",
    "- **Implantar uma API com FastAPI** que disponibilize o modelo CatBoost para uso em produção (endpoint `/predict`).\n",
    "- **Salvar artefatos do modelo** (`.pkl` ou `.cbm`) e aplicá-los no backend.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Aplicação prática (Deployment)\n",
    "\n",
    "## Descrever como foi implementada a API."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
