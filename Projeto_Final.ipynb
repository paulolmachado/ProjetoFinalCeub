{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTNXidF3Qq2K"
   },
   "source": [
    "# **Ciência de Dados e Machine Learning**\n",
    "\n",
    "## **Projeto Final do Curso**\n",
    "\n",
    "---\n",
    "\n",
    "### **Alunos:**\n",
    "\n",
    "> Charles Bezerra - 52400351\n",
    "\n",
    "> Jheferson Warley - 52400071\n",
    "\n",
    "> Paulo Machado - 52400245\n",
    "\n",
    "---\n",
    "\n",
    "### Tema: **Despesas pela Cota para Exercício da Atividade Parlamentar**\n",
    "\n",
    "### Base de Dados: https://dadosabertos.camara.leg.br/swagger/api.html?tab=staticfile\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RfgYroaQq2N"
   },
   "source": [
    "Este projeto final do curso de **Ciência de Dados e Machine** Learning do UniCEUB se baseia na metodologia *Cross-Industry Standard Process for Data Mining - CRISP-DM* (https://www.sv-europe.com/crisp-dm-methodology/), oferecendo uma abordagem estruturada para planejar um projeto de mineração de dados de uma forma robusta.\n",
    "\n",
    "Este modelo representa uma sequência idealizada de eventos. Na prática, muitas das tarefas podem ser realizadas em uma ordem diferente, e frequentemente será necessário voltar a tarefas anteriores e repetir certas ações.\n",
    "\n",
    "<div>\n",
    "<img src=\"FasesCRISP-DM.png\" width=\"50%\">\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjrc0DUFQq2O"
   },
   "source": [
    "## **Etapas do Processo CRISP-DM**\n",
    "\n",
    "### 1. [Entendimento do Negócio](#business-understanding)\n",
    "Compreensão dos objetivos de negócio, contexto organizacional e definição das metas analíticas.\n",
    "\n",
    "- [1.1 Avaliação da Situação Atual](#avaliacao-da-situacao)\n",
    "- [1.2 Resultados Esperados](#resultados-esperados)\n",
    "- [1.3 Questões de Pesquisa](#questoes-de-pesquisa)\n",
    "<!-- - [1.4 Plano de Projeto](#plano-do-projeto) -->\n",
    "\n",
    "---\n",
    "\n",
    "### 2. [Entendimento dos Dados](#entendimento-dados)\n",
    "Exploração inicial dos dados, coleta e verificação da qualidade.\n",
    "\n",
    "- [2.1 Relatorio Inicial](#relatorio-inicial)\n",
    "- [2.2 Descrição dos Dados](#descricao-dados)\n",
    "- [2.3 Exploração dos Dados](#exploracao-dados)\n",
    "- [2.4 Verificação da Qualidade dos Dados](#qualidade-dos-dados)\n",
    "\n",
    "---\n",
    "\n",
    "### 3. [Preparação dos Dados](#preparacao-dados)\n",
    "Construção do dataset final que será utilizado para modelagem.\n",
    "\n",
    "- [3.1 Seleção dos Dados](#selecao-dados)\n",
    "- [3.2 Limpeza dos Dados](#limpeza-dados)\n",
    "- [3.3 Construção de Dados Derivados](#dados-derivados)\n",
    "- [3.4 Integração de Dados](#integracao-dados)\n",
    "- [3.5 Análise Exploratória de Dados](#analise-dados)\n",
    "\n",
    "---\n",
    "\n",
    "### 4. [Modelagem](#modelagem)\n",
    "Aplicação de técnicas de modelagem estatística ou de machine learning.\n",
    "\n",
    "- [5.1 Técnicas de Modelagem](#tecnicas-modelagem)\n",
    "- [5.2 Teste de Modelos](#teste-modelos)\n",
    "- [5.3 Construção dos Modelos](#construcao-modelo)\n",
    "- [5.4 Avaliação de Performance](#avaliacao-modelo)\n",
    "\n",
    "---\n",
    "\n",
    "### 5. [Avaliação](#avaliacao-modelo)\n",
    "Verificação se o modelo atende os objetivos de negócio definidos.\n",
    "\n",
    "- [6.1 Regressão Logística](#regressao-logistica)\n",
    "- [6.2 Revisão do Processo](#revisao-processo)\n",
    "- [6.3 Determinação dos Próximos Passos](#proximos-passos)\n",
    "\n",
    "---\n",
    "\n",
    "### 6. [Implementação (Deployment)](#implementacao)\n",
    "Entrega prática do modelo, seja em relatório, dashboard, sistema ou API.\n",
    "\n",
    "- [6.1 Planejamento da Implementação](#planejamento-implementacao)\n",
    "- [6.2 Monitoramento e Manutenção](#monitoramento)\n",
    "- [6.3 Documentação Final](#documentacao-final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pdYJHP76Qq2O"
   },
   "source": [
    "## 1. Entendimento do Negócio  <a class=\"anchor\" id=\"business-understanding\"></a>\n",
    "\n",
    "Atualmente, o cenário político brasileiro se mostra em foco, principalmente quando se trata de despesas relacionadas à sustentação do governo como todo. Neste contexto, as despesas parlamentares, limitadas por uma cota, são frequentemente noticiadas devido a seu alto custo. As cotas parlamentares variam conforme o estado do deputado e é destinado ao custeio de despesas relacionadas ao exercício do mandato. As despesas incluem passagens aéreas, locomoção, hospedagens, serviços de segurança, divulgação de atividades parlamentares e contratação de pessoal.\n",
    "\n",
    "\n",
    "A Câmara dos Deputados divulga através da plataforma de dados abertos do governo (https://dadosabertos.camara.leg.br/swagger/api.html?tab=staticfile) as despesas refentes ao consumo de cotas separadas por ano, Deputado, UF, tipo de despesas, entre outras classificações. Os arquivos podem ser baixador por ano, disponíveis desde o ano 2018, nos formatos XML, JSON, CSV, XLSX e ODS.\n",
    "\n",
    "\n",
    "Para este projeto, selecionamos os dados relativos ao ano de 2024 (ano completo mais recente) com arquivos no formato CSV para melhor tratamento dos dados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2SqAlWIyQq2P"
   },
   "source": [
    "## 1.1 Avaliação da Situação Atual<a class=\"anchor\" id=\"avaliacao-da-situacao\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFsmtXzxQq2P"
   },
   "source": [
    "A transparência nos gastos públicos tem ganhado relevância nos debates sociais e institucionais, principalmente no contexto político brasileiro. A Câmara dos Deputados disponibiliza, por meio do portal de Dados Abertos, informações detalhadas sobre a utilização da Cota para o Exercício da Atividade Parlamentar (CEAP), que contempla diversos tipos de despesas efetuadas pelos parlamentares no desempenho de suas funções.\n",
    "\n",
    "Apesar da disponibilidade dos dados, observa-se uma subutilização dessas informações por parte da sociedade civil e dos órgãos fiscalizadores. O volume e a complexidade dos dados dificultam análises diretas e conclusivas, exigindo ferramentas adequadas de tratamento, análise e visualização. Diante disso, este projeto visa utilizar técnicas de análise de dados e aprendizado de máquina para transformar os dados brutos em insights relevantes e acessíveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWxWA-87Qq2P"
   },
   "source": [
    "## 1.2 Resultados Esperados<a class=\"anchor\" id=\"resultaods-esperados\"></a>\n",
    "\n",
    "Este projeto tem como objetivo geral analisar os gastos parlamentares por meio da base de dados da CEAP, abrangendo os anos de 2023, 2024 e 2025. Os resultados esperados incluem:\n",
    "\n",
    "- Desenvolvimento de relatórios e dashboards analíticos para visualização dos dados por deputado, partido político, unidade federativa (UF), tipo de despesa, fornecedor e período (mês e ano).\n",
    "- Análises estatísticas descritivas e comparativas, a fim de identificar padrões de gastos e variações relevantes entre diferentes grupos.\n",
    "- Detecção de anomalias e possíveis irregularidades nos registros de despesas.\n",
    "- Aplicação de técnicas de aprendizado de máquina (Machine Learning) com o objetivo de construir modelos preditivos capazes de estimar os gastos parlamentares futuros por partido ou UF, com base nos dados históricos.\n",
    "\n",
    "O projeto segue a metodologia CRISP-DM, com foco na reprodutibilidade dos resultados e na criação de documentação clara e acessível."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Questões de Pesquisa<a class=\"anchor\" id=\"questoes-de-pesquisa\"></a>\n",
    "\n",
    "O projeto é orientado por um conjunto de questões exploratórias e preditivas, que servirão como guia para as etapas analíticas e de modelagem.\n",
    "\n",
    "### Questões Exploratórias\n",
    "\n",
    "- Quais partidos políticos apresentaram os maiores volumes de gasto no período analisado?\n",
    "- Quais unidades federativas concentram os maiores gastos?\n",
    "- Quais são os tipos de despesa mais recorrentes e qual seu impacto nos valores totais?\n",
    "- Como os gastos variam ao longo do tempo? Existe sazonalidade ou tendência?\n",
    "- Há fornecedores recorrentes nos maiores gastos? Qual seu perfil?\n",
    "\n",
    "### Questões Preditivas\n",
    "\n",
    "- É possível prever os gastos parlamentares futuros com base no histórico de dados?\n",
    "- Quais variáveis mais influenciam no volume de gastos (ex.: partido, UF, tipo de despesa, mês)?\n",
    "- Quais partidos ou unidades federativas têm maior propensão a apresentar aumentos nos gastos em futuros mandatos?\n",
    "\n",
    "Estas perguntas direcionam a construção dos indicadores, visualizações e modelos preditivos ao longo do projeto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4S-Y6p8VQq2R"
   },
   "source": [
    "# 2. Entendimento dos Dados <a class=\"anchor\" id=\"entendimento-dados\"></a>\n",
    "A etapa de entendimento dos dados tem como objetivo fornecer uma visão inicial e aprofundada da estrutura, conteúdo e qualidade do conjunto de dados disponível para análise. Trata-se de uma fase fundamental no processo analítico, pois permite identificar características importantes dos dados, potenciais inconsistências, ausência de valores e padrões que podem influenciar diretamente na preparação, modelagem e interpretação dos resultados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-6TQJ_4Qq2R"
   },
   "source": [
    "## 2.1 Relatório Inicial <a class=\"anchor\" id=\"relatorio-inicial\"></a>\n",
    "O conjunto de dados utilizado neste projeto refere-se às despesas parlamentares registradas na Cota para o Exercício da Atividade Parlamentar (CEAP), compreendendo os anos de 2023, 2024 e 2025. Os dados foram extraídos da API pública da Câmara dos Deputados, que disponibiliza os registros em diversos formatos. Para este trabalho, optou-se pelo formato `.csv`, considerando a facilidade de leitura e manipulação em ambientes Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "X9OlrvX3Qq2R"
   },
   "outputs": [],
   "source": [
    "# Importação das Bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "D85E5K77Qq2S"
   },
   "outputs": [],
   "source": [
    "# Leitura dos dados\n",
    "df_2023 = pd.read_csv(\"DataBase/Ano-2023.csv\", sep=\";\", encoding=\"utf-8\", low_memory=False)\n",
    "df_2024 = pd.read_csv(\"DataBase/Ano-2024.csv\", sep=\";\", encoding=\"utf-8\", low_memory=False)\n",
    "df_2025 = pd.read_csv(\"DataBase/Ano-2025.csv\", sep=\";\", encoding=\"utf-8\", low_memory=False)\n",
    "\n",
    "# Combinação dos três dataframes\n",
    "df_completo = pd.concat([df_2023, df_2024, df_2025], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibição das 5 primeiras linhas\n",
    "display(df_completo.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZ8n1_pnQq2T"
   },
   "source": [
    "## 2.2 Descrição dos Dados <a class=\"anchor\" id=\"descricao-dados\"></a>\n",
    "A seguir, são apresentados o nome das colunas disponíveis no dataset e o seu formato dimensional (linhas x colunas).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A tabela abaixo apresenta a descrição de cada uma das variáveis disponíveis no conjunto de dados utilizado.\n",
    "\n",
    "| Nome da Coluna                 | Descrição                                                        |\n",
    "|-------------------------------|------------------------------------------------------------------|\n",
    "| `txNomeParlamentar`           | Nome do parlamentar                                              |\n",
    "| `cpf`                         | CPF do parlamentar (quando disponível)                          |\n",
    "| `ideCadastro`                 | ID único do parlamentar                                          |\n",
    "| `nuCarteiraParlamentar`       | Número da carteira parlamentar                                   |\n",
    "| `nuLegislatura`               | Número da legislatura em exercício                               |\n",
    "| `sgUF`                        | Unidade Federativa (estado)                                      |\n",
    "| `sgPartido`                   | Sigla do partido político                                        |\n",
    "| `codLegislatura`              | Código da legislatura                                            |\n",
    "| `numSubCota`                  | Código da subcota utilizada                                      |\n",
    "| `txtDescricao`                | Descrição da subcota                                             |\n",
    "| `numEspecificacaoSubCota`     | Código da especificação da subcota                               |\n",
    "| `txtDescricaoEspecificacao`   | Descrição detalhada da subcota                                   |\n",
    "| `txtFornecedor`               | Nome do fornecedor                                               |\n",
    "| `txtCNPJCPF`                  | CNPJ ou CPF do fornecedor                                        |\n",
    "| `txtNumero`                   | Número do documento fiscal                                       |\n",
    "| `indTipoDocumento`            | Tipo do documento (nota fiscal, recibo, etc.)                   |\n",
    "| `datEmissao`                  | Data de emissão do documento                                     |\n",
    "| `vlrDocumento`                | Valor bruto do documento                                         |\n",
    "| `vlrGlosa`                    | Valor glosado/desconsiderado                                     |\n",
    "| `vlrLiquido`                  | Valor líquido aceito                                             |\n",
    "| `numMes`                      | Mês de referência da despesa                                     |\n",
    "| `numAno`                      | Ano de referência da despesa                                     |\n",
    "| `numParcela`                  | Número da parcela, quando aplicável                              |\n",
    "| `txtPassageiro`               | Nome do passageiro (se transporte aéreo)                         |\n",
    "| `txtTrecho`                   | Trecho da viagem (ida/volta)                                     |\n",
    "| `numLote`                     | Número do lote do documento                                      |\n",
    "| `numRessarcimento`            | Número de protocolo de ressarcimento                             |\n",
    "| `datPagamentoRestituicao`     | Data do pagamento de restituição                                 |\n",
    "| `vlrRestituicao`              | Valor restituído                                                 |\n",
    "| `nuDeputadoId`                | ID único do deputado                                             |\n",
    "| `ideDocumento`                | ID do documento                                                  |\n",
    "| `urlDocumento`                | Link para o documento oficial                                    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EemJ6DTeQq2U",
    "outputId": "7aa11b1f-b976-4a2a-f622-bab9cffdd1a7"
   },
   "outputs": [],
   "source": [
    "# Nomes das colunas\n",
    "df_completo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gnj33OcMQq2U",
    "outputId": "02529b54-4038-461c-f231-2ba7e0018cc2"
   },
   "outputs": [],
   "source": [
    "# Dimensão do dataframe\n",
    "df_completo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNxTQwN_Qq2V"
   },
   "source": [
    "## 2.3 Exploração dos Dados <a class=\"anchor\" id=\"exploracao-dados\"></a>\n",
    "\n",
    "Essa etapa visa obter uma visão geral das características dos dados, incluindo tipos de variáveis, estatísticas descritivas e primeiros insights de distribuição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TwiVpT8FQq2W",
    "outputId": "ac44ac23-9621-40c0-a32a-61b7199f4960"
   },
   "outputs": [],
   "source": [
    "# Verificação de duplicatas\n",
    "df_completo.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatísticas descritivas\n",
    "df_completo.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatísticas descritivas\n",
    "df_completo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando valores nulos por coluna\n",
    "df_completo.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a quantidade de valores únicos em algumas colunas-chave\n",
    "print(\"UFs:\", df_completo['sgUF'].nunique())\n",
    "print(\"Partidos:\", df_completo['sgPartido'].nunique())\n",
    "print(\"Tipos de despesa:\", df_completo['txtDescricao'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição dos principais campos categóricos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# UF\n",
    "uf_counts = df_completo['sgUF'].value_counts().reset_index()\n",
    "uf_counts.columns = ['UF', 'Total de Registros']\n",
    "display(Markdown(\"### Distribuição por Unidade Federativa\"))\n",
    "plt.figure(figsize=(10,5))\n",
    "ax1 = sns.barplot(data=uf_counts, x='UF', y='Total de Registros', palette='Blues_d')\n",
    "plt.title('Distribuição por Unidade Federativa')\n",
    "plt.xlabel('UF')\n",
    "plt.ylabel('Total de Registros')\n",
    "plt.xticks(rotation=45)\n",
    "for p in ax1.patches:\n",
    "    ax1.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                 ha='center', va='bottom', fontsize=9, color='black', xytext=(0, 3), textcoords='offset points')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Partido\n",
    "partido_counts = df_completo['sgPartido'].value_counts().reset_index()\n",
    "partido_counts.columns = ['Partido', 'Total de Registros']\n",
    "display(Markdown(\"### Distribuição por Partido\"))\n",
    "plt.figure(figsize=(12,5))\n",
    "ax2 = sns.barplot(data=partido_counts, x='Partido', y='Total de Registros', palette='Greens_d')\n",
    "plt.title('Distribuição por Partido')\n",
    "plt.xlabel('Partido')\n",
    "plt.ylabel('Total de Registros')\n",
    "plt.xticks(rotation=45)\n",
    "for p in ax2.patches:\n",
    "    ax2.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                 ha='center', va='bottom', fontsize=9, color='black', xytext=(0, 3), textcoords='offset points')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tipo de Despesa\n",
    "# Exibir apenas os 15 principais tipos para melhor visualização\n",
    "despesa_counts = df_completo['txtDescricao'].value_counts().reset_index()\n",
    "despesa_counts.columns = ['Tipo de Despesa', 'Total de Registros']\n",
    "display(Markdown(\"### Distribuição por Tipo de Despesa (Top 15)\"))\n",
    "plt.figure(figsize=(12,6))\n",
    "ax3 = sns.barplot(data=despesa_counts.head(15), x='Tipo de Despesa', y='Total de Registros', palette='Oranges_d')\n",
    "plt.title('Distribuição por Tipo de Despesa (Top 15)')\n",
    "plt.xlabel('Tipo de Despesa')\n",
    "plt.ylabel('Total de Registros')\n",
    "plt.xticks(rotation=75)\n",
    "for p in ax3.patches:\n",
    "    ax3.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                 ha='center', va='bottom', fontsize=9, color='black', xytext=(0, 3), textcoords='offset points')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzPUggSjQq2c"
   },
   "source": [
    "## 2.4 Verificação da Qualidade dos Dados<a class=\"anchor\" id=\"qualidade-dos-dados\"></a>\n",
    "Abaixo está um resumo quantitativo da qualidade dos dados após a análise exploratória inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo geral do dataset\n",
    "resumo_geral = pd.DataFrame({\n",
    "    \"Indicador\": [\n",
    "        \"Total de registros\",\n",
    "        \"Total de variáveis (colunas)\",\n",
    "        \"Registros duplicados\",\n",
    "        \"Valores inconsistentes (vlrDocumento < vlrLiquido)\",\n",
    "        \"Total valor liquido negativo\",\n",
    "        \"Total UF NULOS\"\n",
    "    ],\n",
    "    \"Valor\": [\n",
    "        df_completo.shape[0],\n",
    "        df_completo.shape[1],\n",
    "        df_completo.duplicated().sum(),\n",
    "        (df_completo['vlrDocumento'] < df_completo['vlrLiquido']).sum(),\n",
    "        (df_completo['vlrLiquido'] < 0 ).sum(),\n",
    "    ]\n",
    "})\n",
    "\n",
    "display(Markdown(\"### Resumo Geral da Base de Dados\"))\n",
    "display(resumo_geral)\n",
    "\n",
    "# Colunas com valores nulos\n",
    "nulls = df_completo.isnull().sum()\n",
    "nulls = nulls[nulls > 0].sort_values(ascending=False).reset_index()\n",
    "nulls.columns = ['Coluna', 'Valores Nulos']\n",
    "\n",
    "display(Markdown(\"### Colunas com Valores Ausentes\"))\n",
    "display(nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcL0DjOzQq2c"
   },
   "source": [
    "# 3. Preparação dos Dados <a class=\"anchor\" id=\"preparacao-dados\"></a>\n",
    "\n",
    "\n",
    "Nesta etapa, realizamos o tratamento necessário para transformar os dados brutos em uma base estruturada e adequada para aplicação de modelos de aprendizado supervisionado. As ações incluem: seleção e limpeza de dados, geração de atributos derivados e integração das bases históricas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQjMmUM5Qq2c"
   },
   "source": [
    "## 3.1 Seleção dos Dados <a class=\"anchor\" id=\"selecao-dados\"></a>\n",
    "\n",
    "Nesta etapa inicial da **Preparação dos Dados**, realizamos a seleção criteriosa das variáveis mais relevantes para o problema de predição do **valor líquido da despesa parlamentar (`vlrLiquido`)**.\n",
    "\n",
    "O objetivo é filtrar os dados brutos e manter somente as informações que possuem **relação direta com o comportamento dos gastos parlamentares**, otimizando o desempenho dos algoritmos de machine learning.\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔸 Critérios de Seleção\n",
    "\n",
    "Selecionamos as colunas que possuem potencial explicativo e que apresentam valor informacional para o modelo supervisionado. As variáveis escolhidas foram:\n",
    "\n",
    "- **`txNomeParlamentar`**: nome do deputado. Utilizada para gerar uma feature derivada de custo total por parlamentar.\n",
    "- **`sgUF`**: unidade federativa, que pode refletir realidades regionais de gastos.\n",
    "- **`sgPartido`**: partido político, possível fator explicativo para padrões de despesa.\n",
    "- **`txtDescricao`**: tipo de despesa (ex: alimentação, aluguel, combustível).\n",
    "- **`vlrDocumento`**: valor bruto do documento fiscal apresentado.\n",
    "- **`numMes` e `numAno`**: período da despesa, para análise sazonal ou temporal.\n",
    "- **`vlrLiquido`**: variável-alvo que será predita pelo modelo.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "g4kDHLdXquwb",
    "outputId": "2e1a32f8-35c5-4e93-8d7d-9b05451514c3"
   },
   "outputs": [],
   "source": [
    "# # Seleção de colunas relevantes\n",
    "# colunas_selecionadas = [\n",
    "#     'sgUF', 'sgPartido','numMes', 'numAno', 'vlrLiquido']\n",
    "\n",
    "# df_modelo = df_completo[colunas_selecionadas].copy()\n",
    "\n",
    "# # Custo total por ano (valor agregado no projeto)\n",
    "# custo_anual = df_modelo.groupby('sgUF', 'sgPartido','numMes', 'numAno', 'vlrLiquido')['vlrLiquido'].transform('sum')\n",
    "# df_modelo['custo_total_anual'] = custo_anual\n",
    "\n",
    "# from IPython.display import display, Markdown\n",
    "# display(Markdown(\"**Amostra da base com colunas selecionadas e nova feature de custo por parlamentar:**\"))\n",
    "# display(df_modelo.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDRfR6L8Qq2d"
   },
   "source": [
    "## 3.2 Limpeza dos Dados <a class=\"anchor\" id=\"limpeza-dados\"></a>\n",
    "\n",
    "\n",
    "Nesta etapa, realizamos uma série de ações de limpeza para garantir que os dados utilizados nos modelos estejam consistentes, sem ruídos e com alta qualidade informacional. A preparação adequada dos dados é essencial para que qualquer modelo de aprendizado de máquina produza resultados confiáveis.\n",
    "\n",
    "As ações tomadas nesta fase incluem:\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔸 Remoção de Registros Inconsistentes\n",
    "\n",
    "Eliminamos os registros em que o valor líquido (`vlrLiquido`) era superior ao valor bruto do documento (`vlrDocumento`). Essa inconsistência viola a lógica financeira da base de dados e poderia comprometer análises futuras. Esses registros foram identificados, quantificados e removidos de forma criteriosa.\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔸 Tratamento de Valores Negativos\n",
    "\n",
    "Foram identificados valores negativos na coluna `vlrLiquido` — o que não representa um cenário válido para gastos parlamentares. Esses valores estavam presentes em todas as bases de 2023, 2024 e 2025:\n",
    "\n",
    "- **2023:** 9.383 registros\n",
    "- **2024:** 10.327 registros\n",
    "- **2025:** 2.626 registros\n",
    "\n",
    "Todos foram removidos após verificação e exibição de amostras por ano. A limpeza foi validada com uma checagem final, confirmando que **nenhum valor negativo permaneceu**.\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔸 Eliminação de Registros com Valores Ausentes (NaN)\n",
    "\n",
    "Após a seleção e transformação das colunas relevantes, identificamos **2.135 registros com valores ausentes**, totalizando **4.270 células com `NaN`**. Esses dados foram descartados para evitar viés no processo de modelagem, uma vez que a imputação poderia comprometer a acurácia dos modelos.\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔸 Remoção de Registros Duplicados\n",
    "\n",
    "Realizamos a verificação de duplicatas no conjunto de dados e removemos entradas repetidas para garantir que cada linha representasse uma observação única. Essa prática evita sobrepeso em certas categorias e garante imparcialidade nas análises estatísticas.\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔸 Remoção de Colunas Desnecessárias\n",
    "\n",
    "Foram excluídas colunas que não contribuíam para os objetivos do projeto, como identificadores únicos (`CPF`, `CNPJ`, códigos legislativos), atributos com alta cardinalidade ou informações redundantes. Essa etapa reduziu a complexidade do modelo e aumentou a interpretabilidade.\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔸 Criação de Feature Agregada: `custo_total_parlamentar`\n",
    "\n",
    "Para enriquecer a base de dados, criamos a variável `custo_total_parlamentar`, que representa o total de gastos acumulados por parlamentar ao longo dos anos. Essa feature é útil tanto para análises descritivas quanto para futuras previsões.\n",
    "\n",
    "---\n",
    "\n",
    "###  Resultado Final\n",
    "\n",
    "Após todas as etapas de limpeza, o novo DataFrame final (`df_modelo`) apresenta:\n",
    "\n",
    "- **518.989 registros**\n",
    "- **9 colunas relevantes**\n",
    "- Nenhum valor `NaN` ou negativo\n",
    "- Dados prontos para modelagem supervisionada\n",
    "\n",
    "---\n",
    "\n",
    "####  Amostra dos dados tratados:\n",
    "\n",
    "| txNomeParlamentar | sgUF | sgPartido | txtDescricao | vlrDocumento | numMes | numAno | vlrLiquido | custo_total_parlamentar |\n",
    "|-------------------|------|-----------|-----------------------------|----------------|---------|--------|-------------|--------------------------|\n",
    "| Danilo Forte      | CE   | UNIÃO     | MANUTENÇÃO DE ESCRITÓRIO... | 400.00         | 1       | 2023   | 400.00      | 1.389.529,54             |\n",
    "| Danilo Forte      | CE   | UNIÃO     | MANUTENÇÃO DE ESCRITÓRIO... | 2.215.00       | 1       | 2023   | 2.215.00    | 1.389.529,54             |\n",
    "| ...               | ...  | ...       | ...                         | ...            | ...     | ...    | ...         | ...                      |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminhos corrigidos com separador \";\"\n",
    "arquivos = {\n",
    "    '2023': 'DataBase/Ano-2023.csv',\n",
    "    '2024': 'DataBase/Ano-2024.csv',\n",
    "    '2025': 'DataBase/Ano-2025.csv'\n",
    "}\n",
    "\n",
    "# Lista para armazenar os DataFrames limpos\n",
    "dfs_limpos = []\n",
    "\n",
    "display(Markdown(\"## Limpeza de valores negativos em `vlrLiquido` por ano\"))\n",
    "\n",
    "# Loop pelos arquivos\n",
    "for ano, caminho in arquivos.items():\n",
    "    # Leitura com separador \";\" e encoding\n",
    "    df = pd.read_csv(caminho, sep=';', encoding='utf-8', low_memory=False)\n",
    "    \n",
    "    # Conversão segura para float\n",
    "    df['vlrLiquido'] = pd.to_numeric(df['vlrLiquido'], errors='coerce')\n",
    "    \n",
    "    # Identificação de negativos\n",
    "    negativos_df = df[df['vlrLiquido'] < 0]\n",
    "    qtd_negativos = negativos_df.shape[0]\n",
    "\n",
    "    # Exibição dos resultados\n",
    "    display(Markdown(f\"### Limpeza de valores negativos na base de {ano}\"))\n",
    "    display(Markdown(f\"**Total de registros negativos encontrados:** `{qtd_negativos}`\"))\n",
    "\n",
    "    if qtd_negativos > 0:\n",
    "        display(negativos_df[['txNomeParlamentar', 'sgUF', 'sgPartido', 'vlrLiquido']].head())\n",
    "    \n",
    "    # Remoção dos registros negativos\n",
    "    df = df[df['vlrLiquido'] >= 0]\n",
    "    \n",
    "    # Adiciona a coluna de ano para controle futuro\n",
    "    df['ano_base'] = int(ano)\n",
    "    \n",
    "    # Salva na lista\n",
    "    dfs_limpos.append(df)\n",
    "\n",
    "# Unificação dos DataFrames limpos\n",
    "df_completo = pd.concat(dfs_limpos, ignore_index=True)\n",
    "\n",
    "# Exibição final\n",
    "display(Markdown(\"## Dados unificados e limpos com sucesso\"))\n",
    "display(Markdown(f\"**Total de registros no `df_completo`:** `{df_completo.shape[0]}`\"))\n",
    "display(Markdown(f\"**Total de variáveis:** `{df_completo.shape[1]}`\"))\n",
    "display(df_completo.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Verificando se restaram valores negativos após a limpeza\n",
    "negativos_restantes = df_completo[df_completo['vlrLiquido'] < 0]\n",
    "qtd_restantes = negativos_restantes.shape[0]\n",
    "\n",
    "# Exibir o resultado da verificação\n",
    "if qtd_restantes == 0:\n",
    "    display(Markdown(\" **Nenhum valor negativo encontrado na coluna `vlrLiquido`. A limpeza foi bem-sucedida!**\"))\n",
    "else:\n",
    "    display(Markdown(f\" **Ainda existem `{qtd_restantes}` registros com valores negativos em `vlrLiquido`.**\"))\n",
    "    display(negativos_restantes[['txNomeParlamentar', 'sgUF', 'sgPartido', 'vlrLiquido']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Continuação do 3.1 Seleção dos Dados com os dados limpos \n",
    "\n",
    "# 2️ - Seleção de colunas relevantes e criação da nova feature\n",
    "colunas_selecionadas = [\n",
    "    'txNomeParlamentar', 'sgUF', 'sgPartido', 'txtDescricao',\n",
    "    'vlrDocumento', 'numMes', 'numAno', 'vlrLiquido'\n",
    "]\n",
    "\n",
    "# Cria uma nova base apenas com as colunas relevantes\n",
    "df_modelo = df_completo[colunas_selecionadas].copy()\n",
    "\n",
    "# 3️ - Criação da coluna de custo total por parlamentar\n",
    "df_modelo['custo_total_parlamentar'] = df_modelo.groupby('txNomeParlamentar')['vlrLiquido'].transform('sum')\n",
    "\n",
    "# 4️ - Exibição final\n",
    "from IPython.display import display, Markdown\n",
    "display(Markdown(\"### Amostra da base `df_modelo` com coluna `custo_total_parlamentar`:\"))\n",
    "display(df_modelo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1️ Identificar registros com valores ausentes\n",
    "na_total = df_modelo.isnull().sum().sum()\n",
    "linhas_nan = df_modelo[df_modelo.isnull().any(axis=1)]\n",
    "\n",
    "display(Markdown(\"## Verificação de valores ausentes (`NaN`) em `df_modelo`\"))\n",
    "display(Markdown(f\"**Total de registros com valores ausentes:** `{linhas_nan.shape[0]}`\"))\n",
    "display(Markdown(f\"**Total de valores `NaN` na base:** `{na_total}`\"))\n",
    "\n",
    "if linhas_nan.shape[0] > 0:\n",
    "    display(Markdown(\"**Exemplo de registros com valores ausentes:**\"))\n",
    "    display(linhas_nan.head())\n",
    "\n",
    "# 2️ Remover registros com qualquer valor ausente\n",
    "df_modelo = df_modelo.dropna().reset_index(drop=True)\n",
    "\n",
    "# 3️ Exibir como ficou a base depois da limpeza\n",
    "display(Markdown(\"##  `df_modelo` após remoção dos registros com valores ausentes\"))\n",
    "display(Markdown(f\"**Total de registros restantes:** `{df_modelo.shape[0]}`\"))\n",
    "display(Markdown(f\"**Total de colunas:** `{df_modelo.shape[1]}`\"))\n",
    "display(df_modelo.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover registros onde vlrLiquido > vlrDocumento\n",
    "df_modelo = df_modelo[df_modelo['vlrLiquido'] <= df_modelo['vlrDocumento']].reset_index(drop=True)\n",
    "\n",
    "display(Markdown(\"✅ **Registros inconsistentes removidos com sucesso!**\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar a coluna faixa_valor com base no valor líquido\n",
    "df_modelo['faixa_valor'] = pd.cut(\n",
    "    df_modelo['vlrLiquido'],\n",
    "    bins=[0, 250, 1000, 2500, 10000, float('inf')],\n",
    "    labels=['Muito Baixo', 'Baixo', 'Médio', 'Alto', 'Muito Alto']\n",
    ")\n",
    "\n",
    "display(Markdown(\"✅ **Coluna `faixa_valor` recriada com sucesso!**\"))\n",
    "display(df_modelo[['vlrLiquido', 'faixa_valor']].sample(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Nesta etapa, realizamos um processo criterioso de saneamento da base de dados, com o objetivo de **garantir a integridade, consistência e confiabilidade das informações** que alimentarão os modelos de aprendizado supervisionado.\n",
    "\n",
    "A limpeza dos dados é uma fase crítica, pois **modelos de Machine Learning são altamente sensíveis a ruídos, valores inválidos e informações incompletas**. Um dado inconsistente pode comprometer toda a performance do modelo — e pior, gerar conclusões enganosas para decisões reais.\n",
    "\n",
    "### Ações realizadas:\n",
    "\n",
    "1. **Remoção de valores negativos em `vlrLiquido`:**  \n",
    "   Foram detectados e eliminados milhares de registros com valores negativos, o que representa **erros claros de entrada de dados**. Como o `vlrLiquido` representa o valor final pago em uma despesa, não é plausível que ele seja negativo.\n",
    "\n",
    "2. **Eliminação de registros com `vlrLiquido` maior que `vlrDocumento`:**  \n",
    "   Foram identificados **2 registros** em que o valor líquido ultrapassava o valor bruto do documento, o que é logicamente incorreto. Esses registros foram removidos.\n",
    "\n",
    "3. **Remoção de valores ausentes (`NaN`)**  \n",
    "   Após as transformações e construções de variáveis, foram encontrados **2.135 registros com valores ausentes** em colunas relevantes. Esses registros foram removidos para **evitar viés nos algoritmos de predição** e assegurar que todas as variáveis estejam completas.\n",
    "\n",
    "4. **Exclusão de colunas irrelevantes ao modelo:**  \n",
    "   Diversas colunas foram descartadas por não contribuírem para a modelagem ou por conterem informações sensíveis e desnecessárias (como CPF, CNPJ, códigos internos da Câmara, etc.).\n",
    "\n",
    "5. **Reconstrução da variável `faixa_valor`:**  \n",
    "   Foi recriada uma variável categórica com base no valor líquido (`vlrLiquido`), segmentando os gastos em faixas como:\n",
    "   - Muito Baixo (até R$250)\n",
    "   - Baixo (até R$1.000)\n",
    "   - Médio (até R$2.500)\n",
    "   - Alto (até R$10.000)\n",
    "   - Muito Alto (acima de R$10.000)\n",
    "\n",
    "   Essa variável poderá ser **utilizada em análises estatísticas, visualizações e até como feature para modelos classificatórios**.\n",
    "\n",
    "---\n",
    "\n",
    "### Benefícios diretos dessa etapa:\n",
    "\n",
    "- **Redução de ruídos** que impactariam negativamente na acurácia dos modelos.\n",
    "- **Evita o overfitting** com dados duplicados ou corrompidos.\n",
    "- **Aumenta a confiabilidade das previsões**, ao garantir que os dados sigam uma lógica de negócios clara.\n",
    "- **Permite extração de insights mais precisos**, facilitando comparações, agrupamentos e análises de tendência.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrQDOkhBQq2h"
   },
   "source": [
    "## 3.3 Construção de Dados Derivados   <a class=\"anchor\" id=\"dados-derivados\"></a>\n",
    "\n",
    "\n",
    "Nesta etapa do CRISP-DM, realizamos a **engenharia de atributos** — um passo estratégico onde criamos novas variáveis a partir das já existentes com o objetivo de enriquecer a base de dados, ampliar a capacidade preditiva dos modelos e facilitar análises exploratórias.\n",
    "\n",
    "### Objetivo\n",
    "Criar **atributos derivados** que ajudem a capturar padrões de comportamento de gastos dos parlamentares ao longo do tempo, considerando variáveis como UF, partido político e tipos de despesas.\n",
    "\n",
    "---\n",
    "\n",
    "### Variáveis Derivadas Criadas:\n",
    "\n",
    "1. **`gasto_uf`**: soma do valor líquido (`vlrLiquido`) por UF  \n",
    "   → Ajuda a entender qual estado apresenta maior volume de gastos.\n",
    "\n",
    "2. **`gasto_partido`**: soma do valor líquido por partido político (`sgPartido`)  \n",
    "   → Permite investigar se há padrão de gasto por filiação partidária.\n",
    "\n",
    "3. **`vlr_medio_por_tipo`**: valor médio por tipo de despesa (`txtDescricao`)  \n",
    "   → Evidencia quais tipos de despesa têm maior custo médio.\n",
    "\n",
    "4. **`ano_mes`**: coluna criada combinando `numAno` e `numMes`  \n",
    "   → Facilita análises temporais e séries históricas.\n",
    "\n",
    "5. **`faixa_valor`**: categorização dos valores líquidos em faixas (\"Até 500\", \"500–1000\", \"1000–2000\", \"Acima de 2000\")  \n",
    "   → Essencial para entender a distribuição dos valores e criar segmentações visuais.\n",
    "\n",
    "---\n",
    "\n",
    "### Benefícios das variáveis derivadas para o modelo\n",
    "\n",
    "-  **Aumentam o poder explicativo dos modelos supervisionados**, ao fornecer mais contexto.\n",
    "-  **Melhoram a visualização e a interpretação dos dados**, tanto em análises exploratórias quanto em relatórios gerenciais.\n",
    "-  **Permitem identificar padrões, desvios ou inconsistências** com mais facilidade.\n",
    "-  **Transformam dados brutos em informações mais robustas e contextualizadas**, aproximando os dados da realidade do negócio.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "cG1gaT08Qq2h"
   },
   "outputs": [],
   "source": [
    "# 3.3 Construção de Dados Derivados\n",
    "\n",
    "\n",
    "# Média de gastos mensais por parlamentar\n",
    "gastos_mensais = df_modelo.groupby(['txNomeParlamentar', 'numAno', 'numMes'])['vlrLiquido'].sum().reset_index()\n",
    "media_mensal = gastos_mensais.groupby('txNomeParlamentar')['vlrLiquido'].mean()\n",
    "df_modelo['media_mensal_parlamentar'] = df_modelo['txNomeParlamentar'].map(media_mensal)\n",
    "\n",
    "# Total de gasto por UF\n",
    "gasto_uf = df_modelo.groupby('sgUF')['vlrLiquido'].sum()\n",
    "df_modelo['gasto_uf'] = df_modelo['sgUF'].map(gasto_uf)\n",
    "\n",
    "# Total de gasto por partido\n",
    "gasto_partido = df_modelo.groupby('sgPartido')['vlrLiquido'].sum()\n",
    "df_modelo['gasto_partido'] = df_modelo['sgPartido'].map(gasto_partido)\n",
    "\n",
    "# Quantidade de despesas por parlamentar\n",
    "qtd_despesas = df_modelo['txNomeParlamentar'].value_counts()\n",
    "df_modelo['qtd_despesas_parlamentar'] = df_modelo['txNomeParlamentar'].map(qtd_despesas)\n",
    "\n",
    "# Valor médio por tipo de despesa\n",
    "vlr_medio_tipo = df_modelo.groupby('txtDescricao')['vlrLiquido'].mean()\n",
    "df_modelo['vlr_medio_por_tipo'] = df_modelo['txtDescricao'].map(vlr_medio_tipo)\n",
    "\n",
    "# Exibição\n",
    "display(Markdown(\"## Novas variáveis derivadas adicionadas com sucesso\"))\n",
    "display(Markdown(f\"**Shape atual do `df_modelo`:** {df_modelo.shape[0]} registros e {df_modelo.shape[1]} colunas\"))\n",
    "display(df_modelo.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdig3vgbQq2i"
   },
   "source": [
    "## 3.4 Integração de Dados  <a class=\"anchor\" id=\"integracao-dados\"></a>\n",
    "\n",
    "\n",
    "Nesta etapa, consolidamos os dados de diferentes anos (2023, 2024 e 2025) em um único DataFrame (`df_completo`). Isso foi fundamental para garantir que a análise futura tenha **visão longitudinal** e **comparabilidade temporal**.\n",
    "\n",
    "### Ações realizadas:\n",
    "- Leitura dos arquivos separados por ano, com estrutura padronizada\n",
    "- Conversão de tipos de dados (ex: `vlrLiquido` como float)\n",
    "- Inclusão da coluna `ano_base` para identificação da origem temporal\n",
    "- Remoção de registros inválidos (valores negativos, `NaN`)\n",
    "- Eliminação de registros duplicados\n",
    "- Concatenação das três bases em um único conjunto integrado\n",
    "\n",
    "### Benefícios da Integração:\n",
    "- Permite análises históricas e temporais\n",
    "- Garante coesão estrutural para uso em modelos preditivos\n",
    "- Aumenta o volume de dados, fortalecendo a robustez estatística\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Fdb51UHGQq2i",
    "outputId": "44ddea98-0ea3-431e-e3a0-bb2ca60929d9"
   },
   "outputs": [],
   "source": [
    "# Verificando se existe a coluna 'ano_base'\n",
    "print(df_completo['ano_base'].unique())  # Deve retornar: [2023, 2024, 2025]\n",
    "\n",
    "# Verificando a quantidade de registros por ano\n",
    "df_completo['ano_base'].value_counts()\n",
    "\n",
    "# Verificando duplicatas (caso já não tenha sido feito)\n",
    "duplicatas = df_completo.duplicated()\n",
    "print(f\"Total de registros duplicados: {duplicatas.sum()}\")\n",
    "\n",
    "display(Markdown(\"\"\"\n",
    "### 🔗 Integração de Dados Realizada com Sucesso\n",
    "\n",
    "Durante a etapa 3.4 da metodologia CRISP-DM, realizamos a integração das bases históricas de **gastos parlamentares dos anos de 2023, 2024 e 2025**. A consolidação foi feita com base na padronização das colunas e no uso da variável `ano_base` para identificar a origem de cada registro.\n",
    "\n",
    "#### ✅ Validações realizadas:\n",
    "\n",
    "- **Anos presentes na base integrada**: `2023`, `2024`, `2025`\n",
    "- **Verificação de duplicatas**: Nenhum registro duplicado encontrado (`0 registros duplicados`)\n",
    "\n",
    "Essas validações garantem que o `DataFrame df_completo` está pronto para ser utilizado nas próximas etapas do projeto, com **confiança na qualidade e integridade dos dados**.\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBP0giRBQq2i"
   },
   "source": [
    "### Construct Our Primary Data Set\n",
    "Join data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Análise Exploratória dos Dados (EDA) <a class=\"anchor\" id=\"analise-dados\"></a>\n",
    "\n",
    "A fase de Análise Exploratória de Dados (EDA) é crucial para aprofundar nosso entendimento sobre as despesas parlamentares. O objetivo aqui é utilizar visualizações e estatísticas para descobrir padrões, identificar anomalias e responder às questões exploratórias que levantamos na primeira fase do projeto.\n",
    "Para conduzir esta análise de forma estruturada, seguiremos um caminho que vai do geral ao específico, dividido em três abordagens principais:\n",
    "\n",
    "1.  **Visão Agregada dos Gastos:** Iniciaremos com uma visão macro, utilizando gráficos de barras para identificar os principais atores e fatores de custo. Analisaremos os totais e médias de gastos para responder a perguntas como:\n",
    "    * Quais parlamentares acumularam os maiores custos?\n",
    "\n",
    "    * Quais UFs e Partidos concentram o maior volume financeiro?\n",
    "    * Quais tipos de despesa possuem o maior valor médio por transação?\n",
    "\n",
    "2.  **Análise da Distribuição dos Valores:** Em seguida, vamos além dos totais e médias. Com o uso de boxplots, investigaremos a **distribuição** dos valores de despesa (`vlrLiquido`) dentro das principais categorias (Partido e UF). Isso nos ajudará a entender a variabilidade, a mediana dos gastos e a presença de valores discrepantes em cada grupo.\n",
    "\n",
    "3.  **Análise de Perfil Específico (Drill-Down):** Por fim, faremos uma análise de \"drill-down\", focando em um insight específico obtido na primeira etapa. Vamos isolar o parlamentar com o maior gasto acumulado e investigar em detalhe o seu perfil de despesas, entendendo quais são suas categorias mais frequentes.\n",
    "\n",
    "Ao final desta seção, teremos um conjunto de insights visuais que não apenas respondem às nossas questões, mas também fornecem uma base sólida para as decisões que tomaremos na etapa de **Modelagem**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Análise das Principais Dimensões de Gasto**\n",
    "\n",
    "\n",
    "### 1️ - Top 5 Parlamentares por Custo Total\n",
    "> **O que mostra:** Os parlamentares com maior volume de gastos no período analisado.  \n",
    "> **Insight:** Permite identificar concentrações de gastos por indivíduo e investigar comportamentos fora do padrão.\n",
    "\n",
    "### 2️ - Top 10 UFs por Gastos\n",
    "> **O que mostra:** Os estados da federação com maior soma de despesas parlamentares.  \n",
    "> **Insight:** Auxilia a visualizar a distribuição geográfica dos gastos.\n",
    "\n",
    "### 3️ - Top 10 Partidos por Gastos\n",
    "> **O que mostra:** Os partidos políticos com maiores gastos médios agregados.  \n",
    "> **Insight:** Pode revelar padrões partidários nos gastos, com possíveis implicações políticas.\n",
    "\n",
    "### 4️ - Tipos de Despesa com Maior Valor Médio\n",
    "> **O que mostra:** Quais tipos de despesa apresentam maior média de valores reembolsados.  \n",
    "> **Insight:** Ajuda a identificar os tipos de gastos mais onerosos, que podem demandar auditoria ou justificativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código para visualizações agregadas com Plotly\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "# Define um template padrão para o Plotly\n",
    "pio.templates.default = \"plotly_white\"\n",
    "df_modelo = pd.DataFrame(df_completo)\n",
    "\n",
    "# Função para formatar como R$ com ponto de milhar e vírgula decimal\n",
    "def formatar_valor(valor):\n",
    "# Garante que está lidando com o DataFrame correto\n",
    "    return f\"R$ {valor:,.2f}\".replace(\",\", \"X\").replace(\".\", \",\").replace(\"X\", \".\")\n",
    "\n",
    "# 1️ Top 5 Parlamentares por Custo Total\n",
    "top_parlamentares = (\n",
    "    df_modelo.groupby('txNomeParlamentar')['custo_total_parlamentar']\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(5)\n",
    "    .reset_index()\n",
    ")\n",
    "top_parlamentares['texto'] = top_parlamentares['custo_total_parlamentar'].apply(formatar_valor)\n",
    "\n",
    "fig1 = px.bar(\n",
    "    top_parlamentares,\n",
    "    x='custo_total_parlamentar',\n",
    "    y='txNomeParlamentar',\n",
    "    orientation='h',\n",
    "    title='<b>Top 5 Parlamentares por Custo Total Acumulado</b>',\n",
    "    labels={'custo_total_parlamentar': 'Custo Total (R$)', 'txNomeParlamentar': 'Parlamentar'},\n",
    "    text='texto'\n",
    ")\n",
    "fig1.update_layout(showlegend=False, yaxis={'categoryorder':'total ascending'})\n",
    "fig1.update_traces(textposition='outside', marker_color='#636EFA')\n",
    "\n",
    "\n",
    "# 2️ Top 10 UFs por Gasto Total\n",
    "top_ufs = (\n",
    "    df_modelo.groupby('sgUF')['gasto_uf']\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(10)\n",
    "    .reset_index()\n",
    ")\n",
    "top_ufs['texto'] = top_ufs['gasto_uf'].apply(formatar_valor)\n",
    "\n",
    "fig2 = px.bar(\n",
    "    top_ufs,\n",
    "    x='gasto_uf',\n",
    "    y='sgUF',\n",
    "    orientation='h',\n",
    "    title='<b>Top 10 UFs por Gastos Totais</b>',\n",
    "    labels={'gasto_uf': 'Gasto Total (R$)', 'sgUF': 'UF'},\n",
    "    text='texto'\n",
    ")\n",
    "fig2.update_layout(showlegend=False, yaxis={'categoryorder':'total ascending'})\n",
    "fig2.update_traces(textposition='outside', marker_color='#EF553B')\n",
    "\n",
    "\n",
    "# 3️ Top 10 Partidos por Gasto Total\n",
    "top_partidos = (\n",
    "    df_modelo.groupby('sgPartido')['gasto_partido']\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(10)\n",
    "    .reset_index()\n",
    ")\n",
    "top_partidos['texto'] = top_partidos['gasto_partido'].apply(formatar_valor)\n",
    "\n",
    "fig3 = px.bar(\n",
    "    top_partidos,\n",
    "    x='gasto_partido',\n",
    "    y='sgPartido',\n",
    "    orientation='h',\n",
    "    title='<b>Top 10 Partidos por Gastos Totais</b>',\n",
    "    labels={'gasto_partido': 'Gasto Total (R$)', 'sgPartido': 'Partido'},\n",
    "    text='texto'\n",
    ")\n",
    "fig3.update_layout(showlegend=False, yaxis={'categoryorder':'total ascending'})\n",
    "fig3.update_traces(textposition='outside', marker_color='#00CC96')\n",
    "\n",
    "\n",
    "# 4️ Top 10 Tipos de Despesa por Valor Médio\n",
    "top_tipos = (\n",
    "    df_modelo.groupby('txtDescricao')['vlr_medio_por_tipo']\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(10)\n",
    "    .reset_index()\n",
    ")\n",
    "top_tipos['texto'] = top_tipos['vlr_medio_por_tipo'].apply(formatar_valor)\n",
    "\n",
    "fig4 = px.bar(\n",
    "    top_tipos,\n",
    "    x='vlr_medio_por_tipo',\n",
    "    y='txtDescricao',\n",
    "    orientation='v',\n",
    "    title='<b>Top 10 Tipos de Despesa com Maior Valor Médio por Transação</b>',\n",
    "    labels={'vlr_medio_por_tipo': 'Valor Médio (R$)', 'txtDescricao': 'Tipo de Despesa'},\n",
    "    text='texto'\n",
    ")\n",
    "fig4.update_layout(showlegend=False, yaxis={'categoryorder':'total ascending'})\n",
    "fig4.update_traces(textposition='outside', marker_color='#AB63FA')\n",
    "\n",
    "\n",
    "# Exibir os gráficos\n",
    "fig1.show()\n",
    "fig2.show()\n",
    "fig3.show()\n",
    "fig4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Análise Bivariada e Multivariada**\n",
    "\n",
    "Nesta seção, cruzamos variáveis para encontrar relações e padrões mais complexos. Vamos focar em como o valor das despesas (`vlrLiquido`) varia entre as diferentes categorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar boxplots interativos com Plotly\n",
    "def plot_boxplot_by_category(df, category_col, value_col, title, n=10):\n",
    "    top_categories = df[category_col].value_counts().nlargest(n).index\n",
    "    df_filtered = df[df[category_col].isin(top_categories)]\n",
    "    \n",
    "    fig = px.box(df_filtered, \n",
    "                 x=category_col, \n",
    "                 y=value_col,\n",
    "                 title=title,\n",
    "                 points=False) # 'points=False' para não poluir com outliers\n",
    "    fig.update_layout(xaxis={'categoryorder':'total descending'})\n",
    "    fig.show()\n",
    "\n",
    "# Gasto por Partido\n",
    "plot_boxplot_by_category(df_modelo, 'sgPartido', 'vlrLiquido', 'Distribuição do Valor Líquido por Partido (Top 10)')\n",
    "\n",
    "# Gasto por UF\n",
    "plot_boxplot_by_category(df_modelo, 'sgUF', 'vlrLiquido', 'Distribuição do Valor Líquido por UF (Top 10)')\n",
    "\n",
    "\n",
    "display(Markdown(\"\"\"\n",
    "**Interpretação:**\n",
    "* **Valor por Partido:** Os boxplots mostram a mediana, os quartis e a dispersão dos valores de despesa por partido. Embora a frequência seja alta para PL e PT, a análise dos valores pode revelar que outros partidos têm despesas com mediana ou valores máximos mais altos. É importante observar a altura das \"caixas\" (intervalo interquartil) e a posição da linha da mediana.\n",
    "\"\"\"))\n",
    "\n",
    "\n",
    "* **Valor por UF:** Alguns estados podem ter uma mediana de gastos mais alta que outros, mesmo com menos registros. Isso pode ser devido a custos de vida regionais mais altos ou a uma cultura de gastos diferente entre as bancadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Análise de Perfil Detalhada**\n",
    "\n",
    "A EDA também serve para aprofundar a análise em pontos de interesse. Vamos investigar o perfil de gasto do parlamentar que mais gastou e, em seguida, analisar quais partidos mais utilizam o tipo de despesa de maior valor médio.\n",
    "\n",
    "#### **Perfil de Gastos do Top 1 Parlamentar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Identificar o parlamentar com o maior custo total\n",
    "top_parlamentar_nome = top_parlamentares.iloc[0]['txNomeParlamentar']\n",
    "\n",
    "# 2. Filtrar o DataFrame para conter apenas as despesas desse parlamentar\n",
    "df_top_parlamentar = df_modelo[df_modelo['txNomeParlamentar'] == top_parlamentar_nome]\n",
    "\n",
    "# 3. Gerar um gráfico dos tipos de despesa para esse parlamentar\n",
    "fig = px.bar(\n",
    "    df_top_parlamentar['txtDescricao'].value_counts().reset_index(),\n",
    "    x='count',\n",
    "    y='txtDescricao',\n",
    "    orientation='h',\n",
    "    title=f'<b>Tipos de Despesa Mais Frequentes para: {top_parlamentar_nome}</b>',\n",
    "    labels={'count': 'Frequência', 'txtDescricao': 'Tipo de Despesa'}\n",
    ")\n",
    "fig.update_layout(yaxis={'categoryorder':'total ascending'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvEceHzUQq2j"
   },
   "source": [
    "# 5. Modelagem <a class=\"anchor\" id=\"modelagem\"></a>\n",
    "As the first step in modelling, you'll select the actual modelling technique that you'll be using. Although you may have already selected a tool during the business understanding phase, at this stage you'll be selecting the specific modelling technique e.g. decision-tree building with C5.0, or neural network generation with back propagation. If multiple techniques are applied, perform this task separately for each technique.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9H-GXDBNQq2j"
   },
   "source": [
    "## 5.1. Técnicas de Modelagem <a class=\"anchor\" id=\"tecnicas-modelagem\"></a>\n",
    "Document the actual modelling technique that is to be used.\n",
    "\n",
    "Import Models below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "nhhwoVkVQq2k"
   },
   "outputs": [],
   "source": [
    "X = df.drop('y', axis=1)\n",
    "y = df['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uFK8exaK-68S"
   },
   "outputs": [],
   "source": [
    "# Normalização dos dados numéricos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "categorical_features = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
    "numeric_features = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8ClvOxXQq2k"
   },
   "source": [
    "## 5.2. Teste de Modelos <a class=\"anchor\" id=\"teste-modelos\"></a>\n",
    "Many modelling techniques make specific assumptions about the data, for example that all attributes have uniform distributions, no missing values allowed, class attribute must be symbolic etc. Record any assumptions made.\n",
    "\n",
    "-\n",
    "-\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUz08h6RBC1a"
   },
   "outputs": [],
   "source": [
    "pipeline_lr = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(C=1.0, solver='liblinear'))\n",
    "])\n",
    "\n",
    "pipeline_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2))\n",
    "])\n",
    "\n",
    "pipeline_gb = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQFDFtQoQq2k"
   },
   "source": [
    "## 5.3. Construção do Modelo (Build) <a class=\"anchor\" id=\"construcao-modelo\"></a>\n",
    "Run the modelling tool on the prepared dataset to create one or more models.\n",
    "\n",
    "**Parameter settings** - With any modelling tool there are often a large number of parameters that can be adjusted. List the parameters and their chosen values, along with the rationale for the choice of parameter settings.\n",
    "\n",
    "**Models** - These are the actual models produced by the modelling tool, not a report on the models.\n",
    "\n",
    "**Model descriptions** - Describe the resulting models, report on the interpretation of the models and document any difficulties encountered with their meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192
    },
    "collapsed": true,
    "id": "JFUvxZVmQq2k",
    "outputId": "418627bc-a187-4460-b50f-bf8f876e8e59"
   },
   "outputs": [],
   "source": [
    "pipeline_lr.fit(X_train, y_train)\n",
    "pipeline_rf.fit(X_train, y_train)\n",
    "pipeline_gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZL6W-w7YQq2k"
   },
   "source": [
    "## 5.4. Avaliação de Performance <a class=\"anchor\" id=\"avaliacao-modelo\"></a>\n",
    "Interpret the models according to your domain knowledge, your data mining success criteria and your desired test design. Judge the success of the application of modelling and discovery techniques technically, then contact business analysts and domain experts later in order to discuss the data mining results in the business context. This task only considers models, whereas the evaluation phase also takes into account all other results that were produced in the course of the project.\n",
    "\n",
    "At this stage you should rank the models and assess them according to the evaluation criteria. You should take the business objectives and business success criteria into account as far as you can here. In most data mining projects a single technique is applied more than once and data mining results are generated with several different techniques.\n",
    "\n",
    "**Model assessment** - Summarise the results of this task, list the qualities of your generated models (e.g.in terms of accuracy) and rank their quality in relation to each other.\n",
    "\n",
    "**Revised parameter settings** - According to the model assessment, revise parameter settings and tune them for the next modelling run. Iterate model building and assessment until you strongly believe that you have found the best model(s). Document all such revisions and assessments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U1YFLClIQq2k",
    "outputId": "bfdbddad-824f-4a40-96cb-6cec08c7cb7d"
   },
   "outputs": [],
   "source": [
    "model_metrics = {}\n",
    "\n",
    "# Lista de modelos para avaliar\n",
    "models = ['lr', 'rf', 'gb']\n",
    "\n",
    "for model_key in models:\n",
    "    try:\n",
    "        pipelines[model_key].fit(X_train, y_train)\n",
    "\n",
    "        y_pred = pipelines[model_key].predict(X_test)\n",
    "        y_proba = pipelines[model_key].predict_proba(X_test)[:, 1]  # Probabilidades para AUC-ROC\n",
    "\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        auc_roc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "        model_metrics[model_key] = {\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1-Score': f1,\n",
    "            'AUC-ROC': auc_roc\n",
    "        }\n",
    "\n",
    "        print(f\"Resultados para {model_key}:\")\n",
    "        print(f\"Precisão: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1-Score: {f1:.4f}\")\n",
    "        print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "        print(\"-----\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao treinar ou avaliar o modelo {model_key}: {e}\")\n",
    "\n",
    "for model_key in models:\n",
    "    try:\n",
    "        y_pred = pipelines[model_key].predict(X_test)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        print(f\"Matriz de Confusão para {model_key}:\")\n",
    "        print(cm)\n",
    "        print(\"-----\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao gerar matriz de confusão para {model_key}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Avaliação do Modelo <a class=\"anchor\" id=\"avaliacao-modelo\"></a>\n",
    "\n",
    "## 6.1. Regressão Logística (lr): <a class=\"anchor\" id=\"regressao-logistica\"></a>\n",
    "\n",
    "Precisão: 69.26% - Este modelo tem uma boa taxa de precisão, indicando que quando prevê que um cliente se inscreverá, está correto aproximadamente 69.26% das vezes.\n",
    "Recall: 40.30% - Capta 40.30% dos casos positivos reais, o que é moderado.\n",
    "F1-Score: 50.95% - Um equilíbrio razoável entre precisão e recall.\n",
    "AUC-ROC: 92.92% - Excelente capacidade de discriminação entre as classes positivas e negativas.\n",
    "Matriz de Confusão: Com um número relativamente baixo de falsos positivos (83) e uma quantidade moderada de falsos negativos (277).\n",
    "Random Forest (rf):\n",
    "\n",
    "Precisão: 65.06% - Ligeiramente inferior à regressão logística em termos de precisão.\n",
    "Recall: 37.72% - Menor do que a regressão logística, indicando uma capacidade mais fraca de capturar todos os positivos reais.\n",
    "F1-Score: 47.75% - Reflete o compromisso entre precisão e recall inferior ao da regressão logística.\n",
    "AUC-ROC: 92.58% - Muito boa, mas ligeiramente inferior à regressão logística.\n",
    "Matriz de Confusão: Mais falsos positivos (94) e falsos negativos (289) do que a regressão logística, indicando uma eficiência geral mais baixa.\n",
    "Gradient Boosting (gb):\n",
    "\n",
    "Precisão: 69.42% - Similar à regressão logística e ligeiramente superior ao Random Forest.\n",
    "Recall: 41.59% - O melhor recall dos três modelos, capturando uma proporção maior de casos positivos.\n",
    "F1-Score: 52.02% - O melhor F1-Score, indicando o melhor equilíbrio entre precisão e recall.\n",
    "AUC-ROC: 93.58% - A melhor das três, mostrando a superioridade do Gradient Boosting em discriminar entre as classes.\n",
    "Matriz de Confusão: Semelhante ao Random Forest em termos de falsos positivos, mas com menos falsos negativos, melhorando tanto a precisão quanto o recall.\n",
    "Conclusões e Recomendações\n",
    "Gradient Boosting parece ser o modelo mais forte em geral, apresentando o melhor equilíbrio entre todas as métricas. Com a maior AUC-ROC e o melhor F1-Score, ele demonstra uma capacidade superior de manejar a classificação de uma maneira equilibrada, tornando-o ideal para situações onde tanto a precisão quanto o recall são importantes.\n",
    "\n",
    "Regressão Logística ainda se mostra uma opção viável, especialmente se a interpretabilidade do modelo é uma prioridade, visto que modelos lineares como este oferecem insights mais diretos sobre como as características estão influenciando as previsões.\n",
    "\n",
    "Random Forest, embora robusto e com um bom desempenho geral, parece ser ligeiramente superado pelos outros modelos em termos de métricas chave neste cenário específico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Aplicação prática (Deployment)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
