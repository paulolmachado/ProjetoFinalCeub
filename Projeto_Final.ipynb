{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTNXidF3Qq2K"
   },
   "source": [
    "# **Ci√™ncia de Dados e Machine Learning**\n",
    "\n",
    "## **Projeto Final do Curso**\n",
    "\n",
    "---\n",
    "\n",
    "### **Alunos:**\n",
    "\n",
    "> Charles Bezerra - 52400351\n",
    "\n",
    "> Jheferson Warley - 52400071\n",
    "\n",
    "> Paulo Machado - 52400245\n",
    "\n",
    "---\n",
    "\n",
    "### Tema: **Despesas pela Cota para Exerc√≠cio da Atividade Parlamentar**\n",
    "\n",
    "### Base de Dados: https://dadosabertos.camara.leg.br/swagger/api.html?tab=staticfile\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RfgYroaQq2N"
   },
   "source": [
    "Este projeto final do curso de **Ci√™ncia de Dados e Machine** Learning do UniCEUB se baseia na metodologia *Cross-Industry Standard Process for Data Mining - CRISP-DM* (https://www.sv-europe.com/crisp-dm-methodology/), oferecendo uma abordagem estruturada para planejar um projeto de minera√ß√£o de dados de uma forma robusta.\n",
    "\n",
    "Este modelo representa uma sequ√™ncia idealizada de eventos. Na pr√°tica, muitas das tarefas podem ser realizadas em uma ordem diferente, e frequentemente ser√° necess√°rio voltar a tarefas anteriores e repetir certas a√ß√µes.\n",
    "\n",
    "<div>\n",
    "<img src=\"FasesCRISP-DM.png\" width=\"50%\">\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjrc0DUFQq2O"
   },
   "source": [
    "## **Etapas do Processo CRISP-DM**\n",
    "\n",
    "### 1. [Entendimento do Neg√≥cio](#business-understanding)\n",
    "Compreens√£o dos objetivos de neg√≥cio, contexto organizacional e defini√ß√£o das metas anal√≠ticas.\n",
    "\n",
    "- [1.1 Avalia√ß√£o da Situa√ß√£o Atual](#avaliacao-da-situacao)\n",
    "- [1.2 Resultados Esperados](#resultados-esperados)\n",
    "- [1.3 Quest√µes de Pesquisa](#questoes-de-pesquisa)\n",
    "<!-- - [1.4 Plano de Projeto](#plano-do-projeto) -->\n",
    "\n",
    "---\n",
    "\n",
    "### 2. [Entendimento dos Dados](#entendimento-dados)\n",
    "Explora√ß√£o inicial dos dados, coleta e verifica√ß√£o da qualidade.\n",
    "\n",
    "- [2.1 Relatorio Inicial](#relatorio-inicial)\n",
    "- [2.2 Descri√ß√£o dos Dados](#descricao-dados)\n",
    "- [2.3 Explora√ß√£o dos Dados](#exploracao-dados)\n",
    "- [2.4 Verifica√ß√£o da Qualidade dos Dados](#qualidade-dos-dados)\n",
    "\n",
    "---\n",
    "\n",
    "### 3. [Prepara√ß√£o dos Dados](#preparacao-dados)\n",
    "Constru√ß√£o do dataset final que ser√° utilizado para modelagem.\n",
    "\n",
    "- [3.1 Sele√ß√£o dos Dados](#selecao-dados)\n",
    "- [3.2 Limpeza dos Dados](#limpeza-dados)\n",
    "- [3.3 An√°lise Explorat√≥ria de Dados](#analise-dados)\n",
    "\n",
    "---\n",
    "\n",
    "### 4. [Modelagem](#modelagem)\n",
    "Aplica√ß√£o de t√©cnicas de modelagem estat√≠stica ou de machine learning.\n",
    "\n",
    "- [4.1 T√©cnicas de Modelagem](#tecnicas-modelagem)\n",
    "- [4.2 Teste de Modelos](#teste-modelos)\n",
    "- [4.3 Constru√ß√£o dos Modelos](#construcao-modelo)\n",
    "- [4.4 Avalia√ß√£o de Performance](#avaliacao-modelo)\n",
    "\n",
    "---\n",
    "\n",
    "### 5. [Avalia√ß√£o do Modelo](#avaliacao-modelo)\n",
    "Verifica√ß√£o se os modelos preditivos atendem aos objetivos de neg√≥cio definidos para estimativa dos gastos parlamentares.\n",
    "\n",
    "- [5.1 Avalia√ß√£o da Performance dos Modelos](#Avalia√ß√£o-da-Performance-dos-Modelos)\n",
    "- [5.2 Interpreta√ß√£o dos Resultados](#interpretacao-dos-resultados)\n",
    "- [5.3 Revis√£o do Processo e Pr√≥ximos Passos](#revisao-do-processo-e-proximos-passos)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 6. [Implementa√ß√£o (Deployment)](#implementacao)\n",
    "Entrega pr√°tica do modelo, seja em relat√≥rio, dashboard, sistema ou API.\n",
    "\n",
    "- [6.1 Planejamento da Implementa√ß√£o](#planejamento-implementacao)\n",
    "- [6.2 Monitoramento e Manuten√ß√£o](#monitoramento)\n",
    "- [6.3 Documenta√ß√£o Final](#documentacao-final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pdYJHP76Qq2O"
   },
   "source": [
    "## 1. Entendimento do Neg√≥cio  <a class=\"anchor\" id=\"business-understanding\"></a>\n",
    "\n",
    "Atualmente, o cen√°rio pol√≠tico brasileiro se mostra em foco, principalmente quando se trata de despesas relacionadas √† sustenta√ß√£o do governo como todo. Neste contexto, as despesas parlamentares, limitadas por uma cota, s√£o frequentemente noticiadas devido a seu alto custo. As cotas parlamentares variam conforme o estado do deputado e √© destinado ao custeio de despesas relacionadas ao exerc√≠cio do mandato. As despesas incluem passagens a√©reas, locomo√ß√£o, hospedagens, servi√ßos de seguran√ßa, divulga√ß√£o de atividades parlamentares e contrata√ß√£o de pessoal.\n",
    "\n",
    "\n",
    "A C√¢mara dos Deputados divulga atrav√©s da plataforma de dados abertos do governo (https://dadosabertos.camara.leg.br/swagger/api.html?tab=staticfile) as despesas refentes ao consumo de cotas separadas por ano, Deputado, UF, tipo de despesas, entre outras classifica√ß√µes. Os arquivos podem ser baixador por ano, dispon√≠veis desde o ano 2018, nos formatos XML, JSON, CSV, XLSX e ODS.\n",
    "\n",
    "\n",
    "Para este projeto, selecionamos os dados relativos ao ano de 2024 (ano completo mais recente) com arquivos no formato CSV para melhor tratamento dos dados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2SqAlWIyQq2P"
   },
   "source": [
    "## 1.1 Avalia√ß√£o da Situa√ß√£o Atual<a class=\"anchor\" id=\"avaliacao-da-situacao\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFsmtXzxQq2P"
   },
   "source": [
    "A transpar√™ncia nos gastos p√∫blicos tem ganhado relev√¢ncia nos debates sociais e institucionais, principalmente no contexto pol√≠tico brasileiro. A C√¢mara dos Deputados disponibiliza, por meio do portal de Dados Abertos, informa√ß√µes detalhadas sobre a utiliza√ß√£o da Cota para o Exerc√≠cio da Atividade Parlamentar (CEAP), que contempla diversos tipos de despesas efetuadas pelos parlamentares no desempenho de suas fun√ß√µes.\n",
    "\n",
    "Apesar da disponibilidade dos dados, observa-se uma subutiliza√ß√£o dessas informa√ß√µes por parte da sociedade civil e dos √≥rg√£os fiscalizadores. O volume e a complexidade dos dados dificultam an√°lises diretas e conclusivas, exigindo ferramentas adequadas de tratamento, an√°lise e visualiza√ß√£o. Diante disso, este projeto visa utilizar t√©cnicas de an√°lise de dados e aprendizado de m√°quina para transformar os dados brutos em insights relevantes e acess√≠veis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWxWA-87Qq2P"
   },
   "source": [
    "## 1.2 Resultados Esperados<a class=\"anchor\" id=\"resultaods-esperados\"></a>\n",
    "\n",
    "Este projeto tem como objetivo geral analisar os gastos parlamentares por meio da base de dados da CEAP, abrangendo os anos de 2023, 2024 e 2025. Os resultados esperados incluem:\n",
    "\n",
    "- Desenvolvimento de relat√≥rios e dashboards anal√≠ticos para visualiza√ß√£o dos dados por deputado, partido pol√≠tico, unidade federativa (UF), tipo de despesa, fornecedor e per√≠odo (m√™s e ano).\n",
    "- An√°lises estat√≠sticas descritivas e comparativas, a fim de identificar padr√µes de gastos e varia√ß√µes relevantes entre diferentes grupos.\n",
    "- Detec√ß√£o de anomalias e poss√≠veis irregularidades nos registros de despesas.\n",
    "- Aplica√ß√£o de t√©cnicas de aprendizado de m√°quina (Machine Learning) com o objetivo de construir modelos preditivos capazes de estimar os gastos parlamentares futuros por partido ou UF, com base nos dados hist√≥ricos.\n",
    "\n",
    "O projeto segue a metodologia CRISP-DM, com foco na reprodutibilidade dos resultados e na cria√ß√£o de documenta√ß√£o clara e acess√≠vel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Quest√µes de Pesquisa<a class=\"anchor\" id=\"questoes-de-pesquisa\"></a>\n",
    "\n",
    "O projeto √© orientado por um conjunto de quest√µes explorat√≥rias e preditivas, que servir√£o como guia para as etapas anal√≠ticas e de modelagem.\n",
    "\n",
    "### Quest√µes Explorat√≥rias\n",
    "\n",
    "- Quais partidos pol√≠ticos apresentaram os maiores volumes de gasto no per√≠odo analisado?\n",
    "- Quais unidades federativas concentram os maiores gastos?\n",
    "- Quais s√£o os tipos de despesa mais recorrentes e qual seu impacto nos valores totais?\n",
    "- Como os gastos variam ao longo do tempo? Existe sazonalidade ou tend√™ncia?\n",
    "- H√° fornecedores recorrentes nos maiores gastos? Qual seu perfil?\n",
    "\n",
    "### Quest√µes Preditivas\n",
    "\n",
    "- √â poss√≠vel prever os gastos parlamentares futuros com base no hist√≥rico de dados?\n",
    "- Quais vari√°veis mais influenciam no volume de gastos (ex.: partido, UF, tipo de despesa, m√™s)?\n",
    "- Quais partidos ou unidades federativas t√™m maior propens√£o a apresentar aumentos nos gastos em futuros mandatos?\n",
    "\n",
    "Estas perguntas direcionam a constru√ß√£o dos indicadores, visualiza√ß√µes e modelos preditivos ao longo do projeto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4S-Y6p8VQq2R"
   },
   "source": [
    "# 2. Entendimento dos Dados <a class=\"anchor\" id=\"entendimento-dados\"></a>\n",
    "A etapa de entendimento dos dados tem como objetivo fornecer uma vis√£o inicial e aprofundada da estrutura, conte√∫do e qualidade do conjunto de dados dispon√≠vel para an√°lise. Trata-se de uma fase fundamental no processo anal√≠tico, pois permite identificar caracter√≠sticas importantes dos dados, potenciais inconsist√™ncias, aus√™ncia de valores e padr√µes que podem influenciar diretamente na prepara√ß√£o, modelagem e interpreta√ß√£o dos resultados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-6TQJ_4Qq2R"
   },
   "source": [
    "## 2.1 Relat√≥rio Inicial <a class=\"anchor\" id=\"relatorio-inicial\"></a>\n",
    "O conjunto de dados utilizado neste projeto refere-se √†s despesas parlamentares registradas na Cota para o Exerc√≠cio da Atividade Parlamentar (CEAP), compreendendo os anos de 2023, 2024 e 2025. Os dados foram extra√≠dos da API p√∫blica da C√¢mara dos Deputados, que disponibiliza os registros em diversos formatos. Para este trabalho, optou-se pelo formato `.csv`, considerando a facilidade de leitura e manipula√ß√£o em ambientes Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "X9OlrvX3Qq2R"
   },
   "outputs": [],
   "source": [
    "# Importa√ß√£o das Bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from catboost import CatBoostRegressor,Pool\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from IPython.display import display, Markdown\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "# Ignora todos os FutureWarning\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "D85E5K77Qq2S"
   },
   "outputs": [],
   "source": [
    "# Leitura dos dados\n",
    "df_2023 = pd.read_csv(\"DataBase/Ano-2023.csv\", sep=\";\", encoding=\"utf-8\", low_memory=False)\n",
    "df_2024 = pd.read_csv(\"DataBase/Ano-2024.csv\", sep=\";\", encoding=\"utf-8\", low_memory=False)\n",
    "df_2025 = pd.read_csv(\"DataBase/Ano-2025.csv\", sep=\";\", encoding=\"utf-8\", low_memory=False)\n",
    "\n",
    "# Combina√ß√£o dos tr√™s dataframes\n",
    "df_completo = pd.concat([df_2023, df_2024, df_2025], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibi√ß√£o das 5 primeiras linhas\n",
    "display(df_completo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZ8n1_pnQq2T"
   },
   "source": [
    "## 2.2 Descri√ß√£o dos Dados <a class=\"anchor\" id=\"descricao-dados\"></a>\n",
    "A seguir, s√£o apresentados o nome das colunas dispon√≠veis no dataset e o seu formato dimensional (linhas x colunas).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A tabela abaixo apresenta a descri√ß√£o de cada uma das vari√°veis dispon√≠veis no conjunto de dados utilizado.\n",
    "\n",
    "| Nome da Coluna                 | Descri√ß√£o                                                        |\n",
    "|-------------------------------|------------------------------------------------------------------|\n",
    "| `txNomeParlamentar`           | Nome do parlamentar                                              |\n",
    "| `cpf`                         | CPF do parlamentar (quando dispon√≠vel)                          |\n",
    "| `ideCadastro`                 | ID √∫nico do parlamentar                                          |\n",
    "| `nuCarteiraParlamentar`       | N√∫mero da carteira parlamentar                                   |\n",
    "| `nuLegislatura`               | N√∫mero da legislatura em exerc√≠cio                               |\n",
    "| `sgUF`                        | Unidade Federativa (estado)                                      |\n",
    "| `sgPartido`                   | Sigla do partido pol√≠tico                                        |\n",
    "| `codLegislatura`              | C√≥digo da legislatura                                            |\n",
    "| `numSubCota`                  | C√≥digo da subcota utilizada                                      |\n",
    "| `txtDescricao`                | Descri√ß√£o da subcota                                             |\n",
    "| `numEspecificacaoSubCota`     | C√≥digo da especifica√ß√£o da subcota                               |\n",
    "| `txtDescricaoEspecificacao`   | Descri√ß√£o detalhada da subcota                                   |\n",
    "| `txtFornecedor`               | Nome do fornecedor                                               |\n",
    "| `txtCNPJCPF`                  | CNPJ ou CPF do fornecedor                                        |\n",
    "| `txtNumero`                   | N√∫mero do documento fiscal                                       |\n",
    "| `indTipoDocumento`            | Tipo do documento (nota fiscal, recibo, etc.)                   |\n",
    "| `datEmissao`                  | Data de emiss√£o do documento                                     |\n",
    "| `vlrDocumento`                | Valor bruto do documento                                         |\n",
    "| `vlrGlosa`                    | Valor glosado/desconsiderado                                     |\n",
    "| `vlrLiquido`                  | Valor l√≠quido aceito                                             |\n",
    "| `numMes`                      | M√™s de refer√™ncia da despesa                                     |\n",
    "| `numAno`                      | Ano de refer√™ncia da despesa                                     |\n",
    "| `numParcela`                  | N√∫mero da parcela, quando aplic√°vel                              |\n",
    "| `txtPassageiro`               | Nome do passageiro (se transporte a√©reo)                         |\n",
    "| `txtTrecho`                   | Trecho da viagem (ida/volta)                                     |\n",
    "| `numLote`                     | N√∫mero do lote do documento                                      |\n",
    "| `numRessarcimento`            | N√∫mero de protocolo de ressarcimento                             |\n",
    "| `datPagamentoRestituicao`     | Data do pagamento de restitui√ß√£o                                 |\n",
    "| `vlrRestituicao`              | Valor restitu√≠do                                                 |\n",
    "| `nuDeputadoId`                | ID √∫nico do deputado                                             |\n",
    "| `ideDocumento`                | ID do documento                                                  |\n",
    "| `urlDocumento`                | Link para o documento oficial                                    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EemJ6DTeQq2U",
    "outputId": "7aa11b1f-b976-4a2a-f622-bab9cffdd1a7"
   },
   "outputs": [],
   "source": [
    "# Nomes das colunas\n",
    "df_completo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gnj33OcMQq2U",
    "outputId": "02529b54-4038-461c-f231-2ba7e0018cc2"
   },
   "outputs": [],
   "source": [
    "# Dimens√£o do dataframe\n",
    "df_completo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNxTQwN_Qq2V"
   },
   "source": [
    "## 2.3 Explora√ß√£o dos Dados <a class=\"anchor\" id=\"exploracao-dados\"></a>\n",
    "\n",
    "Essa etapa visa obter uma vis√£o geral das caracter√≠sticas dos dados, incluindo tipos de vari√°veis, estat√≠sticas descritivas e primeiros insights de distribui√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TwiVpT8FQq2W",
    "outputId": "ac44ac23-9621-40c0-a32a-61b7199f4960"
   },
   "outputs": [],
   "source": [
    "# Verifica√ß√£o de duplicatas\n",
    "qtde_duplicated = df_completo.duplicated().sum()\n",
    "print(f'Quantidade de duplicados: {qtde_duplicated}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estat√≠sticas descritivas\n",
    "df_completo.describe(include='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando valores nulos por coluna\n",
    "df_completo.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a quantidade de valores √∫nicos em algumas colunas-chave\n",
    "print(\"UFs:\", df_completo['sgUF'].nunique())\n",
    "print(\"Partidos:\", df_completo['sgPartido'].nunique())\n",
    "print(\"Tipos de despesa:\", df_completo['txtDescricao'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribui√ß√£o dos principais campos categ√≥ricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UF\n",
    "uf_counts = df_completo['sgUF'].value_counts().reset_index()\n",
    "uf_counts.columns = ['UF', 'Total de Registros']\n",
    "display(Markdown(\"### Distribui√ß√£o por Unidade Federativa\"))\n",
    "plt.figure(figsize=(10,5))\n",
    "ax1 = sns.barplot(data=uf_counts, x='UF', y='Total de Registros', palette='Blues_d', legend=False, hue='UF')\n",
    "plt.title('Distribui√ß√£o por Unidade Federativa')\n",
    "plt.xlabel('UF')\n",
    "plt.ylabel('Total de Registros')\n",
    "plt.xticks(rotation=45)\n",
    "for p in ax1.patches:\n",
    "    ax1.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                 ha='center', va='bottom', fontsize=9, color='black', xytext=(0, 3), textcoords='offset points')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partido\n",
    "partido_counts = df_completo['sgPartido'].value_counts().reset_index()\n",
    "partido_counts.columns = ['Partido', 'Total de Registros']\n",
    "display(Markdown(\"### Distribui√ß√£o por Partido\"))\n",
    "plt.figure(figsize=(12,5))\n",
    "ax2 = sns.barplot(data=partido_counts, x='Partido', y='Total de Registros', palette='Greens_d', legend=False, hue='Partido')\n",
    "plt.title('Distribui√ß√£o por Partido')\n",
    "plt.xlabel('Partido')\n",
    "plt.ylabel('Total de Registros')\n",
    "plt.xticks(rotation=45)\n",
    "for p in ax2.patches:\n",
    "    ax2.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                 ha='center', va='bottom', fontsize=9, color='black', xytext=(0, 3), textcoords='offset points')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipo de Despesa\n",
    "despesa_counts = df_completo['txtDescricao'].value_counts().reset_index()\n",
    "despesa_counts.columns = ['Tipo de Despesa', 'Total de Registros']\n",
    "display(Markdown(\"### Distribui√ß√£o por Tipo de Despesa (Top 15)\"))\n",
    "plt.figure(figsize=(12,6))\n",
    "ax3 = sns.barplot(data=despesa_counts.head(15), x='Tipo de Despesa', y='Total de Registros', palette='Oranges_d', legend=False, hue='Tipo de Despesa', )\n",
    "plt.title('Distribui√ß√£o por Tipo de Despesa (Top 15)')\n",
    "plt.xlabel('Tipo de Despesa')\n",
    "plt.ylabel('Total de Registros')\n",
    "plt.xticks(rotation=75)\n",
    "for p in ax3.patches:\n",
    "    ax3.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                 ha='center', va='bottom', fontsize=9, color='black', xytext=(0, 3), textcoords='offset points')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzPUggSjQq2c"
   },
   "source": [
    "## 2.4 Verifica√ß√£o da Qualidade dos Dados<a class=\"anchor\" id=\"qualidade-dos-dados\"></a>\n",
    "Abaixo est√° um resumo quantitativo da qualidade dos dados ap√≥s a an√°lise explorat√≥ria inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo geral do dataset\n",
    "resumo_geral = pd.DataFrame({\n",
    "    \"Indicador\": [\n",
    "        \"Total de registros\",\n",
    "        \"Total de vari√°veis (colunas)\",\n",
    "        \"Registros duplicados\",\n",
    "        \"Valores inconsistentes (vlrDocumento < vlrLiquido)\",\n",
    "        \"Total valor liquido negativo\"\n",
    "    ],\n",
    "    \"Valor\": [\n",
    "        df_completo.shape[0],\n",
    "        df_completo.shape[1],\n",
    "        df_completo.duplicated().sum(),\n",
    "        (df_completo['vlrDocumento'] < df_completo['vlrLiquido']).sum(),\n",
    "        (df_completo['vlrLiquido'] < 0 ).sum()\n",
    "    ]\n",
    "})\n",
    "\n",
    "display(Markdown(\"### Resumo Geral da Base de Dados\"))\n",
    "display(resumo_geral)\n",
    "\n",
    "# Colunas com valores nulos\n",
    "nulls = df_completo.isnull().sum()\n",
    "nulls = nulls[nulls > 0].sort_values(ascending=False).reset_index()\n",
    "nulls.columns = ['Coluna', 'Valores Nulos']\n",
    "\n",
    "display(Markdown(\"### Colunas com Valores Ausentes\"))\n",
    "display(nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcL0DjOzQq2c"
   },
   "source": [
    "# 3. Prepara√ß√£o dos Dados <a class=\"anchor\" id=\"preparacao-dados\"></a>\n",
    "\n",
    "\n",
    "Nesta etapa, realizamos o tratamento necess√°rio para transformar os dados brutos em uma base estruturada e adequada para aplica√ß√£o de modelos de aprendizado supervisionado. As a√ß√µes incluem: sele√ß√£o e limpeza de dados, gera√ß√£o de atributos derivados e integra√ß√£o das bases hist√≥ricas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQjMmUM5Qq2c"
   },
   "source": [
    "## 3.1 Sele√ß√£o dos Dados <a class=\"anchor\" id=\"selecao-dados\"></a>\n",
    "\n",
    "Nesta etapa inicial da **Prepara√ß√£o dos Dados**, realizamos a sele√ß√£o criteriosa das vari√°veis mais relevantes para o problema de predi√ß√£o do **valor l√≠quido da despesa parlamentar (`vlrLiquido`)**.\n",
    "\n",
    "O objetivo √© filtrar os dados brutos e manter somente as informa√ß√µes que possuem **rela√ß√£o direta com o comportamento dos gastos parlamentares**, otimizando o desempenho dos algoritmos de machine learning.\n",
    "\n",
    "---\n",
    "\n",
    "#### üî∏ Crit√©rios de Sele√ß√£o\n",
    "\n",
    "Selecionamos as colunas que possuem potencial explicativo e que apresentam valor informacional para o modelo supervisionado. As vari√°veis escolhidas foram:\n",
    "\n",
    "- **`sgUF`**: unidade federativa, que pode refletir realidades regionais de gastos.\n",
    "- **`sgPartido`**: partido pol√≠tico, poss√≠vel fator explicativo para padr√µes de despesa.\n",
    "- **`txtDescricao`**: tipo de despesa (ex: alimenta√ß√£o, aluguel, combust√≠vel).\n",
    "- **`vlrDocumento`**: valor bruto do documento fiscal apresentado.\n",
    "- **`numAno`**: per√≠odo da despesa, para an√°lise sazonal ou temporal.\n",
    "- **`vlrLiquido`**: vari√°vel-alvo que ser√° predita pelo modelo.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDRfR6L8Qq2d"
   },
   "source": [
    "## 3.2 Limpeza dos Dados <a class=\"anchor\" id=\"limpeza-dados\"></a>\n",
    "\n",
    "\n",
    "Nesta etapa, realizamos uma s√©rie de a√ß√µes de limpeza para garantir que os dados utilizados nos modelos estejam consistentes, sem ru√≠dos e com alta qualidade informacional. A prepara√ß√£o adequada dos dados √© essencial para que qualquer modelo de aprendizado de m√°quina produza resultados confi√°veis.\n",
    "\n",
    "As a√ß√µes tomadas nesta fase incluem:\n",
    "\n",
    "---\n",
    "\n",
    "#### üî∏ Remo√ß√£o de Registros Inconsistentes\n",
    "\n",
    "Eliminamos os registros em que o valor l√≠quido (`vlrLiquido`) era superior ao valor bruto do documento (`vlrDocumento`). Essa inconsist√™ncia viola a l√≥gica financeira da base de dados e poderia comprometer an√°lises futuras. Esses registros foram identificados, quantificados e removidos de forma criteriosa.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove linhas onde vlrLiquido > vlrDocumento\n",
    "df_modelo = df_completo[df_completo['vlrLiquido'] <= df_completo['vlrDocumento']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### üî∏ Tratamento de Valores Negativos\n",
    "\n",
    "Foram identificados valores negativos na coluna `vlrLiquido` ‚Äî o que n√£o representa um cen√°rio v√°lido para gastos parlamentares. Esses valores estavam presentes em todas as bases de 2023, 2024 e 2025:\n",
    "\n",
    "- **2023:** 9.383 registros\n",
    "- **2024:** 10.327 registros\n",
    "- **2025:** 2.626 registros\n",
    "\n",
    "Todos foram removidos ap√≥s verifica√ß√£o e exibi√ß√£o de amostras por ano. A limpeza foi validada com uma checagem final, confirmando que **nenhum valor negativo permaneceu**.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove registros onde vlrLiquido √© negativo\n",
    "df_modelo = df_modelo[df_modelo['vlrLiquido'] >= 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### üî∏ Elimina√ß√£o de Registros com Valores Ausentes (NaN)\n",
    "\n",
    "Ap√≥s a sele√ß√£o e transforma√ß√£o das colunas relevantes, identificamos **2.135 registros com valores ausentes**, totalizando **4.270 c√©lulas com `NaN`**. Esses dados foram descartados para evitar vi√©s no processo de modelagem, uma vez que a imputa√ß√£o poderia comprometer a acur√°cia dos modelos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove registros onde a coluna 'sgUF' possui valores nulos (NaN)\n",
    "df_modelo = df_modelo[df_modelo['sgUF'].notnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove registros onde a coluna 'sgPartido' possui valores nulos (NaN)\n",
    "df_modelo = df_modelo[df_modelo['sgPartido'].notnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### üî∏ Remo√ß√£o de Registros Duplicados\n",
    "\n",
    "Realizamos a verifica√ß√£o de duplicatas no conjunto de dados e removemos entradas repetidas para garantir que cada linha representasse uma observa√ß√£o √∫nica. Essa pr√°tica evita sobrepeso em certas categorias e garante imparcialidade nas an√°lises estat√≠sticas.\n",
    "\n",
    "**Na base tratado n√£o h√° registros duplicados**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### üî∏ Remo√ß√£o de Colunas Desnecess√°rias\n",
    "\n",
    "Foram exclu√≠das colunas que n√£o contribu√≠am para os objetivos do projeto, como identificadores √∫nicos (`CPF`, `CNPJ`, c√≥digos legislativos), atributos com alta cardinalidade ou informa√ß√µes redundantes. Essa etapa reduziu a complexidade do modelo e aumentou a interpretabilidade.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mant√©m apenas as colunas desejadas em df_modelo\n",
    "colunas_desejadas = ['sgUF', 'sgPartido', 'txtDescricao', 'numAno', 'vlrLiquido']\n",
    "df_modelo = df_modelo[colunas_desejadas].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### üî∏ Convers√£o da coluna numAno em valor categ√≥rico\n",
    "\n",
    "Quando uma vari√°vel como numAno representa categorias (por exemplo, anos como 2019, 2020, 2021 etc.) e n√£o uma medida cont√≠nua, faz total sentido trat√°-la como vari√°vel categ√≥rica. Isso evita que o modelo interprete erroneamente rela√ß√µes ordinais ou cont√≠nuas entre os anos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo['numAno'] = df_modelo['numAno'].astype('int').astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### üî∏ Agrega√ß√£o atrav√©s da soma do vlrLiquido\n",
    "\n",
    "Agrega√ß√£o atrav√©s da soma do vlrLiquido, classificado pelos demais campos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um novo DataFrame agregando pela soma do vlrLiquido\n",
    "df_modelo = (\n",
    "    df_modelo\n",
    "    .groupby(['sgUF', 'sgPartido', 'txtDescricao', 'numAno'], as_index=False)\n",
    "    .agg(vlrLiquidoTotal=('vlrLiquido', 'sum'))\n",
    ")\n",
    "\n",
    "\n",
    "# Exibe as primeiras linhas do novo DataFrame\n",
    "display(df_modelo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "###  Resultado Final\n",
    "\n",
    "Ap√≥s todas as etapas de limpeza, o novo DataFrame final (`df_modelo`) apresenta:\n",
    "\n",
    "- **6490 registros**\n",
    "- **5 colunas relevantes**\n",
    "- Nenhum valor `NaN` ou negativo\n",
    "- Dados prontos para modelagem supervisionada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "####  Amostra dos dados tratados:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Nesta etapa, realizamos um processo criterioso de saneamento da base de dados, com o objetivo de **garantir a integridade, consist√™ncia e confiabilidade das informa√ß√µes** que alimentar√£o os modelos de aprendizado supervisionado.\n",
    "\n",
    "A limpeza dos dados √© uma fase cr√≠tica, pois **modelos de Machine Learning s√£o altamente sens√≠veis a ru√≠dos, valores inv√°lidos e informa√ß√µes incompletas**. Um dado inconsistente pode comprometer toda a performance do modelo ‚Äî e pior, gerar conclus√µes enganosas para decis√µes reais.\n",
    "\n",
    "### A√ß√µes realizadas:\n",
    "\n",
    "1. **Remo√ß√£o de valores negativos em `vlrLiquido`:**  \n",
    "   Foram detectados e eliminados milhares de registros com valores negativos, o que representa **erros claros de entrada de dados**. Como o `vlrLiquido` representa o valor final pago em uma despesa, n√£o √© plaus√≠vel que ele seja negativo.\n",
    "\n",
    "2. **Elimina√ß√£o de registros com `vlrLiquido` maior que `vlrDocumento`:**  \n",
    "   Foram identificados **2 registros** em que o valor l√≠quido ultrapassava o valor bruto do documento, o que √© logicamente incorreto. Esses registros foram removidos.\n",
    "\n",
    "3. **Remo√ß√£o de valores ausentes (`NaN`)**  \n",
    "   Ap√≥s as transforma√ß√µes e constru√ß√µes de vari√°veis, foram encontrados **2.135 registros com valores ausentes** em colunas relevantes. Esses registros foram removidos para **evitar vi√©s nos algoritmos de predi√ß√£o** e assegurar que todas as vari√°veis estejam completas.\n",
    "\n",
    "4. **Exclus√£o de colunas irrelevantes ao modelo:**  \n",
    "   Diversas colunas foram descartadas por n√£o contribu√≠rem para a modelagem ou por conterem informa√ß√µes sens√≠veis e desnecess√°rias (como CPF, CNPJ, c√≥digos internos da C√¢mara, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "### Benef√≠cios diretos dessa etapa:\n",
    "\n",
    "- **Redu√ß√£o de ru√≠dos** que impactariam negativamente na acur√°cia dos modelos.\n",
    "- **Evita o overfitting** com dados duplicados ou corrompidos.\n",
    "- **Aumenta a confiabilidade das previs√µes**, ao garantir que os dados sigam uma l√≥gica de neg√≥cios clara.\n",
    "- **Permite extra√ß√£o de insights mais precisos**, facilitando compara√ß√µes, agrupamentos e an√°lises de tend√™ncia.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 An√°lise Explorat√≥ria dos Dados (EDA) <a class=\"anchor\" id=\"analise-dados\"></a>\n",
    "\n",
    "\n",
    "A an√°lise explorat√≥ria foi fundamental para entender o comportamento dos gastos parlamentares e detectar padr√µes interessantes no dataset. Abaixo, s√£o apresentados os principais destaques visuais:\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ UFs com Maior M√©dia de Gastos\n",
    "\n",
    "O primeiro gr√°fico mostra a m√©dia dos valores l√≠quidos por Unidade Federativa (UF). A visualiza√ß√£o permite identificar quais estados concentram os maiores gastos m√©dios.\n",
    "\n",
    "- **Insight:** Estados com maior representatividade pol√≠tica ou maior n√∫mero de parlamentares podem influenciar esses valores.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Partidos com Maior M√©dia de Gastos\n",
    "\n",
    "Neste gr√°fico, analisamos os partidos pol√≠ticos com maiores m√©dias de despesas l√≠quidas entre seus representantes.\n",
    "\n",
    "- **Insight:** Partidos com mais cadeiras no Congresso tendem a apresentar maiores valores agregados. No entanto, o foco est√° na **m√©dia por parlamentar**, revelando padr√µes internos de gastos por legenda.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Tipos de Despesa com Maior Valor M√©dio por Transa√ß√£o\n",
    "\n",
    "Este gr√°fico horizontal apresenta os **tipos de despesas** com maior valor m√©dio por transa√ß√£o realizada.\n",
    "\n",
    "- **Insight:** Gastos como **loca√ß√£o de ve√≠culos**, **divulga√ß√£o da atividade parlamentar** e **manuten√ß√£o de escrit√≥rio** aparecem entre os maiores custos m√©dios, indicando despesas pontuais de alto valor.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Essas visualiza√ß√µes s√£o essenciais para gerar hip√≥teses que poder√£o ser testadas na modelagem preditiva e ajudar na constru√ß√£o de vari√°veis derivadas com potencial explicativo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√≥digo para visualiza√ß√µes agregadas com Plotly\n",
    "\n",
    "# Define um template padr√£o para o Plotly\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "# Converte apresenta√ß√£o do valor para brasileiro (R$)\n",
    "def formatar_valor(valor):\n",
    "    return f\"R$ {valor:,.2f}\".replace(\",\", \"X\").replace(\".\", \",\").replace(\"X\", \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 UFs por Gasto Total\n",
    "top_ufs = (\n",
    "    df_modelo.groupby('sgUF')['vlrLiquidoTotal']\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .reset_index()\n",
    ")\n",
    "top_ufs['texto'] = top_ufs['vlrLiquidoTotal'].apply(formatar_valor)\n",
    "\n",
    "fig1 = px.bar(\n",
    "    top_ufs,\n",
    "    x='sgUF',\n",
    "    y='vlrLiquidoTotal',\n",
    "    orientation='v',\n",
    "    title='<b>UFs por Gastos Totais</b>',\n",
    "    labels={'vlrLiquidoTotal': 'Gasto Total (R$)', 'sgUF': 'UF'},\n",
    "    text='texto'\n",
    ")\n",
    "fig1.update_layout(showlegend=False, yaxis={'categoryorder':'total ascending'})\n",
    "fig1.update_traces(textposition='outside', marker_color='#EF553B')\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Partidos por Gasto Total\n",
    "top_partidos = (\n",
    "    df_modelo.groupby('sgPartido')['vlrLiquidoTotal']\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .reset_index()\n",
    ")\n",
    "top_partidos['texto'] = top_partidos['vlrLiquidoTotal'].apply(formatar_valor)\n",
    "\n",
    "fig2 = px.bar(\n",
    "    top_partidos,\n",
    "    x='sgPartido',\n",
    "    y='vlrLiquidoTotal',\n",
    "    orientation='v',\n",
    "    title='<b>Partidos por Gastos Totais</b>',\n",
    "    labels={'vlrLiquidoTotal': 'Gasto Total (R$)', 'sgPartido': 'Partido'},\n",
    "    text='texto'\n",
    ")\n",
    "fig2.update_layout(showlegend=False, yaxis={'categoryorder':'total ascending'})\n",
    "fig2.update_traces(textposition='outside', marker_color='#00CC96')\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Tipos de Despesa com Maior Valor M√©dio \n",
    "\n",
    "top_tipos = (\n",
    "    df_modelo.groupby('txtDescricao')['vlrLiquidoTotal']\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Formatando valores como texto no padr√£o brasileiro\n",
    "top_tipos['texto'] = top_tipos['vlrLiquidoTotal'].apply(formatar_valor)\n",
    "\n",
    "# Gr√°fico com tipos de despesa no eixo Y (barra horizontal)\n",
    "fig3 = px.bar(\n",
    "    top_tipos,\n",
    "    x='vlrLiquidoTotal',\n",
    "    y='txtDescricao',\n",
    "    orientation='h',\n",
    "    title='<b>Tipos de Despesa com Maior Valor M√©dio por Transa√ß√£o</b>',\n",
    "    labels={'vlrLiquidoTotal': 'Valor M√©dio (R$)', 'txtDescricao': 'Tipo de Despesa'},\n",
    "    text='texto'\n",
    ")\n",
    "\n",
    "fig3.update_layout(\n",
    "    showlegend=False,\n",
    "    xaxis_tickformat=',.2f',\n",
    "    yaxis=dict(categoryorder='total ascending'),\n",
    "    height=800  # aumenta a altura do gr√°fico para caber melhor os r√≥tulos\n",
    ")\n",
    "\n",
    "fig3.update_traces(\n",
    "    textposition='outside',\n",
    "    marker_color='#AB63FA'\n",
    ")\n",
    "\n",
    "fig3.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvEceHzUQq2j"
   },
   "source": [
    "# 4. Modelagem <a class=\"anchor\" id=\"modelagem\"></a>\n",
    "Nesta etapa, constru√≠mos e testamos diferentes modelos de regress√£o para prever os valores l√≠quidos (`vlrLiquidoTotal`) das despesas parlamentares, com foco na performance e interpretabilidade. Duas abordagens foram adotadas: Random Forest e CatBoost.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9H-GXDBNQq2j"
   },
   "source": [
    "## 4.1. T√©cnicas de Modelagem <a class=\"anchor\" id=\"tecnicas-modelagem\"></a>\n",
    "Foram selecionadas duas t√©cnicas supervisionadas de regress√£o:\n",
    "\n",
    "- **Random Forest Regressor**: um modelo de ensemble baseado em √°rvores de decis√£o. Requer tratamento expl√≠cito das vari√°veis categ√≥ricas (via OneHotEncoder).\n",
    "- **CatBoost Regressor**: algoritmo especializado para lidar com vari√°veis categ√≥ricas de forma nativa, sem a necessidade de codifica√ß√£o manual.\n",
    "\n",
    "Essas abordagens foram encapsuladas em pipelines que garantem consist√™ncia no pr√©-processamento e na modelagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "nhhwoVkVQq2k"
   },
   "outputs": [],
   "source": [
    "# Separa√ß√£o da vari√°vel target\n",
    "X = df_modelo.drop('vlrLiquidoTotal', axis=1)\n",
    "y = df_modelo['vlrLiquidoTotal']\n",
    "\n",
    "categorical_cols = ['sgUF', 'sgPartido', 'txtDescricao', 'numAno']\n",
    "\n",
    "# Divis√£o dos dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline 1: Random Forest com OneHotEncoder\n",
    "preprocessor_rf = ColumnTransformer(\n",
    "    transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)]\n",
    ")\n",
    "\n",
    "pipeline_rf = Pipeline(steps=[\n",
    "    ('preprocessamento', preprocessor_rf),\n",
    "    ('modelo', RandomForestRegressor(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline 2: CatBoost (lida com categorias diretamente)\n",
    "pipeline_cb = Pipeline(steps=[\n",
    "    ('modelo', CatBoostRegressor(verbose=0, cat_features=categorical_cols))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8ClvOxXQq2k"
   },
   "source": [
    "## 4.2. Teste de Modelos <a class=\"anchor\" id=\"teste-modelos\"></a>\n",
    "Ambos os modelos foram treinados e avaliados com **Root Mean Squared Error (RMSE)** como m√©trica principal.\n",
    "\n",
    "**Resultados iniciais (sem otimiza√ß√£o):**\n",
    "- Random Forest ‚Äì RMSE: `14428982591.47198`\n",
    "- CatBoost ‚Äì RMSE: `8239011221.177081`\n",
    "\n",
    "> A partir disso, foi poss√≠vel observar que ambos os modelos conseguiram aprender padr√µes relevantes, mas havia espa√ßo para otimiza√ß√£o.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento e avalia√ß√£o\n",
    "pipeline_rf.fit(X_train, y_train)\n",
    "y_pred_rf = pipeline_rf.predict(X_test)\n",
    "print(\"Random Forest - RMSE:\", mean_squared_error(y_test, y_pred_rf))\n",
    "\n",
    "pipeline_cb.fit(X_train, y_train)\n",
    "y_pred_cb = pipeline_cb.predict(X_test)\n",
    "print(\"CatBoost - RMSE:\", mean_squared_error(y_test, y_pred_cb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQFDFtQoQq2k"
   },
   "source": [
    "## 4.3. Constru√ß√£o do Modelo (Build) <a class=\"anchor\" id=\"construcao-modelo\"></a>\n",
    "\n",
    "Nesta etapa, realizamos o **ajuste fino (tuning)** dos modelos utilizando a t√©cnica de valida√ß√£o cruzada com `GridSearchCV`. Esse processo √© essencial para **maximizar a performance preditiva** e evitar o sobreajuste.\n",
    "\n",
    "---\n",
    "\n",
    "### Random Forest com GridSearchCV\n",
    "\n",
    "A busca por hiperpar√¢metros √≥timos foi aplicada ao modelo de Random Forest, com os seguintes par√¢metros testados:\n",
    "\n",
    "- `n_estimators`: n√∫mero de √°rvores na floresta ‚Üí [50, 100]\n",
    "- `max_depth`: profundidade m√°xima de cada √°rvore ‚Üí [None, 5, 10]\n",
    "\n",
    "O ajuste foi feito com valida√ß√£o cruzada (`cv=3`) e a m√©trica de avalia√ß√£o foi o **RMSE negativo** (porque o `GridSearchCV` busca maximizar scores).\n",
    "\n",
    "**Melhores par√¢metros encontrados:**\n",
    "```python\n",
    "Melhores par√¢metros: {'modelo__max_depth': 10, 'modelo__n_estimators': 100}\n",
    "Melhor RMSE: 191.567, aproximadamente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1. Random Forest: Ajustar os melhores hiperpar√¢metros de forma autom√°tica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'modelo__n_estimators': [50, 100],\n",
    "    'modelo__max_depth': [None, 5, 10]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(pipeline_rf, param_grid, cv=3, scoring='neg_root_mean_squared_error')\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "# üîπ Resultados do GridSearchCV - Random Forest\n",
    "melhores_param_rf = grid_rf.best_params_\n",
    "melhor_rmse_rf = -grid_rf.best_score_\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "###  Resultados do Random Forest (GridSearchCV)\n",
    "- **Melhores Par√¢metros:** `{melhores_param_rf}`\n",
    "- **Melhor RMSE (valida√ß√£o cruzada):** `{melhor_rmse_rf:,.2f}`\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2. Random Forest: Visualizar as categorias mais influentes na previs√£o do pre√ßo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import√¢ncia das features (ap√≥s o one-hot encoding)\n",
    "modelo_treinado = grid_rf.best_estimator_.named_steps['modelo']\n",
    "nomes_features = grid_rf.best_estimator_.named_steps['preprocessamento'].transformers_[0][1].get_feature_names_out(categorical_cols)\n",
    "\n",
    "importancias = pd.Series(modelo_treinado.feature_importances_, index=nomes_features).sort_values(ascending=False)\n",
    "\n",
    "# Top 20 features mais importantes\n",
    "top_n = 20\n",
    "importancias_top = importancias.head(top_n)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=importancias_top.values, y=importancias_top.index, palette=\"crest\")\n",
    "plt.title(f\"Top {top_n} Vari√°veis Mais Importantes - Random Forest\", fontsize=14)\n",
    "plt.xlabel(\"Import√¢ncia\", fontsize=12)\n",
    "plt.ylabel(\"Vari√°veis\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3. CatBoost: Ajustar os melhores hiperpar√¢metros de forma autom√°tica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustando pipeline para uso com GridSearchCV\n",
    "# Precisamos criar uma fun√ß√£o para embutir o Pool do CatBoost, j√° que ele lida com categorias internamente\n",
    "class CatBoostPipeline(Pipeline):\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        # Identifica colunas categ√≥ricas por √≠ndice\n",
    "        cat_features = [X.columns.get_loc(col) for col in X.select_dtypes(include='object').columns]\n",
    "        self.steps[-1][1].fit(X, y, cat_features=cat_features)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, **predict_params):\n",
    "        return self.steps[-1][1].predict(X)\n",
    "\n",
    "# Novo pipeline com CatBoost\n",
    "pipeline_cb = CatBoostPipeline(steps=[('modelo', CatBoostRegressor(verbose=0))])\n",
    "\n",
    "param_grid_cb = {\n",
    "    'modelo__depth': [4, 6, 8],\n",
    "    'modelo__learning_rate': [0.01, 0.1],\n",
    "    'modelo__iterations': [100, 200]\n",
    "}\n",
    "\n",
    "grid_cb = GridSearchCV(pipeline_cb, param_grid_cb, cv=3, scoring='neg_root_mean_squared_error')\n",
    "grid_cb.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "melhores_param_cb = grid_cb.best_params_\n",
    "melhor_rmse_cb = -grid_cb.best_score_\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "### Resultados do CatBoost (GridSearchCV)\n",
    "- **Melhores Par√¢metros:** `{melhores_param_cb}`\n",
    "- **Melhor RMSE (valida√ß√£o cruzada):** `{melhor_rmse_cb:,.2f}`\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.4. CatBoost: Visualizar as categorias mais influentes na previs√£o do pre√ßo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import√¢ncia das vari√°veis\n",
    "modelo_cb = grid_cb.best_estimator_.named_steps['modelo']\n",
    "importancias_cb = modelo_cb.get_feature_importance()\n",
    "nomes_cb = X_train.columns\n",
    "\n",
    "df_importancias = pd.Series(importancias_cb, index=nomes_cb).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(x=df_importancias.values, y=df_importancias.index)\n",
    "plt.title(\"Import√¢ncia das Vari√°veis - CatBoost\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZL6W-w7YQq2k"
   },
   "source": [
    "## 4.4. Avalia√ß√£o de Performance <a class=\"anchor\" id=\"avaliacao-modelo\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1. An√°lise comparativa entre os modelos\n",
    "\n",
    "Antes de prosseguirmos com a avalia√£o de performance dos modelos testados, seguem algumas m√©tricas fundamentais √∫teis:\n",
    "\n",
    "- **RMSE (Root Mean Squared Error)** ‚Äì Penaliza mais erros grandes.\n",
    "- **MAE (Mean Absolute Error)** ‚Äì Mais robusta a outliers.\n",
    "- **R¬≤ (Coeficiente de Determina√ß√£o)** ‚Äì Mede o qu√£o bem os dados se ajustam √† regress√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U1YFLClIQq2k",
    "outputId": "bfdbddad-824f-4a40-96cb-6cec08c7cb7d"
   },
   "outputs": [],
   "source": [
    "# Previs√µes\n",
    "y_pred_rf = grid_rf.predict(X_test)\n",
    "y_pred_cb = grid_cb.predict(X_test)\n",
    "\n",
    "# Fun√ß√£o para consolidar as m√©tricas\n",
    "def avaliar_modelo(y_true, y_pred):\n",
    "    return {\n",
    "        'RMSE': mean_squared_error(y_true, y_pred),\n",
    "        'MAE': mean_absolute_error(y_true, y_pred),\n",
    "        'R¬≤': r2_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "# Avalia√ß√£o dos modelos\n",
    "avaliacao_rf = avaliar_modelo(y_test, y_pred_rf)\n",
    "avaliacao_cb = avaliar_modelo(y_test, y_pred_cb)\n",
    "\n",
    "# üîπ Comparativo Final dos Modelos\n",
    "avaliacao_rf = avaliar_modelo(y_test, y_pred_rf)\n",
    "avaliacao_cb = avaliar_modelo(y_test, y_pred_cb)\n",
    "df_resultados = pd.DataFrame([avaliacao_rf, avaliacao_cb], index=['Random Forest', 'CatBoost'])\n",
    "\n",
    "display(Markdown(\"### Comparativo de M√©tricas dos Modelos (conjunto de teste):\"))\n",
    "display(df_resultados.style.format(\"{:,.2f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Primeiro, pegue o melhor pipeline encontrado pelo GridSearchCV\n",
    "melhor_pipeline = grid_cb.best_estimator_\n",
    "\n",
    "# Agora, extraia APENAS o passo do modelo treinado de dentro do pipeline\n",
    "modelo_final = melhor_pipeline.named_steps['modelo']\n",
    "\n",
    "# Salve APENAS o modelo final. Este ser√° um objeto CatBoostRegressor padr√£o.\n",
    "joblib.dump(modelo_final, 'Modelo/Artefatos/modelo.bin')\n",
    "\n",
    "print(\"Modelo CatBoost final salvo com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados.plot(kind='bar', figsize=(8, 5))\n",
    "plt.title('Compara√ß√£o de Desempenho dos Modelos')\n",
    "plt.ylabel('Valor')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filtro apenas da m√©trica R¬≤\n",
    "r2_resultados = df_resultados[['R¬≤']].copy().reset_index()\n",
    "r2_resultados.columns = ['Modelo', 'R¬≤']\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(7, 4))\n",
    "sns.barplot(data=r2_resultados, x='Modelo', y='R¬≤', palette='coolwarm')\n",
    "\n",
    "plt.title(\"Comparativo do R¬≤ entre os Modelos\")\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel(\"Coeficiente de Determina√ß√£o (R¬≤)\")\n",
    "plt.xlabel(\"Modelo\")\n",
    "\n",
    "# Adiciona os valores nas barras\n",
    "for index, row in r2_resultados.iterrows():\n",
    "    plt.text(x=index, y=row['R¬≤'] + 0.02, s=f\"{row['R¬≤']:.2f}\", ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Avalia√ß√£o do Modelo <a class=\"anchor\" id=\"avaliacao-modelo\"></a>\n",
    "\n",
    "\n",
    "Nesta etapa, avaliamos se os modelos treinados atendem aos objetivos do projeto, especialmente no que diz respeito √† **precis√£o na estimativa dos gastos parlamentares**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Avalia√ß√£o da Performance dos Modelos <a class=\"anchor\" id=\"avaliacao-da-performance-dos-modelos\"></a>\n",
    "\n",
    "Nesta etapa, avaliamos a performance dos modelos de regress√£o treinados para prever o valor l√≠quido das despesas parlamentares (`vlrLiquidoTotal`). Foram aplicados dois algoritmos:\n",
    "\n",
    "- **Random Forest Regressor**, com pr√©-processamento via OneHotEncoder.\n",
    "- **CatBoost Regressor**, que lida nativamente com vari√°veis categ√≥ricas.\n",
    "\n",
    "#### M√©tricas Utilizadas:\n",
    "\n",
    "- **RMSE (Root Mean Squared Error)**: mede o erro quadr√°tico m√©dio. Quanto menor, melhor.\n",
    "- **MAE (Mean Absolute Error)**: erro absoluto m√©dio entre valores reais e previstos.\n",
    "- **R¬≤ (Coeficiente de Determina√ß√£o)**: mede o quanto o modelo explica da variabilidade dos dados.\n",
    "\n",
    "#### Resultados Obtidos:\n",
    "\n",
    "| Modelo         | RMSE                  | MAE           | R¬≤    |\n",
    "|----------------|------------------------|----------------|-------|\n",
    "| Random Forest  | R$ 14.428.982.591,47   | R$ 55.159,50   | 0.56  |\n",
    "| CatBoost       | R$ 8.963.990.729,78    | R$ 42.582,03   | 0.73  |\n",
    "\n",
    "*Conclus√£o:* O **CatBoost superou o Random Forest** em todas as m√©tricas avaliadas, especialmente no RMSE e no R¬≤, mostrando-se mais eficiente em prever o valor final das despesas com menor erro e maior capacidade explicativa.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Interpreta√ß√£o dos Resultados <a class=\"anchor\" id=\"interpretacao-dos-resultados\"></a>\n",
    "\n",
    "A an√°lise da import√¢ncia das vari√°veis indicou que os fatores que mais influenciam o valor l√≠quido das despesas s√£o:\n",
    "\n",
    "- **Tipo de Despesa (`txtDescricao`)**: foi a vari√°vel mais relevante em ambos os modelos.\n",
    "- **UF e Partido**: tamb√©m aparecem com forte impacto, indicando poss√≠veis varia√ß√µes regionais e partid√°rias.\n",
    "- **Ano (`numAno`)**: pode refletir padr√µes anuais de gastos ou ciclos eleitorais.\n",
    "\n",
    "A partir dos gr√°ficos gerados, foi poss√≠vel visualizar:\n",
    "\n",
    "- Os partidos e estados com maiores valores m√©dios de despesas.\n",
    "- O impacto m√©dio por tipo de despesa.\n",
    "- A compara√ß√£o direta entre os modelos com gr√°ficos de barras e o R¬≤ individual.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Revis√£o do Processo e Pr√≥ximos Passos <a class=\"anchor\" id=\"revisao-do-processo-e-proximos-passos\"></a>\n",
    "\n",
    "#### Revis√£o do Processo\n",
    "O projeto seguiu todas as etapas da metodologia **CRISP-DM**, desde o entendimento do problema de neg√≥cio at√© a modelagem e avalia√ß√£o:\n",
    "\n",
    "1. Coleta de dados de diferentes anos do portal da C√¢mara.\n",
    "2. Limpeza, integra√ß√£o e cria√ß√£o de vari√°veis derivadas.\n",
    "3. An√°lise explorat√≥ria e visualiza√ß√µes interativas.\n",
    "4. Modelagem preditiva com dois algoritmos robustos.\n",
    "5. Avalia√ß√£o com m√©tricas de regress√£o e interpreta√ß√£o dos resultados.\n",
    "\n",
    "#### Pr√≥ximos Passos\n",
    "\n",
    "- **Implantar uma API com FastAPI** que disponibilize o modelo CatBoost para uso em produ√ß√£o (endpoint `/predict`).\n",
    "- **Salvar artefatos do modelo** (`.pkl` ou `.cbm`) e aplic√°-los no backend.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Aplica√ß√£o pr√°tica (Deployment)\n",
    "\n",
    "## Descrever como foi implementada a API."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
